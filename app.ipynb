{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "12V8CfYLiGjP0amLsQoJ0hLmj6qUZ6yQE",
      "authorship_tag": "ABX9TyOiIQ/Ew76Pmvyjr53rdRsu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/M85X12/demo-repository/blob/main/app.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f57fe235"
      },
      "source": [
        "import zipfile\n",
        "import json\n",
        "import os\n",
        "\n",
        "zip_path = '/content/drive/MyDrive/takeout-20240523T222735Z-001.zip'\n",
        "json_file_path_in_zip = 'takeout-20240523T222735Z-001/Takeout/我的活動/我的活動.json'\n",
        "json_content = None\n",
        "\n",
        "try:\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zf:\n",
        "        if json_file_path_in_zip in zf.namelist():\n",
        "            with zf.open(json_file_path_in_zip) as f:\n",
        "                # Read the first few lines to avoid loading a huge file into memory\n",
        "                lines = [f.readline().decode('utf-8') for _ in range(20)]\n",
        "                json_content = \"\".join(lines)\n",
        "        else:\n",
        "            print(f\"在壓縮檔中找不到指定的檔案：{json_file_path_in_zip}\")\n",
        "\n",
        "    if json_content:\n",
        "        print(f\"成功讀取 {json_file_path_in_zip} 的部分內容：\\n\")\n",
        "        print(json_content)\n",
        "        print(\"\\n請檢視上述 JSON 結構，特別是每個物件包含的欄位 (header, title, time, products 等)。\")\n",
        "        print(\"這將是您後續建立資料模型的依據。\")\n",
        "    else:\n",
        "        print(f\"無法讀取 {json_file_path_in_zip} 檔案。請確認檔案存在且格式正確。\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"錯誤：找不到檔案 {zip_path}。請確認路徑是否正確，以及 Google Drive 是否已成功掛載。\")\n",
        "except zipfile.BadZipFile:\n",
        "    print(f\"錯誤：檔案 {zip_path} 不是有效的 Zip 檔案。\")\n",
        "except Exception as e:\n",
        "    print(f\"讀取檔案時發生錯誤：{e}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60b18726"
      },
      "source": [
        "def generate_code_for_step(step_description):\n",
        "    \"\"\"\n",
        "    根據步驟描述生成簡單的程式碼片段 (這裡只是簡單示範)\n",
        "    \"\"\"\n",
        "    if \"讀取檔案\" in step_description:\n",
        "        return \"print('正在模擬讀取檔案...')\"\n",
        "    elif \"處理資料\" in step_description:\n",
        "        return \"data = [1, 2, 3]\\nprint(f'正在模擬處理資料: {data}')\"\n",
        "    elif \"顯示結果\" in step_description:\n",
        "        return \"result = '模擬結果'\\nprint(f'正在模擬顯示結果: {result}')\"\n",
        "    else:\n",
        "        return f\"# 無法為步驟 '{step_description}' 生成特定程式碼\"\n",
        "\n",
        "# 模擬的執行計畫\n",
        "execution_plan = [\n",
        "    \"步驟 1: 準備工作，確認環境\",\n",
        "    \"步驟 2: 讀取檔案 'input.txt'\",\n",
        "    \"步驟 3: 處理讀取的資料\",\n",
        "    \"步驟 4: 顯示處理後的結果\",\n",
        "    \"步驟 5: 完成任務\"\n",
        "]\n",
        "\n",
        "print(\"開始執行計畫:\")\n",
        "\n",
        "for i, step in enumerate(execution_plan):\n",
        "    print(f\"\\n執行 {step}...\")\n",
        "\n",
        "    # 根據步驟描述生成並模擬執行程式碼\n",
        "    generated_code = generate_code_for_step(step)\n",
        "    print(\"\\n生成的程式碼:\")\n",
        "    print(\"```python\")\n",
        "    print(generated_code)\n",
        "    print(\"```\")\n",
        "\n",
        "    # 在實際的AI系統中，這裡會執行生成的程式碼\n",
        "    # 在這個模擬範例中，我們只是印出程式碼並繼續下一個步驟\n",
        "\n",
        "print(\"\\n計畫執行完畢。\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def simulate_ai_code_generation(step_description):\n",
        "    \"\"\"\n",
        "    根據步驟描述模擬生成程式碼\n",
        "    \"\"\"\n",
        "    print(f\"  AI 代理正在為步驟 '{step_description}' 生成程式碼...\")\n",
        "    time.sleep(0.5) # 模擬生成時間\n",
        "    if \"讀取資料\" in step_description:\n",
        "        return \"print('模擬：讀取資料完成')\"\n",
        "    elif \"處理資料\" in step_description:\n",
        "        return \"processed_data = [x * 2 for x in range(5)]\\nprint(f'模擬：處理資料結果: {processed_data}')\"\n",
        "    elif \"儲存結果\" in step_description:\n",
        "        return \"print('模擬：結果已儲存到文件')\"\n",
        "    elif \"視覺化\" in step_description:\n",
        "         return \"print('模擬：生成圖表並顯示')\"\n",
        "    else:\n",
        "        return f\"# 模擬：無法為步驟 '{step_description}' 生成特定程式碼\"\n",
        "\n",
        "def simulate_code_execution(code_snippet):\n",
        "    \"\"\"\n",
        "    模擬執行程式碼\n",
        "    \"\"\"\n",
        "    print(\"  --- 開始模擬執行程式碼 ---\")\n",
        "    print(code_snippet)\n",
        "    # 在真實環境中，這裡會執行 code_snippet\n",
        "    # 在模擬中，我們直接執行生成的簡單程式碼\n",
        "    try:\n",
        "        exec(code_snippet)\n",
        "    except Exception as e:\n",
        "        print(f\"模擬執行錯誤: {e}\")\n",
        "    print(\"  --- 模擬執行程式碼結束 ---\")\n",
        "    time.sleep(0.5) # 模擬執行時間\n",
        "\n",
        "# 模擬的 AI 代理計畫\n",
        "ai_plan = [\n",
        "    \"步驟 1: 初始化環境\",\n",
        "    \"步驟 2: 從來源讀取資料\",\n",
        "    \"步驟 3: 處理讀取的資料\",\n",
        "    \"步驟 4: 將處理後的結果儲存起來\",\n",
        "    \"步驟 5: 視覺化處理後的資料\",\n",
        "    \"步驟 6: 完成整個流程\"\n",
        "]\n",
        "\n",
        "print(\"AI 代理啟動，開始執行計畫...\")\n",
        "\n",
        "for i, step in enumerate(ai_plan):\n",
        "    print(f\"\\n--- 執行計畫步驟 {i+1}: {step} ---\")\n",
        "\n",
        "    # 模擬 AI 生成程式碼\n",
        "    generated_code = simulate_ai_code_generation(step)\n",
        "\n",
        "    # 模擬 AI 執行程式碼\n",
        "    simulate_code_execution(generated_code)\n",
        "\n",
        "print(\"\\nAI 代理：所有計畫步驟執行完畢。\")"
      ],
      "metadata": {
        "id": "iDDt6lyHMYkm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "753cf74e"
      },
      "source": [
        "# Task\n",
        "Generate executable code that simulates an AI agent writing code to execute a project plan and workflow for a web-based application, supporting development on Android mobile devices. The code should reflect the plan provided, which involves server-side data processing, backend API development, frontend UI development, data fetching and display, implementing basic features, and deployment and testing. The code should be presented in a way that suggests it is being generated by an AI agent following the outlined steps."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3e17d232"
      },
      "source": [
        "## 前期準備 - 伺服器環境與資料處理\n",
        "\n",
        "### Subtask:\n",
        "設定一個伺服器環境來處理 Google Takeout 資料，並準備好資料供 Web App 使用。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9f247dac"
      },
      "source": [
        "**Reasoning**:\n",
        "The first few steps involve setting up a server environment and installing software, which are outside the scope of what can be done with Python code in a notebook. The next steps involve data processing and database interaction, which *can* be simulated in Python. I will generate code to simulate reading and processing JSON data from a Google Takeout-like structure and preparing it for a database, assuming the server and software are already set up.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cc50897c"
      },
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "# Simulate the file path on the server\n",
        "simulated_data_path = '/tmp/simulated_google_takeout.json'\n",
        "\n",
        "# Create a dummy JSON file to simulate Google Takeout data structure\n",
        "# In a real scenario, this would be the actual JSON file from Google Takeout\n",
        "dummy_data = [\n",
        "    {\n",
        "        \"header\": \"Google Search\",\n",
        "        \"title\": \"Searched for example\",\n",
        "        \"time\": \"2023-10-27T10:00:00.000Z\",\n",
        "        \"products\": [\"Search\"]\n",
        "    },\n",
        "    {\n",
        "        \"header\": \"YouTube\",\n",
        "        \"title\": \"Watched a video\",\n",
        "        \"time\": \"2023-10-27T10:05:00.000Z\",\n",
        "        \"products\": [\"YouTube\"]\n",
        "    }\n",
        "]\n",
        "\n",
        "with open(simulated_data_path, 'w') as f:\n",
        "    json.dump(dummy_data, f, indent=4)\n",
        "\n",
        "print(f\"Created simulated data file at: {simulated_data_path}\")\n",
        "\n",
        "# Step 3 & 4: Simulate reading, parsing, and processing the data\n",
        "processed_data = []\n",
        "try:\n",
        "    with open(simulated_data_path, 'r') as f:\n",
        "        takeout_data = json.load(f)\n",
        "\n",
        "    # Simulate processing: extract relevant fields and prepare for database insertion\n",
        "    for item in takeout_data:\n",
        "        processed_item = {\n",
        "            'activity_title': item.get('title'),\n",
        "            'activity_time': item.get('time'),\n",
        "            'product': ', '.join(item.get('products', []))\n",
        "        }\n",
        "        processed_data.append(processed_item)\n",
        "\n",
        "    print(\"\\nSimulated data processing completed. Processed data:\")\n",
        "    for item in processed_data:\n",
        "        print(item)\n",
        "\n",
        "    # Simulate database storage (in a real scenario, this would be DB insertion code)\n",
        "    print(\"\\nSimulating storage to a database...\")\n",
        "    # Example: INSERT INTO activities (activity_title, activity_time, product) VALUES (...)\n",
        "    print(\"Data is ready to be stored in a database.\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: Simulated data file not found at {simulated_data_path}\")\n",
        "except json.JSONDecodeError:\n",
        "    print(f\"Error: Could not decode JSON from {simulated_data_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred during data processing: {e}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bd865ae"
      },
      "source": [
        "## 後端開發 - 資料 api\n",
        "\n",
        "### Subtask:\n",
        "開發後端程式，建立 API 接口，讓前端可以透過網路請求獲取處理後的活動記錄資料。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3f88d6b"
      },
      "source": [
        "**Reasoning**:\n",
        "To develop the backend API, I will use Flask as it is a lightweight and easy-to-use framework suitable for this task. I will create a Flask application, define an endpoint `/api/activities`, read the previously processed data (simulated from the `/tmp/simulated_google_takeout.json` file), convert it to JSON, and return it as the response. This addresses steps 1, 2, 3, 4, and 5 of the instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fe39c352"
      },
      "source": [
        "from flask import Flask, jsonify\n",
        "import json\n",
        "import os\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Simulate the path where processed data would be stored or accessed\n",
        "simulated_data_path = '/tmp/simulated_google_takeout.json'\n",
        "\n",
        "@app.route('/api/activities', methods=['GET'])\n",
        "def get_activities():\n",
        "    \"\"\"\n",
        "    API endpoint to get processed activity data.\n",
        "    \"\"\"\n",
        "    processed_data = []\n",
        "    try:\n",
        "        # In a real application, this would be database query logic\n",
        "        with open(simulated_data_path, 'r') as f:\n",
        "            # Read the dummy data structure and simulate processing again\n",
        "            # In a real scenario, you would fetch already processed data from a DB\n",
        "            takeout_data = json.load(f)\n",
        "            for item in takeout_data:\n",
        "                 processed_item = {\n",
        "                    'activity_title': item.get('title'),\n",
        "                    'activity_time': item.get('time'),\n",
        "                    'product': ', '.join(item.get('products', []))\n",
        "                }\n",
        "                 processed_data.append(processed_item)\n",
        "\n",
        "        # Return the processed data as JSON\n",
        "        return jsonify(processed_data)\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        return jsonify({\"error\": \"Data file not found\"}), 404\n",
        "    except json.JSONDecodeError:\n",
        "        return jsonify({\"error\": \"Could not decode data file\"}), 500\n",
        "    except Exception as e:\n",
        "        return jsonify({\"error\": str(e)}), 500\n",
        "\n",
        "# To run this Flask app in a script, you'd typically use:\n",
        "# if __name__ == '__main__':\n",
        "#     app.run(debug=True)\n",
        "\n",
        "# Since this is an interactive notebook, we'll just define the app and endpoint.\n",
        "# Running the app directly here would block the notebook.\n",
        "print(\"Flask app and /api/activities endpoint defined.\")\n",
        "print(f\"Data will be read from {simulated_data_path}\")\n",
        "\n",
        "# You can test this endpoint if you run the app, e.g., using curl or a web browser\n",
        "# Example (if running the app): curl http://127.0.0.1:5000/api/activities"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8c98118"
      },
      "source": [
        "## 前端開發 - 使用者介面\n",
        "\n",
        "### Subtask:\n",
        "使用 HTML, CSS, JavaScript 或前端框架 (如 React, Vue, Angular) 開發網頁介面來顯示活動記錄。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8beda79b"
      },
      "source": [
        "**Reasoning**:\n",
        "Create the `index.html` file with the basic HTML structure, title, and a container div, and link the CSS and JavaScript files.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f54ab086"
      },
      "source": [
        "%%writefile index.html\n",
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "    <title>My Activity Tracker</title>\n",
        "    <link rel=\"stylesheet\" href=\"style.css\">\n",
        "</head>\n",
        "<body>\n",
        "    <div id=\"activity-container\">\n",
        "        <!-- Activity data will be loaded here -->\n",
        "    </div>\n",
        "    <script src=\"script.js\"></script>\n",
        "</body>\n",
        "</html>"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78039af5"
      },
      "source": [
        "**Reasoning**:\n",
        "Create the `style.css` file and add basic styling rules for the body and the activity container.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ec1c5e4"
      },
      "source": [
        "%%writefile style.css\n",
        "body {\n",
        "    font-family: sans-serif;\n",
        "    margin: 20px;\n",
        "}\n",
        "\n",
        "#activity-container {\n",
        "    border: 1px solid #ccc;\n",
        "    padding: 15px;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a68a4de1"
      },
      "source": [
        "**Reasoning**:\n",
        "Create the `script.js` file and add a simple console log statement to confirm it's linked correctly.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53c2dea3"
      },
      "source": [
        "%%writefile script.js\n",
        "console.log('Script loaded!');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e94b68cc"
      },
      "source": [
        "## 前端開發 - 資料獲取與顯示\n",
        "\n",
        "### Subtask:\n",
        "在前端程式中，呼叫後端 API 獲取資料，並將資料呈現在網頁上。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2b6039c"
      },
      "source": [
        "**Reasoning**:\n",
        "Modify the `script.js` file to fetch data from the backend API, parse the JSON response, create HTML elements for each activity, and append them to the `activity-container`. Also, include basic error handling.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5a571392"
      },
      "source": [
        "%%writefile script.js\n",
        "document.addEventListener('DOMContentLoaded', () => {\n",
        "    const activityContainer = document.getElementById('activity-container');\n",
        "\n",
        "    fetch('/api/activities')\n",
        "        .then(response => {\n",
        "            if (!response.ok) {\n",
        "                throw new Error(`HTTP error! status: ${response.status}`);\n",
        "            }\n",
        "            return response.json();\n",
        "        })\n",
        "        .then(data => {\n",
        "            console.log('Fetched data:', data);\n",
        "            if (data && data.length > 0) {\n",
        "                data.forEach(activity => {\n",
        "                    const activityDiv = document.createElement('div');\n",
        "                    activityDiv.classList.add('activity-item');\n",
        "\n",
        "                    const titleElement = document.createElement('p');\n",
        "                    titleElement.textContent = `Title: ${activity.activity_title}`;\n",
        "\n",
        "                    const timeElement = document.createElement('p');\n",
        "                    timeElement.textContent = `Time: ${activity.activity_time}`;\n",
        "\n",
        "                    const productElement = document.createElement('p');\n",
        "                    productElement.textContent = `Product: ${activity.product}`;\n",
        "\n",
        "                    activityDiv.appendChild(titleElement);\n",
        "                    activityDiv.appendChild(timeElement);\n",
        "                    activityDiv.appendChild(productElement);\n",
        "\n",
        "                    activityContainer.appendChild(activityDiv);\n",
        "                });\n",
        "            } else {\n",
        "                activityContainer.textContent = 'No activity data available.';\n",
        "            }\n",
        "        })\n",
        "        .catch(error => {\n",
        "            console.error('Error fetching activities:', error);\n",
        "            activityContainer.textContent = 'Failed to load activity data.';\n",
        "        });\n",
        "});"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1e637b5a"
      },
      "source": [
        "## 實作基本功能\n",
        "\n",
        "### Subtask:\n",
        "加入搜尋、篩選或分頁等基本功能，提升使用者體驗。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "493bd382"
      },
      "source": [
        "**Reasoning**:\n",
        "The goal is to add search functionality to the frontend. This involves modifying the HTML to include search input and button elements, and then modifying the JavaScript to handle the search logic, including fetching elements, adding an event listener, filtering data, clearing the container, and displaying filtered data. These steps are closely related and can be implemented in a single code block for efficiency.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cb7f195"
      },
      "source": [
        "%%writefile index.html\n",
        "<!DOCTYPE  html >\n",
        "< html >\n",
        "< head > < title >我的活動追蹤器</ title > < link rel = \"stylesheet\" href = \"style.css\" > </ head > < body > < div > < input type = \"text.css\" > </ head > < body > < div > < input type = \" text \" id = search - in ; >搜尋</ button > < button id = \"clear-button\" style = \"display: none;\" >清除搜尋</ button > </ div > < div id = \"activity-container\" > <!-- 活動資料會在此處載入 --> </ div > < script src = \"script. / < / body > html > / rc = \""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2260d940"
      },
      "source": [
        "**Reasoning**:\n",
        "The next steps involve modifying the `script.js` file to implement the search functionality. This includes getting references to the new HTML elements, adding an event listener to the search button, getting the input value, filtering the data, clearing the current display, and rendering the filtered data. Adding a clear button functionality is also part of the requirements. These steps can be combined into a single JavaScript code block.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "568f7cb8"
      },
      "source": [
        "%%writefile script.js\n",
        "document.addEventListener('DOMContentLoaded', () => {\n",
        "    const activityContainer = document.getElementById('activity-container');\n",
        "    const searchInput = document.getElementById('search-input');\n",
        "    const searchButton = document.getElementById('search-button');\n",
        "    const clearButton = document.getElementById('clear-button');\n",
        "    let allActivities = []; // Variable to store all fetched activities\n",
        "\n",
        "    // Function to render activities based on provided data\n",
        "    const renderActivities = (activitiesToRender) => {\n",
        "        activityContainer.innerHTML = ''; // Clear current content\n",
        "        if (activitiesToRender && activitiesToRender.length > 0) {\n",
        "            activitiesToRender.forEach(activity => {\n",
        "                const activityDiv = document.createElement('div');\n",
        "                activityDiv.classList.add('activity-item');\n",
        "\n",
        "                const titleElement = document.createElement('p');\n",
        "                titleElement.textContent = `Title: ${activity.activity_title}`;\n",
        "\n",
        "                const timeElement = document.createElement('p');\n",
        "                timeElement.textContent = `Time: ${activity.activity_time}`;\n",
        "\n",
        "                const productElement = document.createElement('p');\n",
        "                productElement.textContent = `Product: ${activity.product}`;\n",
        "\n",
        "                activityDiv.appendChild(titleElement);\n",
        "                activityDiv.appendChild(timeElement);\n",
        "                activityDiv.appendChild(productElement);\n",
        "\n",
        "                activityContainer.appendChild(activityDiv);\n",
        "            });\n",
        "        } else {\n",
        "            activityContainer.textContent = 'No activity data available.';\n",
        "        }\n",
        "    };\n",
        "\n",
        "    // Fetch data initially\n",
        "    fetch('/api/activities')\n",
        "        .then(response => {\n",
        "            if (!response.ok) {\n",
        "                throw new Error(`HTTP error! status: ${response.status}`);\n",
        "            }\n",
        "            return response.json();\n",
        "        })\n",
        "        .then(data => {\n",
        "            console.log('Fetched data:', data);\n",
        "            allActivities = data; // Store all fetched activities\n",
        "            renderActivities(allActivities); // Render all activities initially\n",
        "        })\n",
        "        .catch(error => {\n",
        "            console.error('Error fetching activities:', error);\n",
        "            activityContainer.textContent = 'Failed to load activity data.';\n",
        "        });\n",
        "\n",
        "    // Event listener for the search button\n",
        "    searchButton.addEventListener('click', () => {\n",
        "        const searchTerm = searchInput.value.toLowerCase();\n",
        "        const filteredActivities = allActivities.filter(activity =>\n",
        "            activity.activity_title.toLowerCase().includes(searchTerm) ||\n",
        "            activity.product.toLowerCase().includes(searchTerm)\n",
        "        );\n",
        "        renderActivities(filteredActivities);\n",
        "        clearButton.style.display = 'inline-block'; // Show clear button after search\n",
        "    });\n",
        "\n",
        "    // Event listener for clearing the search\n",
        "    clearButton.addEventListener('click', () => {\n",
        "        searchInput.value = ''; // Clear search input\n",
        "        renderActivities(allActivities); // Render all activities\n",
        "        clearButton.style.display = 'none'; // Hide clear button\n",
        "    });\n",
        "});"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "285f66cd"
      },
      "source": [
        "## 部署與測試\n",
        "\n",
        "### Subtask:\n",
        "將後端和前端程式部署到伺服器上，並在不同裝置和瀏覽器上進行測試。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32d5d924"
      },
      "source": [
        "**Reasoning**:\n",
        "Since actual deployment is not possible in this environment, I will use print statements and comments within a code block to describe the typical steps for deploying the backend and frontend, covering server setup, dependency installation, web server configuration, and communication between backend and frontend. I will also describe the testing process across different devices and browsers, including checking developer consoles.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49e1ad69"
      },
      "source": [
        "# This cell simulates the deployment and testing phase.\n",
        "# Actual deployment cannot be performed in this notebook environment.\n",
        "\n",
        "print(\"--- Simulating Deployment Phase ---\")\n",
        "\n",
        "# --- Backend Deployment (Flask App) ---\n",
        "print(\"\\nSimulating Backend Deployment:\")\n",
        "print(\"1.  **Prepare Server Environment:** Provision a server (e.g., a VPS, Heroku, AWS Elastic Beanstalk instance). Install necessary software (Python, pip, virtual environment).\")\n",
        "print(\"2.  **Transfer Code:** Copy your Flask application files to the server.\")\n",
        "print(\"3.  **Install Dependencies:** Navigate to the application directory on the server and install Python dependencies using pip:\")\n",
        "print(\"    # Example command:\")\n",
        "print(\"    # pip install -r requirements.txt\")\n",
        "print(\"4.  **Configure Production Server:** Use a production-ready web server gateway interface (WSGI) server like Gunicorn or uWSGI to run the Flask application.\")\n",
        "print(\"    # Example command (using Gunicorn):\")\n",
        "print(\"    # gunicorn --bind 0.0.0.0:5000 app:app\")\n",
        "print(\"5.  **Set up Web Server (Optional but Recommended):** Configure a web server like Nginx or Apache to act as a reverse proxy. This server will handle incoming requests, serve static frontend files, and forward API requests to the running Flask backend.\")\n",
        "print(\"    # Configuration steps involve defining server blocks/virtual hosts to point to your frontend files and proxying requests for /api/* to the backend WSGI server.\")\n",
        "print(\"6.  **Configure Environment Variables:** Set up any necessary environment variables on the server (e.g., database connection strings, secret keys).\")\n",
        "\n",
        "# --- Frontend Deployment (HTML, CSS, JS) ---\n",
        "print(\"\\nSimulating Frontend Deployment:\")\n",
        "print(\"1.  **Transfer Files:** Copy your index.html, style.css, script.js, and any other static frontend assets to the web server's designated directory for serving static files.\")\n",
        "print(\"    # If using Nginx/Apache as a reverse proxy, place these files in the directory configured in the server block.\")\n",
        "print(\"2.  **Ensure Correct Paths:** Verify that the links to CSS and JS files in your index.html are correct relative to the deployed location.\")\n",
        "\n",
        "# --- Ensuring Backend and Frontend Communication ---\n",
        "print(\"\\nEnsuring Communication:\")\n",
        "print(\"1.  **CORS Configuration:** If the frontend and backend are served from different origins (different domain, port, or protocol), configure Cross-Origin Resource Sharing (CORS) on the Flask backend to allow requests from the frontend origin.\")\n",
        "print(\"    # In Flask, you can use the Flask-CORS extension.\")\n",
        "print(\"    # Example (in your Flask app):\")\n",
        "print(\"    # from flask_cors import CORS\")\n",
        "print(\"    # CORS(app)\")\n",
        "print(\"2.  **API Endpoint URL:** Ensure the frontend's `fetch('/api/activities')` call is directed to the correct URL of the deployed backend API.\")\n",
        "print(\"    # If using a reverse proxy, the path /api/activities should be proxied to the backend.\")\n",
        "\n",
        "print(\"\\n--- Simulating Testing Phase ---\")\n",
        "\n",
        "# --- Testing on Different Devices and Browsers ---\n",
        "print(\"\\nSimulating Testing:\")\n",
        "print(\"1.  **Access Application:** Open a web browser on various devices (desktop, Android mobile) and navigate to the deployed application's URL.\")\n",
        "print(\"2.  **Functionality Testing:**\")\n",
        "print(\"    - Verify that the activity data loads and is displayed correctly.\")\n",
        "print(\"    - Test the search functionality with different keywords to ensure filtering works as expected.\")\n",
        "print(\"    - Check for any JavaScript errors in the browser's developer console (F12).\")\n",
        "print(\"3.  **Cross-Browser Testing:** Test the application on different browsers (Chrome, Firefox, Safari, Edge) on both desktop and mobile to ensure consistent rendering and functionality.\")\n",
        "print(\"    - Pay attention to layout, styling, and JavaScript execution.\")\n",
        "print(\"4.  **Responsiveness Testing:** Resize the browser window and test on mobile devices to ensure the layout adapts correctly to different screen sizes (if responsive design was implemented).\")\n",
        "print(\"5.  **Network Monitoring:** Use the browser's developer console (Network tab) to monitor the API calls (`/api/activities`) to ensure they are successful (status code 200) and the data is being transferred correctly.\")\n",
        "print(\"    - Check for slow response times or failed requests.\")\n",
        "print(\"6.  **Server Logs:** Monitor the server logs for the Flask application and the web server (Nginx/Apache) for any errors or warnings during testing.\")\n",
        "\n",
        "print(\"\\n--- Simulation Complete ---\")\n",
        "print(\"In a real scenario, based on testing results, you would debug and iterate on the code or deployment configuration.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42d6c029"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   Simulated the creation of a dummy Google Takeout JSON file and processed it to extract relevant activity data (title, time, products).\n",
        "*   Developed a simulated backend API using Flask with an endpoint `/api/activities` that reads and returns the processed data in JSON format.\n",
        "*   Created the basic frontend structure with `index.html`, `style.css`, and `script.js` files.\n",
        "*   Implemented frontend JavaScript code to fetch data from the simulated backend API and display it on the webpage.\n",
        "*   Added basic search functionality to the frontend, allowing users to filter activities by title or product.\n",
        "*   Simulated the deployment and testing process, outlining steps for deploying both backend and frontend components and testing on various devices and browsers.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   The current implementation uses simulated data and file-based storage. A critical next step is to integrate a real database (e.g., SQLite, PostgreSQL) to store and manage the processed Google Takeout data persistently.\n",
        "*   Enhance the frontend with more advanced features such as pagination, filtering by date or product type, and improved styling for better user experience. Implement responsive design to ensure the application is fully functional and user-friendly on Android mobile devices.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f252f0a1"
      },
      "source": [
        "## 後端開發 - 資料 api\n",
        "\n",
        "### Subtask:\n",
        "開發後端程式，建立 API 接口，讓前端可以透過網路請求獲取處理後的活動記錄資料。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6774533"
      },
      "source": [
        "**Reasoning**:\n",
        "To develop the backend API, I will use Flask as it is a lightweight and easy-to-use framework suitable for this task. I will create a Flask application, define an endpoint `/api/activities`, read the previously processed data (simulated from the `/tmp/simulated_google_takeout.json` file), convert it to JSON, and return it as the response. This addresses steps 1, 2, 3, 4, and 5 of the instructions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aeb260d"
      },
      "source": [
        "from flask import Flask, jsonify\n",
        "import json\n",
        "import os\n",
        "\n",
        "# Create a Flask application instance\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Simulate the path where processed data would be stored or accessed\n",
        "# In a real backend, this would likely be database interaction logic\n",
        "simulated_data_path = '/tmp/simulated_google_takeout.json'\n",
        "\n",
        "# Define an API endpoint\n",
        "@app.route('/api/activities', methods=['GET'])\n",
        "def get_activities():\n",
        "    \"\"\"\n",
        "    API endpoint to get processed activity data.\n",
        "    Reads from the simulated data file.\n",
        "    \"\"\"\n",
        "    processed_data = []\n",
        "    try:\n",
        "        # In a real application, this would be database query logic\n",
        "        # For this simulation, we read the dummy data file\n",
        "        with open(simulated_data_path, 'r') as f:\n",
        "            # Read the dummy data structure and simulate processing again\n",
        "            # In a real scenario, you would fetch already processed data from a DB\n",
        "            takeout_data = json.load(f)\n",
        "            for item in takeout_data:\n",
        "                 processed_item = {\n",
        "                    'activity_title': item.get('title'),\n",
        "                    'activity_time': item.get('time'),\n",
        "                    'product': ', '.join(item.get('products', [])) # Joining products if multiple\n",
        "                }\n",
        "                 processed_data.append(processed_item)\n",
        "\n",
        "        # Return the processed data as JSON\n",
        "        return jsonify(processed_data)\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        # Handle case where the simulated data file is not found\n",
        "        return jsonify({\"error\": \"Data file not found\"}), 404\n",
        "    except json.JSONDecodeError:\n",
        "        # Handle case where the simulated data file is not valid JSON\n",
        "        return jsonify({\"error\": \"Could not decode data file\"}), 500\n",
        "    except Exception as e:\n",
        "        # Handle any other exceptions during processing\n",
        "        return jsonify({\"error\": str(e)}), 500\n",
        "\n",
        "# To run this Flask app in a script, you'd typically use:\n",
        "# if __name__ == '__main__':\n",
        "#     app.run(debug=True)\n",
        "\n",
        "# Since this is an interactive notebook, we'll just define the app and endpoint.\n",
        "# Running the app directly here would block the notebook.\n",
        "print(\"Flask app and /api/activities endpoint defined.\")\n",
        "print(f\"Data will be read from {simulated_data_path}\")\n",
        "\n",
        "# You can test this endpoint if you run the app, e.g., using curl or a web browser\n",
        "# Example (if running the app): curl http://127.0.0.1:5000/api/activities"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "129ab48a"
      },
      "source": [
        "## 前端開發 - 使用者介面\n",
        "\n",
        "### Subtask:\n",
        "使用 HTML, CSS, JavaScript 或前端框架 (如 React, Vue, Angular) 開發網頁介面來顯示活動記錄。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8a4c009a"
      },
      "source": [
        "**Reasoning**:\n",
        "Create the `index.html` file with the basic HTML structure, title, and a container div, and link the CSS and JavaScript files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b80e6e41"
      },
      "source": [
        "%%writefile index.html\n",
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "    <title>My Activity Tracker</title>\n",
        "    <link rel=\"stylesheet\" href=\"style.css\">\n",
        "</head>\n",
        "<body>\n",
        "    <div id=\"activity-container\">\n",
        "        <!-- Activity data will be loaded here -->\n",
        "    </div>\n",
        "    <script src=\"script.js\"></script>\n",
        "</body>\n",
        "</html>"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1493cd3"
      },
      "source": [
        "**Reasoning**:\n",
        "Create the `style.css` file and add basic styling rules for the body and the activity container."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76ba1243"
      },
      "source": [
        "%%writefile style.css\n",
        "body {\n",
        "    font-family: sans-serif;\n",
        "    margin: 20px;\n",
        "}\n",
        "\n",
        "#activity-container {\n",
        "    border: 1px solid #ccc;\n",
        "    padding: 15px;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "be2f039d"
      },
      "source": [
        "**Reasoning**:\n",
        "Create the `script.js` file and add a simple console log statement to confirm it's linked correctly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ffd8fbb"
      },
      "source": [
        "%%writefile script.js\n",
        "console.log('Script loaded!');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75b2dda8"
      },
      "source": [
        "## 前端開發 - 資料獲取與顯示\n",
        "\n",
        "### Subtask:\n",
        "在前端程式中，呼叫後端 API 獲取資料，並將資料呈現在網頁上。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63724744"
      },
      "source": [
        "**Reasoning**:\n",
        "Modify the `script.js` file to fetch data from the backend API, parse the JSON response, create HTML elements for each activity, and append them to the `activity-container`. Also, include basic error handling."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bf6d764f"
      },
      "source": [
        "%%writefile script.js\n",
        "document.addEventListener('DOMContentLoaded', () => {\n",
        "    const activityContainer = document.getElementById('activity-container');\n",
        "\n",
        "    // Fetch data from the backend API\n",
        "    fetch('/api/activities')\n",
        "        .then(response => {\n",
        "            // Check if the request was successful\n",
        "            if (!response.ok) {\n",
        "                throw new Error(`HTTP error! status: ${response.status}`);\n",
        "            }\n",
        "            // Parse the JSON response\n",
        "            return response.json();\n",
        "        })\n",
        "        .then(data => {\n",
        "            console.log('Fetched data:', data); // Log the data to the console\n",
        "\n",
        "            // Check if data is an array and not empty\n",
        "            if (data && data.length > 0) {\n",
        "                // Iterate over the data and create HTML elements\n",
        "                data.forEach(activity => {\n",
        "                    const activityDiv = document.createElement('div');\n",
        "                    activityDiv.classList.add('activity-item'); // Add a class for potential styling\n",
        "\n",
        "                    const titleElement = document.createElement('p');\n",
        "                    titleElement.textContent = `Title: ${activity.activity_title}`;\n",
        "\n",
        "                    const timeElement = document.createElement('p');\n",
        "                    timeElement.textContent = `Time: ${activity.activity_time}`;\n",
        "\n",
        "                    const productElement = document.createElement('p');\n",
        "                    productElement.textContent = `Product: ${activity.product}`;\n",
        "\n",
        "                    // Append the elements to the activityDiv\n",
        "                    activityDiv.appendChild(titleElement);\n",
        "                    activityDiv.appendChild(timeElement);\n",
        "                    activityDiv.appendChild(productElement);\n",
        "\n",
        "                    // Append the activityDiv to the container\n",
        "                    activityContainer.appendChild(activityDiv);\n",
        "                });\n",
        "            } else {\n",
        "                // Display a message if no data is available\n",
        "                activityContainer.textContent = 'No activity data available.';\n",
        "            }\n",
        "        })\n",
        "        .catch(error => {\n",
        "            // Handle any errors during the fetch process\n",
        "            console.error('Error fetching activities:', error);\n",
        "            activityContainer.textContent = 'Failed to load activity data.';\n",
        "        });\n",
        "});"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a382c663"
      },
      "source": [
        "## 實作基本功能\n",
        "\n",
        "### Subtask:\n",
        "加入搜尋、篩選或分頁等基本功能，提升使用者體驗。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d868e945"
      },
      "source": [
        "**Reasoning**:\n",
        "The goal is to add search functionality to the frontend. This involves modifying the HTML to include search input and button elements, and then modifying the JavaScript to handle the search logic, including fetching elements, adding an event listener, filtering data, clearing the container, and displaying filtered data. These steps are closely related and can be implemented in a single code block for efficiency."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d25c9871"
      },
      "source": [
        "%%writefile index.html\n",
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "    <title>我的活動追蹤器</title>\n",
        "    <link rel=\"stylesheet\" href=\"style.css\">\n",
        "</head>\n",
        "<body>\n",
        "    <div>\n",
        "        <input type=\"text\" id=\"search-input\" placeholder=\"搜尋活動標題或產品...\">\n",
        "        <button id=\"search-button\">搜尋</button>\n",
        "        <button id=\"clear-button\" style=\"display: none;\">清除搜尋</button>\n",
        "    </div>\n",
        "    <div id=\"activity-container\">\n",
        "        <!-- 活動資料會在此處載入 -->\n",
        "    </div>\n",
        "    <script src=\"script.js\"></script>\n",
        "</body>\n",
        "</html>"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c90c4664"
      },
      "source": [
        "**Reasoning**:\n",
        "The next steps involve modifying the `script.js` file to implement the search functionality. This includes getting references to the new HTML elements, adding an event listener to the search button, getting the input value, filtering the data, clearing the current display, and rendering the filtered data. Adding a clear button functionality is also part of the requirements. These steps can be combined into a single JavaScript code block."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fc55857"
      },
      "source": [
        "%%writefile script.js\n",
        "document.addEventListener('DOMContentLoaded', () => {\n",
        "    const activityContainer = document.getElementById('activity-container');\n",
        "    const searchInput = document.getElementById('search-input');\n",
        "    const searchButton = document.getElementById('search-button');\n",
        "    const clearButton = document.getElementById('clear-button');\n",
        "    let allActivities = []; // Variable to store all fetched activities\n",
        "\n",
        "    // Function to render activities based on provided data\n",
        "    const renderActivities = (activitiesToRender) => {\n",
        "        activityContainer.innerHTML = ''; // Clear current content\n",
        "        if (activitiesToRender && activitiesToRender.length > 0) {\n",
        "            activitiesToRender.forEach(activity => {\n",
        "                const activityDiv = document.createElement('div');\n",
        "                activityDiv.classList.add('activity-item');\n",
        "\n",
        "                const titleElement = document.createElement('p');\n",
        "                titleElement.textContent = `Title: ${activity.activity_title}`;\n",
        "\n",
        "                const timeElement = document.createElement('p');\n",
        "                timeElement.textContent = `Time: ${activity.activity_time}`;\n",
        "\n",
        "                const productElement = document.createElement('p');\n",
        "                productElement.textContent = `Product: ${activity.product}`;\n",
        "\n",
        "                activityDiv.appendChild(titleElement);\n",
        "                activityDiv.appendChild(timeElement);\n",
        "                activityDiv.appendChild(productElement);\n",
        "\n",
        "                activityContainer.appendChild(activityDiv);\n",
        "            });\n",
        "        } else {\n",
        "            activityContainer.textContent = 'No activity data available.';\n",
        "        }\n",
        "    };\n",
        "\n",
        "    // Fetch data initially\n",
        "    fetch('/api/activities')\n",
        "        .then(response => {\n",
        "            if (!response.ok) {\n",
        "                throw new Error(`HTTP error! status: ${response.status}`);\n",
        "            }\n",
        "            return response.json();\n",
        "        })\n",
        "        .then(data => {\n",
        "            console.log('Fetched data:', data);\n",
        "            allActivities = data; // Store all fetched activities\n",
        "            renderActivities(allActivities); // Render all activities initially\n",
        "        })\n",
        "        .catch(error => {\n",
        "            console.error('Error fetching activities:', error);\n",
        "            activityContainer.textContent = 'Failed to load activity data.';\n",
        "        });\n",
        "\n",
        "    // Event listener for the search button\n",
        "    searchButton.addEventListener('click', () => {\n",
        "        const searchTerm = searchInput.value.toLowerCase();\n",
        "        const filteredActivities = allActivities.filter(activity =>\n",
        "            activity.activity_title.toLowerCase().includes(searchTerm) ||\n",
        "            activity.product.toLowerCase().includes(searchTerm)\n",
        "        );\n",
        "        renderActivities(filteredActivities);\n",
        "        clearButton.style.display = 'inline-block'; // Show clear button after search\n",
        "    });\n",
        "\n",
        "    // Event listener for clearing the search\n",
        "    clearButton.addEventListener('click', () => {\n",
        "        searchInput.value = ''; // Clear search input\n",
        "        renderActivities(allActivities); // Render all activities\n",
        "        clearButton.style.display = 'none'; // Hide clear button\n",
        "    });\n",
        "});"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95cdd20a"
      },
      "source": [
        "## 部署與測試\n",
        "\n",
        "### Subtask:\n",
        "將後端和前端程式部署到伺服器上，並在不同裝置和瀏覽器上進行測試。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cf5c754b"
      },
      "source": [
        "**Reasoning**:\n",
        "Since actual deployment is not possible in this environment, I will use print statements and comments within a code block to describe the typical steps for deploying the backend and frontend, covering server setup, dependency installation, web server configuration, and communication between backend and frontend. I will also describe the testing process across different devices and browsers, including checking developer consoles."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9112e66c"
      },
      "source": [
        "# This cell simulates the deployment and testing phase.\n",
        "# Actual deployment cannot be performed in this notebook environment.\n",
        "\n",
        "print(\"--- Simulating Deployment Phase ---\")\n",
        "\n",
        "# --- Backend Deployment (Flask App) ---\n",
        "print(\"\\nSimulating Backend Deployment:\")\n",
        "print(\"1.  **Prepare Server Environment:** Provision a server (e.g., a VPS, Heroku, AWS Elastic Beanstalk instance). Install necessary software (Python, pip, virtual environment).\")\n",
        "print(\"2.  **Transfer Code:** Copy your Flask application files to the server.\")\n",
        "print(\"3.  **Install Dependencies:** Navigate to the application directory on the server and install Python dependencies using pip:\")\n",
        "print(\"    # Example command:\")\n",
        "print(\"    # pip install -r requirements.txt\")\n",
        "print(\"4.  **Configure Production Server:** Use a production-ready web server gateway interface (WSGI) server like Gunicorn or uWSGI to run the Flask application.\")\n",
        "print(\"    # Example command (using Gunicorn):\")\n",
        "print(\"    # gunicorn --bind 0.0.0.0:5000 app:app\")\n",
        "print(\"5.  **Set up Web Server (Optional but Recommended):** Configure a web server like Nginx or Apache to act as a reverse proxy. This server will handle incoming requests, serve static frontend files, and forward API requests to the running Flask backend.\")\n",
        "print(\"    # Configuration steps involve defining server blocks/virtual hosts to point to your frontend files and proxying requests for /api/* to the backend WSGI server.\")\n",
        "print(\"6.  **Configure Environment Variables:** Set up any necessary environment variables on the server (e.g., database connection strings, secret keys).\")\n",
        "\n",
        "# --- Frontend Deployment (HTML, CSS, JS) ---\n",
        "print(\"\\nSimulating Frontend Deployment:\")\n",
        "print(\"1.  **Transfer Files:** Copy your index.html, style.css, script.js, and any other static frontend assets to the web server's designated directory for serving static files.\")\n",
        "print(\"    # If using Nginx/Apache as a reverse proxy, place these files in the directory configured in the server block.\")\n",
        "print(\"2.  **Ensure Correct Paths:** Verify that the links to CSS and JS files in your index.html are correct relative to the deployed location.\")\n",
        "\n",
        "# --- Ensuring Backend and Frontend Communication ---\n",
        "print(\"\\nEnsuring Communication:\")\n",
        "print(\"1.  **CORS Configuration:** If the frontend and backend are served from different origins (different domain, port, or protocol), configure Cross-Origin Resource Sharing (CORS) on the Flask backend to allow requests from the frontend origin.\")\n",
        "print(\"    # In Flask, you can use the Flask-CORS extension.\")\n",
        "print(\"    # Example (in your Flask app):\")\n",
        "print(\"    # from flask_cors import CORS\")\n",
        "print(\"    # CORS(app)\")\n",
        "print(\"2.  **API Endpoint URL:** Ensure the frontend's `fetch('/api/activities')` call is directed to the correct URL of the deployed backend API.\")\n",
        "print(\"    # If using a reverse proxy, the path /api/activities should be proxied to the backend.\")\n",
        "\n",
        "print(\"\\n--- Simulating Testing Phase ---\")\n",
        "\n",
        "# --- Testing on Different Devices and Browsers ---\n",
        "print(\"\\nSimulating Testing:\")\n",
        "print(\"1.  **Access Application:** Open a web browser on various devices (desktop, Android mobile) and navigate to the deployed application's URL.\")\n",
        "print(\"2.  **Functionality Testing:**\")\n",
        "print(\"    - Verify that the activity data loads and is displayed correctly.\")\n",
        "print(\"    - Test the search functionality with different keywords to ensure filtering works as expected.\")\n",
        "print(\"    - Check for any JavaScript errors in the browser's developer console (F12).\")\n",
        "print(\"3.  **Cross-Browser Testing:** Test the application on different browsers (Chrome, Firefox, Safari, Edge) on both desktop and mobile to ensure consistent rendering and functionality.\")\n",
        "print(\"    - Pay attention to layout, styling, and JavaScript execution.\")\n",
        "print(\"4.  **Responsiveness Testing:** Resize the browser window and test on mobile devices to ensure the layout adapts correctly to different screen sizes (if responsive design was implemented).\")\n",
        "print(\"5.  **Network Monitoring:** Use the browser's developer console (Network tab) to monitor the API calls (`/api/activities`) to ensure they are successful (status code 200) and the data is being transferred correctly.\")\n",
        "print(\"    - Check for slow response times or failed requests.\")\n",
        "print(\"6.  **Server Logs:** Monitor the server logs for the Flask application and the web server (Nginx/Apache) for any errors or warnings during testing.\")\n",
        "\n",
        "print(\"\\n--- Simulation Complete ---\")\n",
        "print(\"In a real scenario, based on testing results, you would debug and iterate on the code or deployment configuration.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c708ab3d"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   Simulated the creation of a dummy Google Takeout JSON file and processed it to extract relevant activity data (title, time, products).\n",
        "*   Developed a simulated backend API using Flask with an endpoint `/api/activities` that reads and returns the processed data in JSON format.\n",
        "*   Created the basic frontend structure with `index.html`, `style.css`, and `script.js` files.\n",
        "*   Implemented frontend JavaScript code to fetch data from the simulated backend API and display it on the webpage.\n",
        "*   Added basic search functionality to the frontend, allowing users to filter activities by title or product.\n",
        "*   Simulated the deployment and testing process, outlining steps for deploying both backend and frontend components and testing on various devices and browsers.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   The current implementation uses simulated data and file-based access in the API. A critical next step is to **integrate a real database** (e.g., SQLite, PostgreSQL) to store and manage the processed Google Takeout data persistently and efficiently for the backend API to query.\n",
        "*   Enhance the frontend with more advanced features such as **pagination**, **filtering by date or product type**, and **improved styling** for better user experience. Implement **responsive design** to ensure the application is fully functional and user-friendly on Android mobile devices and other screen sizes.\n",
        "*   Explore **deployment options**: Research and choose a suitable hosting provider or platform to deploy the Flask backend and the static frontend files, making the Web App accessible online."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8d0d61f9"
      },
      "source": [
        "# Install Flask and ngrok\n",
        "!pip install Flask flask-ngrok\n",
        "\n",
        "# Import necessary libraries\n",
        "from flask import Flask, jsonify\n",
        "from flask_ngrok import run_with_ngrok\n",
        "import json\n",
        "import os\n",
        "import threading\n",
        "import time\n",
        "\n",
        "# Create a Flask application instance\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Enable ngrok integration\n",
        "run_with_ngrok(app)\n",
        "\n",
        "# Simulate the path where processed data would be stored or accessed\n",
        "# In a real backend, this would likely be database interaction logic\n",
        "simulated_data_path = '/tmp/simulated_google_takeout.json'\n",
        "\n",
        "# Define an API endpoint\n",
        "@app.route('/api/activities', methods=['GET'])\n",
        "def get_activities():\n",
        "    \"\"\"\n",
        "    API endpoint to get processed activity data.\n",
        "    Reads from the simulated data file.\n",
        "    \"\"\"\n",
        "    processed_data = []\n",
        "    try:\n",
        "        # In a real application, this would be database query logic\n",
        "        # For this simulation, we read the dummy data file\n",
        "        with open(simulated_data_path, 'r') as f:\n",
        "            # Read the dummy data structure and simulate processing again\n",
        "            # In a real scenario, you would fetch already processed data from a DB\n",
        "            takeout_data = json.load(f)\n",
        "            for item in takeout_data:\n",
        "                 processed_item = {\n",
        "                    'activity_title': item.get('title'),\n",
        "                    'activity_time': item.get('time'),\n",
        "                    'product': ', '.join(item.get('products', [])) # Joining products if multiple\n",
        "                }\n",
        "                 processed_data.append(processed_item)\n",
        "\n",
        "        # Return the processed data as JSON\n",
        "        return jsonify(processed_data)\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        # Handle case where the simulated data file is not found\n",
        "        return jsonify({\"error\": \"Data file not found\"}), 404\n",
        "    except json.JSONDecodeError:\n",
        "        # Handle case where the simulated data file is not valid JSON\n",
        "        return jsonify({\"error\": \"Could not decode data file\"}), 500\n",
        "    except Exception as e:\n",
        "        # Handle any other exceptions during processing\n",
        "        return jsonify({\"error\": str(e)}), 500\n",
        "\n",
        "# Create the simulated data file before running the app\n",
        "# This ensures the data file exists when the Flask app tries to read it\n",
        "def create_simulated_data():\n",
        "    simulated_data_path = '/tmp/simulated_google_takeout.json'\n",
        "    dummy_data = [\n",
        "        {\n",
        "            \"header\": \"Google Search\",\n",
        "            \"title\": \"Searched for example\",\n",
        "            \"time\": \"2023-10-27T10:00:00.000Z\",\n",
        "            \"products\": [\"Search\"]\n",
        "        },\n",
        "        {\n",
        "            \"header\": \"YouTube\",\n",
        "            \"title\": \"Watched a video\",\n",
        "            \"time\": \"2023-10-27T10:05:00.000Z\",\n",
        "            \"products\": [\"YouTube\"]\n",
        "        }\n",
        "    ]\n",
        "    with open(simulated_data_path, 'w') as f:\n",
        "        json.dump(dummy_data, f, indent=4)\n",
        "    print(f\"Simulated data file created at: {simulated_data_path}\")\n",
        "\n",
        "# Create the data file before starting the Flask app\n",
        "create_simulated_data()\n",
        "\n",
        "# Run the Flask application with ngrok\n",
        "print(\"Starting Flask app with ngrok...\")\n",
        "app.run()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ac33e20"
      },
      "source": [
        "import threading\n",
        "import time\n",
        "import json\n",
        "import os\n",
        "from flask import Flask, jsonify\n",
        "\n",
        "# Create a Flask application instance (if not already defined)\n",
        "# We'll reuse the app instance if it exists from previous cells\n",
        "try:\n",
        "    app\n",
        "except NameError:\n",
        "    app = Flask(__name__)\n",
        "\n",
        "# --- REMOVED: run_with_ngrok(app) as we are using a separate thread for local testing ---\n",
        "\n",
        "# Simulate the path where processed data would be stored or accessed\n",
        "simulated_data_path = '/tmp/simulated_google_takeout.json'\n",
        "\n",
        "# Create the simulated data file before running the app\n",
        "# This ensures the data file exists when the Flask app tries to read it\n",
        "def create_simulated_data():\n",
        "    if not os.path.exists(simulated_data_path):\n",
        "        dummy_data = [\n",
        "            {\n",
        "                \"header\": \"Google Search\",\n",
        "                \"title\": \"Searched for example\",\n",
        "                \"time\": \"2023-10-27T10:00:00.000Z\",\n",
        "                \"products\": [\"Search\"]\n",
        "            },\n",
        "            {\n",
        "                \"header\": \"YouTube\",\n",
        "                \"title\": \"Watched a video\",\n",
        "                \"time\": \"2023-10-27T10:05:00.000Z\",\n",
        "                \"products\": [\"YouTube\"]\n",
        "            }\n",
        "        ]\n",
        "        with open(simulated_data_path, 'w') as f:\n",
        "            json.dump(dummy_data, f, indent=4)\n",
        "        print(f\"Simulated data file created at: {simulated_data_path}\")\n",
        "    else:\n",
        "        print(f\"Simulated data file already exists at: {simulated_data_path}\")\n",
        "\n",
        "# Define the API endpoint (if not already defined)\n",
        "# Check if the endpoint 'get_activities' already exists\n",
        "if 'get_activities' not in app.view_functions:\n",
        "    @app.route('/api/activities', methods=['GET'])\n",
        "    def get_activities():\n",
        "        \"\"\"\n",
        "        API endpoint to get processed activity data.\n",
        "        Reads from the simulated data file.\n",
        "        \"\"\"\n",
        "        processed_data = []\n",
        "        try:\n",
        "            with open(simulated_data_path, 'r') as f:\n",
        "                takeout_data = json.load(f)\n",
        "                for item in takeout_data:\n",
        "                     processed_item = {\n",
        "                        'activity_title': item.get('title'),\n",
        "                        'activity_time': item.get('time'),\n",
        "                        'product': ', '.join(item.get('products', []))\n",
        "                    }\n",
        "                     processed_data.append(processed_item)\n",
        "            return jsonify(processed_data)\n",
        "\n",
        "        except FileNotFoundError:\n",
        "            return jsonify({\"error\": \"Data file not found\"}), 404\n",
        "        except json.JSONDecodeError:\n",
        "            return jsonify({\"error\": \"Could not decode data file\"}), 500\n",
        "        except Exception as e:\n",
        "            return jsonify({\"error\": str(e)}), 500\n",
        "else:\n",
        "    print(\"API endpoint '/api/activities' already defined.\")\n",
        "\n",
        "\n",
        "# Function to run the Flask app\n",
        "def run_flask_app():\n",
        "    # Use a development server suitable for basic testing\n",
        "    # Now 'port' argument should be accepted\n",
        "    app.run(port=5000, debug=False)\n",
        "\n",
        "# Create the data file\n",
        "create_simulated_data()\n",
        "\n",
        "# Run the Flask app in a separate thread\n",
        "# Check if the thread is already running to avoid starting multiple threads\n",
        "if 'flask_thread' not in locals() or not flask_thread.is_alive():\n",
        "    flask_thread = threading.Thread(target=run_flask_app)\n",
        "    flask_thread.daemon = True # Allow the main thread to exit even if the Flask thread is running\n",
        "    flask_thread.start()\n",
        "    print(\"Flask app正在背景執行緒中啟動...\")\n",
        "    print(\"請等待片刻，然後執行下一個程式碼格來測試 API。\")\n",
        "else:\n",
        "    print(\"Flask app已經在背景執行緒中運行。\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2a4153c3"
      },
      "source": [
        "import requests\n",
        "import time\n",
        "\n",
        "# Give the Flask app a moment to start\n",
        "time.sleep(3)\n",
        "\n",
        "try:\n",
        "    # Make a GET request to the local Flask API endpoint\n",
        "    response = requests.get('http://127.0.0.1:5000/api/activities')\n",
        "\n",
        "    # Check if the request was successful (status code 200)\n",
        "    if response.status_code == 200:\n",
        "        # Print the JSON response\n",
        "        print(\"成功獲取 API 資料：\")\n",
        "        print(response.json())\n",
        "    else:\n",
        "        print(f\"API 請求失敗，狀態碼：{response.status_code}\")\n",
        "        print(\"回應內容：\")\n",
        "        print(response.text)\n",
        "\n",
        "except requests.exceptions.ConnectionError as e:\n",
        "    print(f\"無法連接到 Flask 應用程式。請確認前一個程式碼格已執行，並且 Flask 應用程式正在運行。錯誤：{e}\")\n",
        "except Exception as e:\n",
        "    print(f\"測試 API 時發生錯誤：{e}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cf94c2a2"
      },
      "source": [
        "# Task\n",
        "Integrate a database into the web application for persistent storage of processed Google Takeout data, enhance the frontend with features like pagination and filtering, and implement responsive design for Android mobile device compatibility, using Traditional Chinese for all output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ea7091f"
      },
      "source": [
        "## 資料庫規劃與設定\n",
        "\n",
        "### Subtask:\n",
        "設計資料庫綱要 (Schema)，並在後端程式中設定資料庫連接。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9e3e395a"
      },
      "source": [
        "**Reasoning**:\n",
        "I will create a Python script to define the database schema using SQLite, set up the database connection, create the table if it doesn't exist, and ensure the connection is handled properly. This addresses instructions 1, 2, 3, and 4 of the subtask.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d57c4181"
      },
      "source": [
        "import sqlite3\n",
        "import os\n",
        "\n",
        "# Define the database file path\n",
        "DATABASE_FILE = 'activities.db'\n",
        "\n",
        "# Define the database schema\n",
        "# id: INTEGER PRIMARY KEY AUTOINCREMENT\n",
        "# activity_title: TEXT\n",
        "# activity_time: TEXT (storing ISO 8601 formatted time strings)\n",
        "# product: TEXT\n",
        "DATABASE_SCHEMA = \"\"\"\n",
        "CREATE TABLE IF NOT EXISTS activities (\n",
        "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "    activity_title TEXT NOT NULL,\n",
        "    activity_time TEXT NOT NULL,\n",
        "    product TEXT\n",
        ");\n",
        "\"\"\"\n",
        "\n",
        "def create_database_and_table():\n",
        "    \"\"\"Creates the database file and the activities table if they don't exist.\"\"\"\n",
        "    conn = None\n",
        "    try:\n",
        "        conn = sqlite3.connect(DATABASE_FILE)\n",
        "        cursor = conn.cursor()\n",
        "        cursor.execute(DATABASE_SCHEMA)\n",
        "        conn.commit()\n",
        "        print(f\"資料庫 '{DATABASE_FILE}' 已準備就緒，活動記錄表格已建立或已存在。\")\n",
        "    except sqlite3.Error as e:\n",
        "        print(f\"資料庫操作錯誤: {e}\")\n",
        "    finally:\n",
        "        if conn:\n",
        "            conn.close()\n",
        "\n",
        "def get_db_connection():\n",
        "    \"\"\"Establishes and returns a database connection.\"\"\"\n",
        "    try:\n",
        "        conn = sqlite3.connect(DATABASE_FILE)\n",
        "        # Return rows as dictionary-like objects\n",
        "        conn.row_factory = sqlite3.Row\n",
        "        return conn\n",
        "    except sqlite3.Error as e:\n",
        "        print(f\"無法建立資料庫連線: {e}\")\n",
        "        return None\n",
        "\n",
        "# Call the function to create the database and table when the script runs\n",
        "create_database_and_table()\n",
        "\n",
        "# Example of how to get and close a connection (for demonstration)\n",
        "# In the actual Flask app, you would manage connections per request\n",
        "# conn = get_db_connection()\n",
        "# if conn:\n",
        "#     print(\"成功建立資料庫連線。\")\n",
        "#     conn.close()\n",
        "#     print(\"資料庫連線已關閉。\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dede6deb"
      },
      "source": [
        "**Reasoning**:\n",
        "The database schema is defined and the table creation logic is in place. The next step is to integrate this database connection and schema into the Flask backend application. This involves modifying the Flask app to use the `get_db_connection` function to interact with the database for the `/api/activities` endpoint, specifically to insert processed data (simulating the data loading step) and query data when the API is called. I will also modify the previous data processing step to insert data into the database instead of just printing it. This addresses the remaining parts of the subtask by integrating the database into the backend.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcb315f3"
      },
      "source": [
        "from flask import Flask, jsonify\n",
        "import json\n",
        "import os\n",
        "import sqlite3\n",
        "import threading\n",
        "import time\n",
        "\n",
        "# Reuse the existing Flask app instance if it exists\n",
        "try:\n",
        "    app\n",
        "except NameError:\n",
        "    app = Flask(__name__)\n",
        "\n",
        "# Database configuration (reusing definitions from the previous cell)\n",
        "DATABASE_FILE = 'activities.db'\n",
        "DATABASE_SCHEMA = \"\"\"\n",
        "CREATE TABLE IF NOT EXISTS activities (\n",
        "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "    activity_title TEXT NOT NULL,\n",
        "    activity_time TEXT NOT NULL,\n",
        "    product TEXT\n",
        ");\n",
        "\"\"\"\n",
        "\n",
        "def create_database_and_table():\n",
        "    \"\"\"Creates the database file and the activities table if they don't exist.\"\"\"\n",
        "    conn = None\n",
        "    try:\n",
        "        conn = sqlite3.connect(DATABASE_FILE)\n",
        "        cursor = conn.cursor()\n",
        "        cursor.execute(DATABASE_SCHEMA)\n",
        "        conn.commit()\n",
        "        print(f\"資料庫 '{DATABASE_FILE}' 已準備就緒，活動記錄表格已建立或已存在。\")\n",
        "    except sqlite3.Error as e:\n",
        "        print(f\"資料庫操作錯誤: {e}\")\n",
        "    finally:\n",
        "        if conn:\n",
        "            conn.close()\n",
        "\n",
        "def get_db_connection():\n",
        "    \"\"\"Establishes and returns a database connection.\"\"\"\n",
        "    try:\n",
        "        conn = sqlite3.connect(DATABASE_FILE)\n",
        "        conn.row_factory = sqlite3.Row # Return rows as dictionary-like objects\n",
        "        return conn\n",
        "    except sqlite3.Error as e:\n",
        "        print(f\"無法建立資料庫連線: {e}\")\n",
        "        return None\n",
        "\n",
        "# Create the database and table when the script starts\n",
        "create_database_and_table()\n",
        "\n",
        "# Simulate data processing and insertion into the database\n",
        "def insert_simulated_data():\n",
        "    \"\"\"Simulates processing dummy data and inserting it into the database.\"\"\"\n",
        "    dummy_data = [\n",
        "        {\n",
        "            \"header\": \"Google Search\",\n",
        "            \"title\": \"Searched for example\",\n",
        "            \"time\": \"2023-10-27T10:00:00.000Z\",\n",
        "            \"products\": [\"Search\"]\n",
        "        },\n",
        "        {\n",
        "            \"header\": \"YouTube\",\n",
        "            \"title\": \"Watched a video\",\n",
        "            \"time\": \"2023-10-27T10:05:00.000Z\",\n",
        "            \"products\": [\"YouTube\"]\n",
        "        },\n",
        "         {\n",
        "            \"header\": \"Google Maps\",\n",
        "            \"title\": \"Searched for a location\",\n",
        "            \"time\": \"2023-10-27T10:10:00.000Z\",\n",
        "            \"products\": [\"Maps\"]\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    conn = get_db_connection()\n",
        "    if conn:\n",
        "        cursor = conn.cursor()\n",
        "        # Clear existing data for simplicity in simulation\n",
        "        cursor.execute(\"DELETE FROM activities\")\n",
        "        conn.commit()\n",
        "        print(\"清除現有資料庫資料 (模擬)。\")\n",
        "\n",
        "        for item in dummy_data:\n",
        "            try:\n",
        "                processed_item = {\n",
        "                    'activity_title': item.get('title', '無標題'),\n",
        "                    'activity_time': item.get('time', '無時間資訊'),\n",
        "                    'product': ', '.join(item.get('products', [])) or '無產品資訊'\n",
        "                }\n",
        "                cursor.execute(\n",
        "                    \"INSERT INTO activities (activity_title, activity_time, product) VALUES (?, ?, ?)\",\n",
        "                    (processed_item['activity_title'], processed_item['activity_time'], processed_item['product'])\n",
        "                )\n",
        "            except sqlite3.Error as e:\n",
        "                print(f\"插入資料錯誤: {e}\")\n",
        "\n",
        "        conn.commit()\n",
        "        conn.close()\n",
        "        print(f\"已將 {len(dummy_data)} 筆模擬資料插入資料庫。\")\n",
        "    else:\n",
        "        print(\"無法連接資料庫，跳過資料插入。\")\n",
        "\n",
        "# Insert simulated data into the database\n",
        "insert_simulated_data()\n",
        "\n",
        "\n",
        "# Define the API endpoint to fetch data from the database\n",
        "# Check if the endpoint 'get_activities' already exists before defining\n",
        "if 'get_activities' not in app.view_functions:\n",
        "    @app.route('/api/activities', methods=['GET'])\n",
        "    def get_activities():\n",
        "        \"\"\"\n",
        "        API endpoint to get processed activity data from the database.\n",
        "        \"\"\"\n",
        "        conn = get_db_connection()\n",
        "        if conn:\n",
        "            try:\n",
        "                cursor = conn.cursor()\n",
        "                cursor.execute(\"SELECT activity_title, activity_time, product FROM activities\")\n",
        "                activities = [dict(row) for row in cursor.fetchall()] # Convert rows to dictionaries\n",
        "                return jsonify(activities)\n",
        "            except sqlite3.Error as e:\n",
        "                print(f\"查詢資料庫錯誤: {e}\")\n",
        "                return jsonify({\"error\": \"無法從資料庫獲取資料\"}), 500\n",
        "            finally:\n",
        "                conn.close()\n",
        "        else:\n",
        "            return jsonify({\"error\": \"無法連接資料庫\"}), 500\n",
        "else:\n",
        "    print(\"API endpoint '/api/activities' already defined.\")\n",
        "\n",
        "\n",
        "# Function to run the Flask app in a separate thread for notebook environment\n",
        "def run_flask_app():\n",
        "    # Use a development server suitable for basic testing\n",
        "    print(\"Flask app正在背景執行緒中啟動...\")\n",
        "    app.run(port=5000, debug=False, use_reloader=False) # use_reloader=False to prevent issues with threading\n",
        "\n",
        "# Check if the thread is already running to avoid starting multiple threads\n",
        "if 'flask_thread' not in locals() or not flask_thread.is_alive():\n",
        "    flask_thread = threading.Thread(target=run_flask_app)\n",
        "    flask_thread.daemon = True # Allow the main thread to exit even if the Flask thread is running\n",
        "    flask_thread.start()\n",
        "    print(\"請等待片刻，然後執行下一個程式碼格來測試 API。\")\n",
        "else:\n",
        "    print(\"Flask app已經在背景執行緒中運行。\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4d62a2d8"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous attempt to run the Flask app in a separate thread failed because `flask-ngrok` modifies the `app.run()` method and doesn't accept the `port` argument directly when `run_with_ngrok` is used. Since the goal is to test the API locally within the notebook environment without exposing it via ngrok, I need to remove the `run_with_ngrok(app)` call and run the Flask app's built-in development server in a separate thread, explicitly specifying the port. I will also update the print statements to reflect the local testing setup.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vWTDWnlbDEx"
      },
      "source": [
        "from flask import Flask, jsonify\n",
        "import json\n",
        "import os\n",
        "import sqlite3\n",
        "import threading\n",
        "import time\n",
        "\n",
        "# Reuse the existing Flask app instance if it exists\n",
        "try:\n",
        "    app\n",
        "except NameError:\n",
        "    app = Flask(__name__)\n",
        "\n",
        "# --- REMOVED: run_with_ngrok(app) as we are using a separate thread for local testing ---\n",
        "\n",
        "# Database configuration (reusing definitions from previous cells)\n",
        "DATABASE_FILE = 'activities.db'\n",
        "DATABASE_SCHEMA = \"\"\"\n",
        "CREATE TABLE IF NOT EXISTS activities (\n",
        "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "    activity_title TEXT NOT NULL,\n",
        "    activity_time TEXT NOT NULL,\n",
        "    product TEXT\n",
        ");\n",
        "\"\"\"\n",
        "\n",
        "def create_database_and_table():\n",
        "    \"\"\"Creates the database file and the activities table if they don't exist.\"\"\"\n",
        "    conn = None\n",
        "    try:\n",
        "        conn = sqlite3.connect(DATABASE_FILE)\n",
        "        cursor = conn.cursor()\n",
        "        cursor.execute(DATABASE_SCHEMA)\n",
        "        conn.commit()\n",
        "        print(f\"資料庫 '{DATABASE_FILE}' 已準備就緒，活動記錄表格已建立或已存在。\")\n",
        "    except sqlite3.Error as e:\n",
        "        print(f\"資料庫操作錯誤: {e}\")\n",
        "    finally:\n",
        "        if conn:\n",
        "            conn.close()\n",
        "\n",
        "def get_db_connection():\n",
        "    \"\"\"Establishes and returns a database connection.\"\"\"\n",
        "    try:\n",
        "        conn = sqlite3.connect(DATABASE_FILE)\n",
        "        conn.row_factory = sqlite3.Row # Return rows as dictionary-like objects\n",
        "        return conn\n",
        "    except sqlite3.Error as e:\n",
        "        print(f\"無法建立資料庫連線: {e}\")\n",
        "        return None\n",
        "\n",
        "# Create the database and table when the script starts\n",
        "create_database_and_table()\n",
        "\n",
        "# Simulate data processing and insertion into the database\n",
        "def insert_simulated_data():\n",
        "    \"\"\"Simulates processing dummy data and inserting it into the database.\"\"\"\n",
        "    dummy_data = [\n",
        "        {\n",
        "            \"header\": \"Google Search\",\n",
        "            \"title\": \"Searched for example\",\n",
        "            \"time\": \"2023-10-27T10:00:00.000Z\",\n",
        "            \"products\": [\"Search\"]\n",
        "        },\n",
        "        {\n",
        "            \"header\": \"YouTube\",\n",
        "            \"title\": \"Watched a video\",\n",
        "            \"time\": \"2023-10-27T10:05:00.000Z\",\n",
        "            \"products\": [\"YouTube\"]\n",
        "        },\n",
        "         {\n",
        "            \"header\": \"Google Maps\",\n",
        "            \"title\": \"Searched for a location\",\n",
        "            \"time\": \"2023-10-27T10:10:00.000Z\",\n",
        "            \"products\": [\"Maps\"]\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    conn = get_db_connection()\n",
        "    if conn:\n",
        "        cursor = conn.cursor()\n",
        "        # Clear existing data for simplicity in simulation\n",
        "        cursor.execute(\"DELETE FROM activities\")\n",
        "        conn.commit()\n",
        "        print(\"清除現有資料庫資料 (模擬)。\")\n",
        "\n",
        "        for item in dummy_data:\n",
        "            try:\n",
        "                processed_item = {\n",
        "                    'activity_title': item.get('title', '無標題'),\n",
        "                    'activity_time': item.get('time', '無時間資訊'),\n",
        "                    'product': ', '.join(item.get('products', [])) or '無產品資訊'\n",
        "                }\n",
        "                cursor.execute(\n",
        "                    \"INSERT INTO activities (activity_title, activity_time, product) VALUES (?, ?, ?)\",\n",
        "                    (processed_item['activity_title'], processed_item['activity_time'], processed_item['product'])\n",
        "                )\n",
        "            except sqlite3.Error as e:\n",
        "                print(f\"插入資料錯誤: {e}\")\n",
        "\n",
        "        conn.commit()\n",
        "        conn.close()\n",
        "        print(f\"已將 {len(dummy_data)} 筆模擬資料插入資料庫。\")\n",
        "    else:\n",
        "        print(\"無法連接資料庫，跳過資料插入。\")\n",
        "\n",
        "# Insert simulated data into the database\n",
        "insert_simulated_data()\n",
        "\n",
        "\n",
        "# Define the API endpoint to fetch data from the database\n",
        "# Check if the endpoint 'get_activities' already exists before defining\n",
        "if 'get_activities' not in app.view_functions:\n",
        "    @app.route('/api/activities', methods=['GET'])\n",
        "    def get_activities():\n",
        "        \"\"\"\n",
        "        API endpoint to get processed activity data from the database.\n",
        "        \"\"\"\n",
        "        conn = get_db_connection()\n",
        "        if conn:\n",
        "            try:\n",
        "                cursor = conn.cursor()\n",
        "                cursor.execute(\"SELECT activity_title, activity_time, product FROM activities\")\n",
        "                activities = [dict(row) for row in cursor.fetchall()] # Convert rows to dictionaries\n",
        "                return jsonify(activities)\n",
        "            except sqlite3.Error as e:\n",
        "                print(f\"查詢資料庫錯誤: {e}\")\n",
        "                return jsonify({\"error\": \"無法從資料庫獲取資料\"}), 500\n",
        "            finally:\n",
        "                conn.close()\n",
        "        else:\n",
        "            return jsonify({\"error\": \"無法連接資料庫\"}), 500\n",
        "else:\n",
        "    print(\"API endpoint '/api/activities' already defined.\")\n",
        "\n",
        "\n",
        "# Function to run the Flask app in a separate thread for notebook environment\n",
        "def run_flask_app():\n",
        "    # Use a development server suitable for basic testing\n",
        "    print(\"Flask app正在背景執行緒中啟動 (本地測試)...\")\n",
        "    # Explicitly use Flask's built-in development server\n",
        "    app.run(port=5000, debug=False, use_reloader=False)\n",
        "\n",
        "# Check if the thread is already running to avoid starting multiple threads\n",
        "if 'flask_thread' not in locals() or not flask_thread.is_alive():\n",
        "    flask_thread = threading.Thread(target=run_flask_app)\n",
        "    flask_thread.daemon = True # Allow the main thread to exit even if the Flask thread is running\n",
        "    flask_thread.start()\n",
        "    print(\"請等待片刻，然後執行下一個程式碼格來測試 API。\")\n",
        "else:\n",
        "    print(\"Flask app已經在背景執行緒中運行。\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fd1ae64"
      },
      "source": [
        "**Reasoning**:\n",
        "The error message `TypeError: run_with_ngrok.<locals>.new_run() got an unexpected keyword argument 'port'` indicates that the `run_with_ngrok` modification is still active on the `app.run()` method, even though the `run_with_ngrok(app)` call was removed in the previous cell. This is likely because the `app` object itself retains the modification from a previous execution of a cell that included `run_with_ngrok(app)`. To fix this, I need to explicitly redefine the Flask app instance *before* attempting to run it, ensuring a clean `app` object that hasn't been modified by `flask-ngrok`. I will redefine `app = Flask(__name__)` at the beginning of the cell to guarantee this.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGvb4aDqbGpc"
      },
      "source": [
        "from flask import Flask, jsonify\n",
        "import json\n",
        "import os\n",
        "import sqlite3\n",
        "import threading\n",
        "import time\n",
        "\n",
        "# Explicitly redefine the Flask app instance to ensure a clean state\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Database configuration (reusing definitions from previous cells)\n",
        "DATABASE_FILE = 'activities.db'\n",
        "DATABASE_SCHEMA = \"\"\"\n",
        "CREATE TABLE IF NOT EXISTS activities (\n",
        "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "    activity_title TEXT NOT NULL,\n",
        "    activity_time TEXT NOT NULL,\n",
        "    product TEXT\n",
        ");\n",
        "\"\"\"\n",
        "\n",
        "def create_database_and_table():\n",
        "    \"\"\"Creates the database file and the activities table if they don't exist.\"\"\"\n",
        "    conn = None\n",
        "    try:\n",
        "        conn = sqlite3.connect(DATABASE_FILE)\n",
        "        cursor = conn.cursor()\n",
        "        cursor.execute(DATABASE_SCHEMA)\n",
        "        conn.commit()\n",
        "        print(f\"資料庫 '{DATABASE_FILE}' 已準備就緒，活動記錄表格已建立或已存在。\")\n",
        "    except sqlite3.Error as e:\n",
        "        print(f\"資料庫操作錯誤: {e}\")\n",
        "    finally:\n",
        "        if conn:\n",
        "            conn.close()\n",
        "\n",
        "def get_db_connection():\n",
        "    \"\"\"Establishes and returns a database connection.\"\"\"\n",
        "    try:\n",
        "        conn = sqlite3.connect(DATABASE_FILE)\n",
        "        conn.row_factory = sqlite3.Row # Return rows as dictionary-like objects\n",
        "        return conn\n",
        "    except sqlite3.Error as e:\n",
        "        print(f\"無法建立資料庫連線: {e}\")\n",
        "        return None\n",
        "\n",
        "# Create the database and table when the script starts\n",
        "create_database_and_table()\n",
        "\n",
        "# Simulate data processing and insertion into the database\n",
        "def insert_simulated_data():\n",
        "    \"\"\"Simulates processing dummy data and inserting it into the database.\"\"\"\n",
        "    dummy_data = [\n",
        "        {\n",
        "            \"header\": \"Google Search\",\n",
        "            \"title\": \"Searched for example\",\n",
        "            \"time\": \"2023-10-27T10:00:00.000Z\",\n",
        "            \"products\": [\"Search\"]\n",
        "        },\n",
        "        {\n",
        "            \"header\": \"YouTube\",\n",
        "            \"title\": \"Watched a video\",\n",
        "            \"time\": \"2023-10-27T10:05:00.000Z\",\n",
        "            \"products\": [\"YouTube\"]\n",
        "        },\n",
        "         {\n",
        "            \"header\": \"Google Maps\",\n",
        "            \"title\": \"Searched for a location\",\n",
        "            \"time\": \"2023-10-27T10:10:00.000Z\",\n",
        "            \"products\": [\"Maps\"]\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    conn = get_db_connection()\n",
        "    if conn:\n",
        "        cursor = conn.cursor()\n",
        "        # Clear existing data for simplicity in simulation\n",
        "        cursor.execute(\"DELETE FROM activities\")\n",
        "        conn.commit()\n",
        "        print(\"清除現有資料庫資料 (模擬)。\")\n",
        "\n",
        "        for item in dummy_data:\n",
        "            try:\n",
        "                processed_item = {\n",
        "                    'activity_title': item.get('title', '無標題'),\n",
        "                    'activity_time': item.get('time', '無時間資訊'),\n",
        "                    'product': ', '.join(item.get('products', [])) or '無產品資訊'\n",
        "                }\n",
        "                cursor.execute(\n",
        "                    \"INSERT INTO activities (activity_title, activity_time, product) VALUES (?, ?, ?)\",\n",
        "                    (processed_item['activity_title'], processed_item['activity_time'], processed_item['product'])\n",
        "                )\n",
        "            except sqlite3.Error as e:\n",
        "                print(f\"插入資料錯誤: {e}\")\n",
        "\n",
        "        conn.commit()\n",
        "        conn.close()\n",
        "        print(f\"已將 {len(dummy_data)} 筆模擬資料插入資料庫。\")\n",
        "    else:\n",
        "        print(\"無法連接資料庫，跳過資料插入。\")\n",
        "\n",
        "# Insert simulated data into the database\n",
        "insert_simulated_data()\n",
        "\n",
        "\n",
        "# Define the API endpoint to fetch data from the database\n",
        "@app.route('/api/activities', methods=['GET'])\n",
        "def get_activities():\n",
        "    \"\"\"\n",
        "    API endpoint to get processed activity data from the database.\n",
        "    \"\"\"\n",
        "    conn = get_db_connection()\n",
        "    if conn:\n",
        "        try:\n",
        "            cursor = conn.cursor()\n",
        "            cursor.execute(\"SELECT activity_title, activity_time, product FROM activities\")\n",
        "            activities = [dict(row) for row in cursor.fetchall()] # Convert rows to dictionaries\n",
        "            return jsonify(activities)\n",
        "        except sqlite3.Error as e:\n",
        "            print(f\"查詢資料庫錯誤: {e}\")\n",
        "            return jsonify({\"error\": \"無法從資料庫獲取資料\"}), 500\n",
        "        finally:\n",
        "            conn.close()\n",
        "    else:\n",
        "        return jsonify({\"error\": \"無法連接資料庫\"}), 500\n",
        "\n",
        "\n",
        "# Function to run the Flask app in a separate thread for notebook environment\n",
        "def run_flask_app():\n",
        "    # Use a development server suitable for basic testing\n",
        "    print(\"Flask app正在背景執行緒中啟動 (本地測試)...\")\n",
        "    # Explicitly use Flask's built-in development server\n",
        "    app.run(port=5000, debug=False, use_reloader=False)\n",
        "\n",
        "# Check if the thread is already running to avoid starting multiple threads\n",
        "# Also check if the port is already in use before trying to start the app\n",
        "import socket\n",
        "\n",
        "def is_port_in_use(port):\n",
        "    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
        "        return s.connect_ex(('localhost', port)) == 0\n",
        "\n",
        "if 'flask_thread' not in locals() or not flask_thread.is_alive():\n",
        "    if not is_port_in_use(5000):\n",
        "        flask_thread = threading.Thread(target=run_flask_app)\n",
        "        flask_thread.daemon = True # Allow the main thread to exit even if the Flask thread is running\n",
        "        flask_thread.start()\n",
        "        print(\"請等待片刻，然後執行下一個程式碼格來測試 API。\")\n",
        "    else:\n",
        "        print(\"Port 5000 已經在使用中，無法啟動 Flask app。\")\n",
        "        print(\"請嘗試重新啟動執行階段，或手動停止佔用 Port 5000 的程序。\")\n",
        "else:\n",
        "    print(\"Flask app已經在背景執行緒中運行。\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3e820065"
      },
      "source": [
        "## 修改資料處理流程\n",
        "\n",
        "### Subtask:\n",
        "修改前期資料處理程式碼，將處理好的資料寫入 SQLite 資料庫。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "225ef534"
      },
      "source": [
        "**Reasoning**:\n",
        "Modify the existing data processing code to read the simulated JSON data and insert it into the SQLite database using the `get_db_connection` function, rather than writing to a simulated JSON file. This addresses steps 1, 2, 3, 4, and 5 of the instructions by integrating database insertion into the data processing flow and including error handling.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9d2333af"
      },
      "source": [
        "import json\n",
        "import os\n",
        "import sqlite3\n",
        "\n",
        "# Reusing the database file path and get_db_connection function from previous steps\n",
        "# DATABASE_FILE is defined in previous cells\n",
        "# get_db_connection() function is defined in previous cells\n",
        "\n",
        "# Simulate the path where raw Google Takeout JSON would be located initially\n",
        "simulated_raw_data_path = '/tmp/simulated_google_takeout_raw.json'\n",
        "\n",
        "# Create a dummy RAW JSON file to simulate the initial Google Takeout data structure\n",
        "# This file will be read by the processing script\n",
        "dummy_raw_data = [\n",
        "    {\n",
        "        \"header\": \"Google Search\",\n",
        "        \"title\": \"Searched for example\",\n",
        "        \"time\": \"2023-10-27T10:00:00.000Z\",\n",
        "        \"products\": [\"Search\"]\n",
        "    },\n",
        "    {\n",
        "        \"header\": \"YouTube\",\n",
        "        \"title\": \"Watched a video\",\n",
        "        \"time\": \"2023-10-27T10:05:00.000Z\",\n",
        "        \"products\": [\"YouTube\"]\n",
        "    },\n",
        "     {\n",
        "        \"header\": \"Google Maps\",\n",
        "        \"title\": \"Searched for a location\",\n",
        "        \"time\": \"2023-10-27T10:10:00.000Z\",\n",
        "        \"products\": [\"Maps\"]\n",
        "    }\n",
        "]\n",
        "\n",
        "# Create the dummy raw data file if it doesn't exist\n",
        "if not os.path.exists(simulated_raw_data_path):\n",
        "    with open(simulated_raw_data_path, 'w') as f:\n",
        "        json.dump(dummy_raw_data, f, indent=4)\n",
        "    print(f\"模擬原始資料檔案已建立於: {simulated_raw_data_path}\")\n",
        "else:\n",
        "    print(f\"模擬原始資料檔案已存在於: {simulated_raw_data_path}\")\n",
        "\n",
        "\n",
        "# Modified data processing function to read from the raw JSON and insert into DB\n",
        "def process_and_insert_data():\n",
        "    \"\"\"\n",
        "    讀取模擬的 Google Takeout 原始資料，處理後插入 SQLite 資料庫。\n",
        "    \"\"\"\n",
        "    conn = get_db_connection()\n",
        "    if conn is None:\n",
        "        print(\"無法建立資料庫連線，跳過資料處理及插入。\")\n",
        "        return\n",
        "\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    try:\n",
        "        # Read data from the simulated raw JSON file\n",
        "        with open(simulated_raw_data_path, 'r') as f:\n",
        "            takeout_data = json.load(f)\n",
        "\n",
        "        # Clear existing data for simplicity in simulation\n",
        "        cursor.execute(\"DELETE FROM activities\")\n",
        "        conn.commit()\n",
        "        print(\"清除現有資料庫資料 (在插入新資料前)。\")\n",
        "\n",
        "        inserted_count = 0\n",
        "        # Process data and insert into the database\n",
        "        for item in takeout_data:\n",
        "            try:\n",
        "                processed_item = {\n",
        "                    'activity_title': item.get('title', '無標題'),\n",
        "                    'activity_time': item.get('time', '無時間資訊'),\n",
        "                    'product': ', '.join(item.get('products', [])) or '無產品資訊'\n",
        "                }\n",
        "                cursor.execute(\n",
        "                    \"INSERT INTO activities (activity_title, activity_time, product) VALUES (?, ?, ?)\",\n",
        "                    (processed_item['activity_title'], processed_item['activity_time'], processed_item['product'])\n",
        "                )\n",
        "                inserted_count += 1\n",
        "            except sqlite3.Error as e:\n",
        "                print(f\"插入單筆資料錯誤: {e} - 資料: {processed_item}\")\n",
        "\n",
        "        conn.commit() # Commit the transaction after all insertions\n",
        "        print(f\"已成功處理並將 {inserted_count} 筆資料插入資料庫。\")\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"錯誤: 模擬原始資料檔案未找到於 {simulated_raw_data_path}\")\n",
        "    except json.JSONDecodeError:\n",
        "        print(f\"錯誤: 無法解析模擬原始資料檔案 {simulated_raw_data_path} 中的 JSON\")\n",
        "    except Exception as e:\n",
        "        print(f\"處理和插入資料時發生未知錯誤: {e}\")\n",
        "    finally:\n",
        "        conn.close() # Close the database connection\n",
        "\n",
        "# Execute the data processing and insertion function\n",
        "process_and_insert_data()\n",
        "\n",
        "# Verify the data in the database (optional verification step)\n",
        "def verify_data_in_db():\n",
        "    conn = get_db_connection()\n",
        "    if conn:\n",
        "        cursor = conn.cursor()\n",
        "        cursor.execute(\"SELECT COUNT(*) FROM activities\")\n",
        "        count = cursor.fetchone()[0]\n",
        "        print(f\"\\n資料庫中目前的活動記錄筆數: {count}\")\n",
        "        cursor.execute(\"SELECT * FROM activities LIMIT 5\") # Show first 5 records\n",
        "        rows = cursor.fetchall()\n",
        "        print(\"資料庫中前 5 筆記錄:\")\n",
        "        for row in rows:\n",
        "            print(dict(row)) # Print as dictionary\n",
        "        conn.close()\n",
        "\n",
        "verify_data_in_db()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ef2fc0ba"
      },
      "source": [
        "## 更新後端 api\n",
        "\n",
        "### Subtask:\n",
        "修改 `/api/activities` 接口，使其從 SQLite 資料庫中讀取資料，而不是從模擬檔案。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acff2b7d"
      },
      "source": [
        "**Reasoning**:\n",
        "Modify the `/api/activities` endpoint in the Flask application to fetch data from the SQLite database using the `get_db_connection` function, query the `activities` table for the required fields, convert the results to a list of dictionaries, and return them as a JSON response, ensuring proper error handling and database connection closure, and removing the old logic for reading from the simulated file. This addresses steps 1 through 9 of the instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d37b5daf"
      },
      "source": [
        "import sqlite3\n",
        "import os\n",
        "import json\n",
        "from flask import Flask, jsonify\n",
        "import threading\n",
        "import time\n",
        "import socket\n",
        "\n",
        "# Re-use the Flask app instance if it exists\n",
        "try:\n",
        "    app\n",
        "except NameError:\n",
        "    app = Flask(__name__)\n",
        "\n",
        "# Re-use database configuration and helper functions\n",
        "# DATABASE_FILE, DATABASE_SCHEMA, create_database_and_table, get_db_connection\n",
        "# are assumed to be defined in previous cells and available in the kernel\n",
        "\n",
        "# Ensure the database and table exist and is populated with simulated data\n",
        "create_database_and_table()\n",
        "# Only insert simulated data if the table is empty to avoid duplicates on re-execution\n",
        "conn_check = get_db_connection()\n",
        "if conn_check:\n",
        "    cursor_check = conn_check.cursor()\n",
        "    cursor_check.execute(\"SELECT COUNT(*) FROM activities\")\n",
        "    count = cursor_check.fetchone()[0]\n",
        "    conn_check.close()\n",
        "    if count == 0:\n",
        "        print(\"資料庫為空，插入模擬資料...\")\n",
        "        # Assuming insert_simulated_data() is defined in a previous cell\n",
        "        try:\n",
        "            insert_simulated_data()\n",
        "        except NameError:\n",
        "            print(\"錯誤: insert_simulated_data 函式未定義。請確認前一個程式碼格已成功執行。\")\n",
        "            # Define a minimal insert_simulated_data if not found, to prevent further errors\n",
        "            def insert_simulated_data():\n",
        "                 print(\"Simulated data insertion function placeholder executed.\")\n",
        "            insert_simulated_data() # Call the placeholder\n",
        "    else:\n",
        "        print(f\"資料庫中已有 {count} 筆資料，跳過模擬資料插入。\")\n",
        "\n",
        "\n",
        "# Modify the API endpoint to fetch data from the database\n",
        "# Check if the endpoint 'get_activities' already exists to avoid re-adding it\n",
        "if 'get_activities' in app.view_functions:\n",
        "    # If it exists, remove the old rule before adding the new one\n",
        "    # Note: This is a simplified approach for a notebook; proper Flask app structure is better\n",
        "    for rule in list(app.url_map.iter_rules()):\n",
        "        if rule.endpoint == 'get_activities':\n",
        "            app.url_map._rules.remove(rule)\n",
        "            break # Assuming only one rule per endpoint name\n",
        "\n",
        "@app.route('/api/activities', methods=['GET'])\n",
        "def get_activities():\n",
        "    \"\"\"\n",
        "    API endpoint to get processed activity data from the database.\n",
        "    Reads from the SQLite database.\n",
        "    \"\"\"\n",
        "    conn = get_db_connection()\n",
        "    if conn is None:\n",
        "        print(\"無法建立資料庫連線。\")\n",
        "        return jsonify({\"error\": \"無法連接資料庫\"}), 500\n",
        "\n",
        "    activities = []\n",
        "    try:\n",
        "        cursor = conn.cursor()\n",
        "        # Query the database for the required fields\n",
        "        cursor.execute(\"SELECT activity_title, activity_time, product FROM activities\")\n",
        "\n",
        "        # Fetch all rows and convert them to a list of dictionaries\n",
        "        # conn.row_factory = sqlite3.Row makes rows dictionary-like\n",
        "        activities = [dict(row) for row in cursor.fetchall()]\n",
        "\n",
        "        # Return the data as JSON\n",
        "        return jsonify(activities)\n",
        "\n",
        "    except sqlite3.Error as e:\n",
        "        print(f\"查詢資料庫錯誤: {e}\")\n",
        "        return jsonify({\"error\": \"無法從資料庫獲取資料\"}), 500\n",
        "    except Exception as e:\n",
        "        print(f\"獲取活動資料時發生未知錯誤: {e}\")\n",
        "        return jsonify({\"error\": str(e)}), 500\n",
        "    finally:\n",
        "        # Ensure the database connection is closed\n",
        "        if conn:\n",
        "            conn.close()\n",
        "            # print(\"資料庫連線已關閉。\") # Optional: uncomment for detailed logging\n",
        "\n",
        "# Function to run the Flask app in a separate thread for notebook environment\n",
        "# Re-using the function definition from previous cells\n",
        "def run_flask_app():\n",
        "    print(\"Flask app正在背景執行緒中啟動 (本地測試)...\")\n",
        "    # Explicitly use Flask's built-in development server\n",
        "    # use_reloader=False is important to prevent issues with threading in notebooks\n",
        "    app.run(port=5000, debug=False, use_reloader=False)\n",
        "\n",
        "# Check if the thread is already running and port is free before starting\n",
        "def is_port_in_use(port):\n",
        "    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
        "        try:\n",
        "            s.bind(('localhost', port))\n",
        "            return False # Port is free\n",
        "        except socket.error:\n",
        "            return True # Port is in use\n",
        "\n",
        "# Check if the thread is alive or if the port is in use\n",
        "# Use locals() to check for the thread variable in the current scope\n",
        "if 'flask_thread' not in locals() or not flask_thread.is_alive():\n",
        "    if not is_port_in_use(5000):\n",
        "        flask_thread = threading.Thread(target=run_flask_app)\n",
        "        flask_thread.daemon = True # Allow the main thread to exit even if the Flask thread is running\n",
        "        flask_thread.start()\n",
        "        print(\"Flask app正在背景執行緒中啟動...\")\n",
        "        print(\"請等待片刻，然後執行下一個程式碼格來測試 API。\")\n",
        "    else:\n",
        "        print(\"Port 5000 已經在使用中，無法啟動 Flask app。\")\n",
        "        print(\"請嘗試重新啟動執行階段，或手動停止佔用 Port 5000 的程序。\")\n",
        "else:\n",
        "    print(\"Flask app已經在背景執行緒中運行。\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36edb228"
      },
      "source": [
        "**Reasoning**:\n",
        "The traceback indicates that the `get_activities` endpoint is being registered again without being properly removed, causing an `AssertionError`. I need to ensure the existing rule for `/api/activities` with the endpoint name `get_activities` is removed from the Flask application's URL map before attempting to add the new rule and function definition. The previous attempt to remove the rule was insufficient. I will revise the code to more reliably remove the existing rule if it exists before adding the new one.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iNPbd2kbVcp"
      },
      "source": [
        "import sqlite3\n",
        "import os\n",
        "import json\n",
        "from flask import Flask, jsonify\n",
        "import threading\n",
        "import time\n",
        "import socket\n",
        "\n",
        "# Re-use the Flask app instance if it exists\n",
        "try:\n",
        "    app\n",
        "except NameError:\n",
        "    app = Flask(__name__)\n",
        "\n",
        "# Re-use database configuration and helper functions\n",
        "# DATABASE_FILE, DATABASE_SCHEMA, create_database_and_table, get_db_connection\n",
        "# are assumed to be defined in previous cells and available in the kernel\n",
        "\n",
        "# Ensure the database and table exist and is populated with simulated data\n",
        "create_database_and_table()\n",
        "# Only insert simulated data if the table is empty to avoid duplicates on re-execution\n",
        "conn_check = get_db_connection()\n",
        "if conn_check:\n",
        "    cursor_check = conn_check.cursor()\n",
        "    cursor_check.execute(\"SELECT COUNT(*) FROM activities\")\n",
        "    count = cursor_check.fetchone()[0]\n",
        "    conn_check.close()\n",
        "    if count == 0:\n",
        "        print(\"資料庫為空，插入模擬資料...\")\n",
        "        # Assuming insert_simulated_data() is defined in a previous cell\n",
        "        try:\n",
        "            insert_simulated_data()\n",
        "        except NameError:\n",
        "            print(\"錯誤: insert_simulated_data 函式未定義。請確認前一個程式碼格已成功執行。\")\n",
        "            # Define a minimal insert_simulated_data if not found, to prevent further errors\n",
        "            def insert_simulated_data():\n",
        "                 print(\"Simulated data insertion function placeholder executed.\")\n",
        "            insert_simulated_data() # Call the placeholder\n",
        "    else:\n",
        "        print(f\"資料庫中已有 {count} 筆資料，跳過模擬資料插入。\")\n",
        "\n",
        "# Modify the API endpoint to fetch data from the database\n",
        "# More robust check and removal of existing rule\n",
        "existing_rule = None\n",
        "for rule in app.url_map.iter_rules():\n",
        "    if rule.endpoint == 'get_activities' and '/api/activities' in rule.rule:\n",
        "        existing_rule = rule\n",
        "        break\n",
        "\n",
        "if existing_rule:\n",
        "    print(f\"移除現有路由 '{existing_rule.rule}'，端點名稱 '{existing_rule.endpoint}'\")\n",
        "    app.url_map._rules.remove(existing_rule)\n",
        "    # Also remove the endpoint from view_functions to be safe\n",
        "    if 'get_activities' in app.view_functions:\n",
        "         del app.view_functions['get_activities']\n",
        "\n",
        "\n",
        "@app.route('/api/activities', methods=['GET'])\n",
        "def get_activities():\n",
        "    \"\"\"\n",
        "    API endpoint to get processed activity data from the database.\n",
        "    Reads from the SQLite database.\n",
        "    \"\"\"\n",
        "    conn = get_db_connection()\n",
        "    if conn is None:\n",
        "        print(\"無法建立資料庫連線。\")\n",
        "        return jsonify({\"error\": \"無法連接資料庫\"}), 500\n",
        "\n",
        "    activities = []\n",
        "    try:\n",
        "        cursor = conn.cursor()\n",
        "        # Query the database for the required fields\n",
        "        cursor.execute(\"SELECT activity_title, activity_time, product FROM activities\")\n",
        "\n",
        "        # Fetch all rows and convert them to a list of dictionaries\n",
        "        # conn.row_factory = sqlite3.Row makes rows dictionary-like\n",
        "        activities = [dict(row) for row in cursor.fetchall()]\n",
        "\n",
        "        # Return the data as JSON\n",
        "        return jsonify(activities)\n",
        "\n",
        "    except sqlite3.Error as e:\n",
        "        print(f\"查詢資料庫錯誤: {e}\")\n",
        "        return jsonify({\"error\": \"無法從資料庫獲取資料\"}), 500\n",
        "    except Exception as e:\n",
        "        print(f\"獲取活動資料時發生未知錯誤: {e}\")\n",
        "        return jsonify({\"error\": str(e)}), 500\n",
        "    finally:\n",
        "        # Ensure the database connection is closed\n",
        "        if conn:\n",
        "            conn.close()\n",
        "            # print(\"資料庫連線已關閉。\") # Optional: uncomment for detailed logging\n",
        "\n",
        "\n",
        "# Function to run the Flask app in a separate thread for notebook environment\n",
        "# Re-using the function definition from previous cells\n",
        "def run_flask_app():\n",
        "    print(\"Flask app正在背景執行緒中啟動 (本地測試)...\")\n",
        "    # Explicitly use Flask's built-in development server\n",
        "    # use_reloader=False is important to prevent issues with threading in notebooks\n",
        "    app.run(port=5000, debug=False, use_reloader=False)\n",
        "\n",
        "# Check if the thread is already running and port is free before starting\n",
        "def is_port_in_use(port):\n",
        "    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
        "        try:\n",
        "            s.bind(('localhost', port))\n",
        "            return False # Port is free\n",
        "        except socket.error:\n",
        "            return True # Port is in use\n",
        "\n",
        "# Check if the thread is alive or if the port is in use\n",
        "# Use locals() to check for the thread variable in the current scope\n",
        "if 'flask_thread' not in locals() or not flask_thread.is_alive():\n",
        "    if not is_port_in_use(5000):\n",
        "        flask_thread = threading.Thread(target=run_flask_app)\n",
        "        flask_thread.daemon = True # Allow the main thread to exit even if the Flask thread is running\n",
        "        flask_thread.start()\n",
        "        print(\"Flask app正在背景執行緒中啟動...\")\n",
        "        print(\"請等待片刻，然後執行下一個程式碼格來測試 API。\")\n",
        "    else:\n",
        "        print(\"Port 5000 已經在使用中，無法啟動 Flask app。\")\n",
        "        print(\"請嘗試重新啟動執行階段，或手動停止佔用 Port 5000 的程序。\")\n",
        "else:\n",
        "    print(\"Flask app已經在背景執行緒中運行。\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0b0b6752"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   Successfully designed a SQLite database schema including `id`, `activity_title`, `activity_time`, and `product` fields for storing processed activity data.\n",
        "*   Implemented functions in Python using the `sqlite3` module to establish database connections (`get_db_connection`) and ensure the database file and `activities` table are created on application startup (`create_database_and_table`).\n",
        "*   Modified the data processing logic to read from a simulated raw data source and insert the processed activity information into the SQLite database. This involved clearing existing data (for simulation purposes) and using parameterized queries for insertion.\n",
        "*   Updated the Flask backend API endpoint `/api/activities` to retrieve data directly from the SQLite database, converting the results to a list of dictionaries before returning them as JSON.\n",
        "*   Addressed and resolved issues related to re-registering Flask routes in an interactive environment by explicitly removing the old route definition before adding the new one that interacts with the database.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   The current implementation clears the entire database table before inserting new simulated data. For a production environment, the data processing logic should be refined to handle incremental updates or append new data while avoiding duplicates.\n",
        "*   Implement pagination and filtering capabilities directly within the SQL queries executed by the `/api/activities` endpoint to efficiently handle larger datasets and improve frontend performance.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c76557c1"
      },
      "source": [
        "## 資料庫規劃與設定\n",
        "\n",
        "### Subtask:\n",
        "設計資料庫綱要 (Schema)，並在後端程式中設定資料庫連接。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67724eeb"
      },
      "source": [
        "**Reasoning**:\n",
        "I will create a Python script to define the database schema using SQLite, set up the database connection, create the table if it doesn't exist, and ensure the connection is handled properly. This addresses instructions 1, 2, 3, and 4 of the subtask."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a45aa23f"
      },
      "source": [
        "import sqlite3\n",
        "import os\n",
        "\n",
        "# Define the database file path\n",
        "DATABASE_FILE = 'activities.db'\n",
        "\n",
        "# Define the database schema\n",
        "# id: INTEGER PRIMARY KEY AUTOINCREMENT\n",
        "# activity_title: TEXT\n",
        "# activity_time: TEXT (storing ISO 8601 formatted time strings)\n",
        "# product: TEXT\n",
        "DATABASE_SCHEMA = \"\"\"\n",
        "CREATE TABLE IF NOT EXISTS activities (\n",
        "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "    activity_title TEXT NOT NULL,\n",
        "    activity_time TEXT NOT NULL,\n",
        "    product TEXT\n",
        ");\n",
        "\"\"\"\n",
        "\n",
        "def create_database_and_table():\n",
        "    \"\"\"Creates the database file and the activities table if they don't exist.\"\"\"\n",
        "    conn = None\n",
        "    try:\n",
        "        conn = sqlite3.connect(DATABASE_FILE)\n",
        "        cursor = conn.cursor()\n",
        "        cursor.execute(DATABASE_SCHEMA)\n",
        "        conn.commit()\n",
        "        print(f\"資料庫 '{DATABASE_FILE}' 已準備就緒，活動記錄表格已建立或已存在。\")\n",
        "    except sqlite3.Error as e:\n",
        "        print(f\"資料庫操作錯誤: {e}\")\n",
        "    finally:\n",
        "        if conn:\n",
        "            conn.close()\n",
        "\n",
        "def get_db_connection():\n",
        "    \"\"\"Establishes and returns a database connection.\"\"\"\n",
        "    try:\n",
        "        conn = sqlite3.connect(DATABASE_FILE)\n",
        "        # Return rows as dictionary-like objects\n",
        "        conn.row_factory = sqlite3.Row\n",
        "        return conn\n",
        "    except sqlite3.Error as e:\n",
        "        print(f\"無法建立資料庫連線: {e}\")\n",
        "        return None\n",
        "\n",
        "# Call the function to create the database and table when the script runs\n",
        "create_database_and_table()\n",
        "\n",
        "# Example of how to get and close a connection (for demonstration)\n",
        "# In the actual Flask app, you would manage connections per request\n",
        "# conn = get_db_connection()\n",
        "# if conn:\n",
        "#     print(\"成功建立資料庫連線。\")\n",
        "#     conn.close()\n",
        "#     print(\"資料庫連線已關閉。\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebb4666b"
      },
      "source": [
        "## 修改資料處理流程\n",
        "\n",
        "### Subtask:\n",
        "修改前期資料處理程式碼，將處理好的資料寫入 SQLite 資料庫。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2c21f924"
      },
      "source": [
        "**Reasoning**:\n",
        "Modify the existing data processing code to read the simulated JSON data and insert it into the SQLite database using the `get_db_connection` function, rather than writing to a simulated JSON file. This addresses steps 1, 2, 3, 4, and 5 of the instructions by integrating database insertion into the data processing flow and including error handling."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a92cfc9d"
      },
      "source": [
        "import json\n",
        "import os\n",
        "import sqlite3\n",
        "\n",
        "# Reusing the database file path and get_db_connection function from previous steps\n",
        "# DATABASE_FILE is defined in previous cells\n",
        "# get_db_connection() function is defined in previous cells\n",
        "\n",
        "# Simulate the path where raw Google Takeout JSON would be located initially\n",
        "simulated_raw_data_path = '/tmp/simulated_google_takeout_raw.json'\n",
        "\n",
        "# Create a dummy RAW JSON file to simulate the initial Google Takeout data structure\n",
        "# This file will be read by the processing script\n",
        "dummy_raw_data = [\n",
        "    {\n",
        "        \"header\": \"Google Search\",\n",
        "        \"title\": \"Searched for example\",\n",
        "        \"time\": \"2023-10-27T10:00:00.000Z\",\n",
        "        \"products\": [\"Search\"]\n",
        "    },\n",
        "    {\n",
        "        \"header\": \"YouTube\",\n",
        "        \"title\": \"Watched a video\",\n",
        "        \"time\": \"2023-10-27T10:05:00.000Z\",\n",
        "        \"products\": [\"YouTube\"]\n",
        "    },\n",
        "     {\n",
        "        \"header\": \"Google Maps\",\n",
        "        \"title\": \"Searched for a location\",\n",
        "        \"time\": \"2023-10-27T10:10:00.000Z\",\n",
        "        \"products\": [\"Maps\"]\n",
        "    }\n",
        "    # Add more dummy data if needed\n",
        "]\n",
        "\n",
        "# Create the dummy raw data file if it doesn't exist\n",
        "if not os.path.exists(simulated_raw_data_path):\n",
        "    with open(simulated_raw_data_path, 'w') as f:\n",
        "        json.dump(dummy_raw_data, f, indent=4)\n",
        "    print(f\"模擬原始資料檔案已建立於: {simulated_raw_data_path}\")\n",
        "else:\n",
        "    print(f\"模擬原始資料檔案已存在於: {simulated_raw_data_path}\")\n",
        "\n",
        "\n",
        "# Modified data processing function to read from the raw JSON and insert into DB\n",
        "def process_and_insert_data():\n",
        "    \"\"\"\n",
        "    讀取模擬的 Google Takeout 原始資料，處理後插入 SQLite 資料庫。\n",
        "    \"\"\"\n",
        "    conn = get_db_connection()\n",
        "    if conn is None:\n",
        "        print(\"無法建立資料庫連線，跳過資料處理及插入。\")\n",
        "        return\n",
        "\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    try:\n",
        "        # Read data from the simulated raw JSON file\n",
        "        with open(simulated_raw_data_path, 'r') as f:\n",
        "            takeout_data = json.load(f)\n",
        "\n",
        "        # Clear existing data for simplicity in simulation\n",
        "        # In a real application handling large data, you might use a different strategy\n",
        "        cursor.execute(\"DELETE FROM activities\")\n",
        "        conn.commit()\n",
        "        print(\"清除現有資料庫資料 (在插入新資料前)。\")\n",
        "\n",
        "        inserted_count = 0\n",
        "        # Process data and insert into the database\n",
        "        for item in takeout_data:\n",
        "            try:\n",
        "                processed_item = {\n",
        "                    'activity_title': item.get('title', '無標題'),\n",
        "                    'activity_time': item.get('time', '無時間資訊'),\n",
        "                    'product': ', '.join(item.get('products', [])) or '無產品資訊'\n",
        "                }\n",
        "                cursor.execute(\n",
        "                    \"INSERT INTO activities (activity_title, activity_time, product) VALUES (?, ?, ?)\",\n",
        "                    (processed_item['activity_title'], processed_item['activity_time'], processed_item['product'])\n",
        "                )\n",
        "                inserted_count += 1\n",
        "            except sqlite3.Error as e:\n",
        "                print(f\"插入單筆資料錯誤: {e} - 資料: {processed_item}\")\n",
        "\n",
        "        conn.commit() # Commit the transaction after all insertions\n",
        "        print(f\"已成功處理並將 {inserted_count} 筆資料插入資料庫。\")\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"錯誤: 模擬原始資料檔案未找到於 {simulated_raw_data_path}\")\n",
        "    except json.JSONDecodeError:\n",
        "        print(f\"錯誤: 無法解析模擬原始資料檔案 {simulated_raw_data_path} 中的 JSON\")\n",
        "    except Exception as e:\n",
        "        print(f\"處理和插入資料時發生未知錯誤: {e}\")\n",
        "    finally:\n",
        "        conn.close() # Close the database connection\n",
        "\n",
        "# Execute the data processing and insertion function\n",
        "process_and_insert_data()\n",
        "\n",
        "# Verify the data in the database (optional verification step)\n",
        "def verify_data_in_db():\n",
        "    conn = get_db_connection()\n",
        "    if conn:\n",
        "        cursor = conn.cursor()\n",
        "        cursor.execute(\"SELECT COUNT(*) FROM activities\")\n",
        "        count = cursor.fetchone()[0]\n",
        "        print(f\"\\n資料庫中目前的活動記錄筆數: {count}\")\n",
        "        cursor.execute(\"SELECT * FROM activities LIMIT 5\") # Show first 5 records\n",
        "        rows = cursor.fetchall()\n",
        "        print(\"資料庫中前 5 筆記錄:\")\n",
        "        for row in rows:\n",
        "            print(dict(row)) # Print as dictionary\n",
        "        conn.close()\n",
        "\n",
        "verify_data_in_db()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77bb1598"
      },
      "source": [
        "## 更新後端 api\n",
        "\n",
        "### Subtask:\n",
        "修改 `/api/activities` 接口，使其從 SQLite 資料庫中讀取資料，而不是從模擬檔案。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5872f40"
      },
      "source": [
        "**Reasoning**:\n",
        "Modify the `/api/activities` endpoint in the Flask application to fetch data from the SQLite database using the `get_db_connection` function, query the `activities` table for the required fields, convert the results to a list of dictionaries, and return them as a JSON response, ensuring proper error handling and database connection closure, and removing the old logic for reading from the simulated file. This addresses steps 1 through 9 of the instructions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fafb01f"
      },
      "source": [
        "import sqlite3\n",
        "import os\n",
        "import json\n",
        "from flask import Flask, jsonify\n",
        "import threading\n",
        "import time\n",
        "import socket\n",
        "\n",
        "# Re-use the Flask app instance if it exists\n",
        "try:\n",
        "    app\n",
        "except NameError:\n",
        "    app = Flask(__name__)\n",
        "\n",
        "# Re-use database configuration and helper functions\n",
        "# DATABASE_FILE, DATABASE_SCHEMA, create_database_and_table, get_db_connection\n",
        "# are assumed to be defined in previous cells and available in the kernel\n",
        "\n",
        "# Ensure the database and table exist and is populated with simulated data\n",
        "create_database_and_table()\n",
        "# Only insert simulated data if the table is empty to avoid duplicates on re-execution\n",
        "conn_check = get_db_connection()\n",
        "if conn_check:\n",
        "    cursor_check = conn_check.cursor()\n",
        "    cursor_check.execute(\"SELECT COUNT(*) FROM activities\")\n",
        "    count = cursor_check.fetchone()[0]\n",
        "    conn_check.close()\n",
        "    if count == 0:\n",
        "        print(\"資料庫為空，插入模擬資料...\")\n",
        "        # Assuming insert_simulated_data() is defined in a previous cell\n",
        "        try:\n",
        "            insert_simulated_data()\n",
        "        except NameError:\n",
        "            print(\"錯誤: insert_simulated_data 函式未定義。請確認前一個程式碼格已成功執行。\")\n",
        "            # Define a minimal insert_simulated_data if not found, to prevent further errors\n",
        "            def insert_simulated_data():\n",
        "                 print(\"Simulated data insertion function placeholder executed.\")\n",
        "            insert_simulated_data() # Call the placeholder\n",
        "    else:\n",
        "        print(f\"資料庫中已有 {count} 筆資料，跳過模擬資料插入。\")\n",
        "\n",
        "# Modify the API endpoint to fetch data from the database\n",
        "# Check if the endpoint 'get_activities' already exists to avoid re-adding it\n",
        "existing_rule = None\n",
        "for rule in app.url_map.iter_rules():\n",
        "    if rule.endpoint == 'get_activities' and '/api/activities' in rule.rule:\n",
        "        existing_rule = rule\n",
        "        break\n",
        "\n",
        "if existing_rule:\n",
        "    print(f\"移除現有路由 '{existing_rule.rule}'，端點名稱 '{existing_rule.endpoint}'\")\n",
        "    app.url_map._rules.remove(existing_rule)\n",
        "    # Also remove the endpoint from view_functions to be safe\n",
        "    if 'get_activities' in app.view_functions:\n",
        "         del app.view_functions['get_activities']\n",
        "\n",
        "\n",
        "@app.route('/api/activities', methods=['GET'])\n",
        "def get_activities():\n",
        "    \"\"\"\n",
        "    API endpoint to get processed activity data from the database.\n",
        "    Reads from the SQLite database.\n",
        "    \"\"\"\n",
        "    conn = get_db_connection()\n",
        "    if conn is None:\n",
        "        print(\"無法建立資料庫連線。\")\n",
        "        return jsonify({\"error\": \"無法連接資料庫\"}), 500\n",
        "\n",
        "    activities = []\n",
        "    try:\n",
        "        cursor = conn.cursor()\n",
        "        # Query the database for the required fields\n",
        "        cursor.execute(\"SELECT activity_title, activity_time, product FROM activities\")\n",
        "\n",
        "        # Fetch all rows and convert them to a list of dictionaries\n",
        "        # conn.row_factory = sqlite3.Row makes rows dictionary-like\n",
        "        activities = [dict(row) for row in cursor.fetchall()]\n",
        "\n",
        "        # Return the data as JSON\n",
        "        return jsonify(activities)\n",
        "\n",
        "    except sqlite3.Error as e:\n",
        "        print(f\"查詢資料庫錯誤: {e}\")\n",
        "        return jsonify({\"error\": \"無法從資料庫獲取資料\"}), 500\n",
        "    except Exception as e:\n",
        "        print(f\"獲取活動資料時發生未知錯誤: {e}\")\n",
        "        return jsonify({\"error\": str(e)}), 500\n",
        "    finally:\n",
        "        # Ensure the database connection is closed\n",
        "        if conn:\n",
        "            conn.close()\n",
        "            # print(\"資料庫連線已關閉。\") # Optional: uncomment for detailed logging\n",
        "\n",
        "\n",
        "# Function to run the Flask app in a separate thread for notebook environment\n",
        "# Re-using the function definition from previous cells\n",
        "def run_flask_app():\n",
        "    print(\"Flask app正在背景執行緒中啟動 (本地測試)...\")\n",
        "    # Explicitly use Flask's built-in development server\n",
        "    # use_reloader=False is important to prevent issues with threading in notebooks\n",
        "    app.run(port=5000, debug=False, use_reloader=False)\n",
        "\n",
        "# Check if the thread is already running and port is free before starting\n",
        "def is_port_in_use(port):\n",
        "    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
        "        try:\n",
        "            s.bind(('localhost', port))\n",
        "            return False # Port is free\n",
        "        except socket.error:\n",
        "            return True # Port is in use\n",
        "\n",
        "# Check if the thread is alive or if the port is in use\n",
        "# Use locals() to check for the thread variable in the current scope\n",
        "if 'flask_thread' not in locals() or not flask_thread.is_alive():\n",
        "    if not is_port_in_use(5000):\n",
        "        flask_thread = threading.Thread(target=run_flask_app)\n",
        "        flask_thread.daemon = True # Allow the main thread to exit even if the Flask thread is running\n",
        "        flask_thread.start()\n",
        "        print(\"Flask app正在背景執行緒中啟動...\")\n",
        "        print(\"請等待片刻，然後執行下一個程式碼格來測試 API。\")\n",
        "    else:\n",
        "        print(\"Port 5000 已經在使用中，無法啟動 Flask app。\")\n",
        "        print(\"請嘗試重新啟動執行階段，或手動停止佔用 Port 5000 的程序。\")\n",
        "else:\n",
        "    print(\"Flask app已經在背景執行緒中運行。\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6c008a55"
      },
      "source": [
        "## 前端開發 - 進階功能與響應式設計\n",
        "\n",
        "### Subtask:\n",
        "在前端網頁中實作分頁和篩選功能，並調整介面使其在 Android 行動裝置上具有良好的響應式設計。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ff6b587"
      },
      "source": [
        "**Reasoning**:\n",
        "Modify the `script.js` file to implement pagination and filtering on the frontend. This involves storing all fetched data, implementing functions to render data for the current page, handling pagination controls, and filtering data based on search input. I will also add basic responsive styling in `style.css`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ae875172"
      },
      "source": [
        "%%writefile script.js\n",
        "document.addEventListener('DOMContentLoaded', () => {\n",
        "    const activityContainer = document.getElementById('activity-container');\n",
        "    const searchInput = document.getElementById('search-input');\n",
        "    const searchButton = document.getElementById('search-button');\n",
        "    const clearButton = document.getElementById('clear-button');\n",
        "    const paginationDiv = document.createElement('div'); // Create a div for pagination controls\n",
        "    paginationDiv.id = 'pagination-controls';\n",
        "    activityContainer.parentNode.insertBefore(paginationDiv, activityContainer.nextSibling); // Insert pagination after container\n",
        "\n",
        "    let allActivities = []; // Variable to store all fetched activities\n",
        "    const itemsPerPage = 10; // Number of items to display per page\n",
        "    let currentPage = 1; // Current page number\n",
        "    let filteredActivities = []; // Variable to store filtered activities\n",
        "\n",
        "    // Function to render activities for the current page\n",
        "    const renderActivities = (activitiesToRender) => {\n",
        "        activityContainer.innerHTML = ''; // Clear current content\n",
        "        const startIndex = (currentPage - 1) * itemsPerPage;\n",
        "        const endIndex = startIndex + itemsPerPage;\n",
        "        const activitiesToDisplay = activitiesToRender.slice(startIndex, endIndex);\n",
        "\n",
        "        if (activitiesToDisplay && activitiesToDisplay.length > 0) {\n",
        "            activitiesToDisplay.forEach(activity => {\n",
        "                const activityDiv = document.createElement('div');\n",
        "                activityDiv.classList.add('activity-item');\n",
        "\n",
        "                const titleElement = document.createElement('h3'); // Use h3 for title\n",
        "                titleElement.textContent = activity.activity_title;\n",
        "\n",
        "                const timeElement = document.createElement('p');\n",
        "                // Format time for better readability (optional)\n",
        "                try {\n",
        "                    const date = new Date(activity.activity_time);\n",
        "                    timeElement.textContent = `時間: ${date.toLocaleString()}`;\n",
        "                } catch (e) {\n",
        "                    timeElement.textContent = `時間: ${activity.activity_time}`;\n",
        "                }\n",
        "\n",
        "\n",
        "                const productElement = document.createElement('p');\n",
        "                productElement.textContent = `產品: ${activity.product}`;\n",
        "\n",
        "                activityDiv.appendChild(titleElement);\n",
        "                activityDiv.appendChild(timeElement);\n",
        "                activityDiv.appendChild(productElement);\n",
        "\n",
        "                activityContainer.appendChild(activityDiv);\n",
        "            });\n",
        "        } else {\n",
        "            activityContainer.textContent = '沒有活動資料可顯示。';\n",
        "        }\n",
        "    };\n",
        "\n",
        "    // Function to render pagination controls\n",
        "    const renderPaginationControls = (activitiesToRender) => {\n",
        "        paginationDiv.innerHTML = ''; // Clear existing controls\n",
        "        const totalPages = Math.ceil(activitiesToRender.length / itemsPerPage);\n",
        "\n",
        "        if (totalPages > 1) {\n",
        "            const prevButton = document.createElement('button');\n",
        "            prevButton.textContent = '上一頁';\n",
        "            prevButton.disabled = currentPage === 1;\n",
        "            prevButton.addEventListener('click', () => {\n",
        "                currentPage--;\n",
        "                renderActivities(activitiesToRender);\n",
        "                renderPaginationControls(activitiesToRender);\n",
        "            });\n",
        "            paginationDiv.appendChild(prevButton);\n",
        "\n",
        "            const pageInfo = document.createElement('span');\n",
        "            pageInfo.textContent = ` 第 ${currentPage} / ${totalPages} 頁 `;\n",
        "            paginationDiv.appendChild(pageInfo);\n",
        "\n",
        "            const nextButton = document.createElement('button');\n",
        "            nextButton.textContent = '下一頁';\n",
        "            nextButton.disabled = currentPage === totalPages;\n",
        "            nextButton.addEventListener('click', () => {\n",
        "                currentPage++;\n",
        "                renderActivities(activitiesToRender);\n",
        "                renderPaginationControls(activitiesToRender);\n",
        "            });\n",
        "            paginationDiv.appendChild(nextButton);\n",
        "        }\n",
        "    };\n",
        "\n",
        "\n",
        "    // Fetch data initially\n",
        "    fetch('/api/activities')\n",
        "        .then(response => {\n",
        "            if (!response.ok) {\n",
        "                throw new Error(`HTTP error! status: ${response.status}`);\n",
        "            }\n",
        "            return response.json();\n",
        "        })\n",
        "        .then(data => {\n",
        "            console.log('Fetched data:', data);\n",
        "            allActivities = data; // Store all fetched activities\n",
        "            filteredActivities = data; // Initially, filtered data is all data\n",
        "            currentPage = 1; // Reset to first page\n",
        "            renderActivities(filteredActivities); // Render initial data\n",
        "            renderPaginationControls(filteredActivities); // Render initial pagination\n",
        "        })\n",
        "        .catch(error => {\n",
        "            console.error('Error fetching activities:', error);\n",
        "            activityContainer.textContent = '載入活動資料失敗。';\n",
        "        });\n",
        "\n",
        "    // Event listener for the search button\n",
        "    searchButton.addEventListener('click', () => {\n",
        "        const searchTerm = searchInput.value.toLowerCase();\n",
        "        filteredActivities = allActivities.filter(activity =>\n",
        "            (activity.activity_title && activity.activity_title.toLowerCase().includes(searchTerm)) ||\n",
        "            (activity.product && activity.product.toLowerCase().includes(searchTerm))\n",
        "        );\n",
        "        currentPage = 1; // Reset to first page after search\n",
        "        renderActivities(filteredActivities);\n",
        "        renderPaginationControls(filteredActivities);\n",
        "        clearButton.style.display = 'inline-block'; // Show clear button after search\n",
        "    });\n",
        "\n",
        "    // Event listener for clearing the search\n",
        "    clearButton.addEventListener('click', () => {\n",
        "        searchInput.value = ''; // Clear search input\n",
        "        filteredActivities = allActivities; // Reset filtered data to all data\n",
        "        currentPage = 1; // Reset to first page\n",
        "        renderActivities(filteredActivities); // Render all activities\n",
        "        renderPaginationControls(filteredActivities); // Render pagination for all activities\n",
        "        clearButton.style.display = 'none'; // Hide clear button\n",
        "    });\n",
        "\n",
        "    // Optional: Allow searching by pressing Enter key in the input field\n",
        "    searchInput.addEventListener('keypress', (event) => {\n",
        "        if (event.key === 'Enter') {\n",
        "            event.preventDefault(); // Prevent form submission\n",
        "            searchButton.click(); // Trigger the search button click\n",
        "        }\n",
        "    });\n",
        "});"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ce3fba0"
      },
      "source": [
        "%%writefile style.css\n",
        "body {\n",
        "    font-family: sans-serif;\n",
        "    margin: 20px;\n",
        "    line-height: 1.6; /* Improve readability */\n",
        "}\n",
        "\n",
        "#activity-container {\n",
        "    border: 1px solid #ccc;\n",
        "    padding: 15px;\n",
        "    margin-top: 20px; /* Add some space above the container */\n",
        "}\n",
        "\n",
        ".activity-item {\n",
        "    border-bottom: 1px solid #eee; /* Separator for activity items */\n",
        "    padding: 10px 0;\n",
        "    margin-bottom: 10px;\n",
        "}\n",
        "\n",
        ".activity-item:last-child {\n",
        "    border-bottom: none; /* Remove border for the last item */\n",
        "}\n",
        "\n",
        ".activity-item h3 {\n",
        "    margin-top: 0;\n",
        "    margin-bottom: 5px;\n",
        "    color: #333;\n",
        "}\n",
        "\n",
        ".activity-item p {\n",
        "    margin: 5px 0;\n",
        "    color: #666;\n",
        "    font-size: 0.9em;\n",
        "}\n",
        "\n",
        "#pagination-controls {\n",
        "    margin-top: 20px;\n",
        "    text-align: center; /* Center pagination controls */\n",
        "}\n",
        "\n",
        "#pagination-controls button {\n",
        "    margin: 0 5px;\n",
        "    padding: 8px 15px;\n",
        "    cursor: pointer;\n",
        "}\n",
        "\n",
        "/* Basic Responsive Design */\n",
        "@media (max-width: 600px) {\n",
        "    body {\n",
        "        margin: 10px; /* Reduce margin on smaller screens */\n",
        "    }\n",
        "\n",
        "    #activity-container {\n",
        "        padding: 10px; /* Reduce padding */\n",
        "    }\n",
        "\n",
        "    #pagination-controls button {\n",
        "        padding: 5px 10px; /* Smaller buttons */\n",
        "        font-size: 0.9em;\n",
        "    }\n",
        "\n",
        "    #pagination-controls span {\n",
        "         font-size: 0.9em;\n",
        "    }\n",
        "\n",
        "    .activity-item h3 {\n",
        "        font-size: 1em; /* Adjust font size */\n",
        "    }\n",
        "\n",
        "    .activity-item p {\n",
        "        font-size: 0.8em; /* Adjust font size */\n",
        "    }\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7105b091"
      },
      "source": [
        "## 部署與測試\n",
        "\n",
        "### Subtask:\n",
        "將後端和前端程式部署到伺服器上，並在不同裝置和瀏覽器上進行測試。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ce6ae29"
      },
      "source": [
        "**Reasoning**:\n",
        "Since actual deployment is not possible in this environment, I will use print statements and comments within a code block to describe the typical steps for deploying the backend and frontend, covering server setup, dependency installation, web server configuration, and communication between backend and frontend. I will also describe the testing process across different devices and browsers, including checking developer consoles."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ea404457"
      },
      "source": [
        "# This cell simulates the deployment and testing phase.\n",
        "# Actual deployment cannot be performed in this notebook environment.\n",
        "\n",
        "print(\"--- 模擬部署階段 ---\")\n",
        "\n",
        "# --- 後端部署 (Flask 應用程式) ---\n",
        "print(\"\\n模擬後端部署:\")\n",
        "print(\"1.  **準備伺服器環境：** 佈建伺服器 (例如：VPS、Heroku、AWS Elastic Beanstalk 實例)。安裝必要的軟體 (Python, pip, 虛擬環境)。\")\n",
        "print(\"2.  **傳輸程式碼：** 將您的 Flask 應用程式檔案複製到伺服器。\")\n",
        "print(\"3.  **安裝依賴項：** 在伺服器上導航到應用程式目錄並使用 pip 安裝 Python 依賴項：\")\n",
        "print(\"    # 範例指令：\")\n",
        "print(\"    # pip install -r requirements.txt\")\n",
        "print(\"4.  **配置生產伺服器：** 使用生產環境就緒的 Web 伺服器網關介面 (WSGI) 伺服器，例如 Gunicorn 或 uWSGI 來運行 Flask 應用程式。\")\n",
        "print(\"    # 範例指令 (使用 Gunicorn)：\")\n",
        "print(\"    # gunicorn --bind 0.0.0.0:5000 app:app\")\n",
        "print(\"5.  **設定 Web 伺服器 (可選但建議)：** 配置 Web 伺服器，例如 Nginx 或 Apache，作為反向代理。此伺服器將處理傳入請求、提供靜態前端檔案，並將 API 請求轉發到運行的 Flask 後端。\")\n",
        "print(\"    # 配置步驟包括定義伺服器區塊/虛擬主機以指向您的前端檔案，並將 /api/* 的請求代理到後端 WSGI 伺服器。\")\n",
        "print(\"6.  **配置環境變數：** 在伺服器上設定任何必要的環境變數 (例如：資料庫連線字串、密鑰)。\")\n",
        "\n",
        "# --- 前端部署 (HTML, CSS, JS) ---\n",
        "print(\"\\n模擬前端部署:\")\n",
        "print(\"1.  **傳輸檔案：** 將您的 index.html, style.css, script.js 和任何其他靜態前端資產複製到 Web 伺服器用於提供靜態檔案的指定目錄。\")\n",
        "print(\"    # 如果使用 Nginx/Apache 作為反向代理，請將這些檔案放在伺服器區塊中配置的目錄下。\")\n",
        "print(\"2.  **確保路徑正確：** 驗證 index.html 中指向 CSS 和 JS 檔案的連結相對於部署位置是正確的。\")\n",
        "\n",
        "# --- 確保後端與前端通訊 ---\n",
        "print(\"\\n確保通訊:\")\n",
        "print(\"1.  **CORS 配置：** 如果前端和後端從不同的來源 (不同的網域、埠或協定) 提供服務，請在 Flask 後端配置跨域資源共享 (CORS) 以允許來自前端來源的請求。\")\n",
        "print(\"    # 在 Flask 中，您可以使用 Flask-CORS 擴充套件。\")\n",
        "print(\"    # 範例 (在您的 Flask 應用程式中)：\")\n",
        "print(\"    # from flask_cors import CORS\")\n",
        "print(\"    # CORS(app)\")\n",
        "print(\"2.  **API 端點 URL：** 確保前端的 `fetch('/api/activities')` 呼叫指向已部署後端 API 的正確 URL。\")\n",
        "print(\"    # 如果使用反向代理，則應將 /api/activities 路徑代理到後端。\")\n",
        "\n",
        "print(\"\\n--- 模擬測試階段 ---\")\n",
        "\n",
        "# --- 在不同裝置和瀏覽器上進行測試 ---\n",
        "print(\"\\n模擬測試:\")\n",
        "print(\"1.  **存取應用程式：** 在各種裝置 (桌面、Android 行動裝置) 上開啟網頁瀏覽器，並導航到已部署應用程式的 URL。\")\n",
        "print(\"2.  **功能性測試：**\")\n",
        "print(\"    - 驗證活動資料是否正確載入並顯示。\")\n",
        "print(\"    - 使用不同的關鍵字測試搜尋功能，確保篩選功能按預期工作。\")\n",
        "print(\"    - 在瀏覽器的開發者工具 (F12) 中檢查是否有任何 JavaScript 錯誤。\")\n",
        "print(\"    - 測試分頁功能，確保每頁顯示正確數量的項目，且上一頁/下一頁按鈕按預期工作。\")\n",
        "print(\"3.  **跨瀏覽器測試：** 在不同瀏覽器 (Chrome, Firefox, Safari, Edge) 的桌面和行動裝置上測試應用程式，確保渲染和功能的一致性。\")\n",
        "print(\"    - 注意佈局、樣式和 JavaScript 執行。\")\n",
        "print(\"4.  **響應式測試：** 調整瀏覽器視窗大小並在行動裝置上測試，確保佈局能正確適應不同的螢幕尺寸 (如果實作了響應式設計)。\")\n",
        "print(\"5.  **網路監控：** 使用瀏覽器的開發者工具 (網路標籤) 監控 API 呼叫 (`/api/activities`)，確保它們成功 (狀態碼 200) 且資料傳輸正確。\")\n",
        "print(\"    - 檢查是否有慢速回應時間或失敗的請求。\")\n",
        "print(\"6.  **伺服器日誌：** 在測試期間監控 Flask 應用程式和 Web 伺服器 (Nginx/Apache) 的伺服器日誌，檢查是否有任何錯誤或警告。\")\n",
        "\n",
        "print(\"\\n--- 模擬完成 ---\")\n",
        "print(\"在實際情況中，根據測試結果，您將對程式碼或部署配置進行偵錯和迭代。\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20a89b16"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "* Successfully integrated a SQLite database into the backend to persistently store processed activity data.\n",
        "* Updated the Flask API endpoint to fetch data from the database, replacing the previous file-based data access.\n",
        "* Enhanced the frontend with pagination and filtering capabilities using JavaScript, improving the user experience for navigating and searching through activity records.\n",
        "* Added basic responsive styling to the frontend CSS to improve the layout and usability on smaller screens, including Android mobile devices.\n",
        "* Simulated the deployment and testing process, outlining the necessary steps for deploying the backend and frontend and testing the application across different environments.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "* Refine the database schema and data processing logic to handle potential data updates and avoid clearing the entire table on each run in a real-world scenario.\n",
        "* Implement more advanced filtering options on the frontend (e.g., by date range, product categories) and potentially move some filtering logic to the backend API for better performance with larger datasets.\n",
        "* Continue to enhance the frontend's responsive design to ensure a seamless user experience across a wider range of devices and screen sizes.\n",
        "* Explore different deployment strategies and platforms suitable for hosting Flask applications and static frontend assets.\n",
        "* **Finish task**: Summarize the completed work and provide a brief overview of the implemented features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e77682c5"
      },
      "source": [
        "## 完成任務\n",
        "\n",
        "### Subtask:\n",
        "總結已完成的工作，並概述已實作的功能。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbb5d3a3"
      },
      "source": [
        "**Reasoning**:\n",
        "Generate a summary of the completed work, highlighting the key features implemented throughout the project, including data processing, backend API development, frontend UI with pagination and filtering, and simulated deployment and testing. This will fulfill the final step of the plan."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8e9c223c"
      },
      "source": [
        "好的，任務已完成。我們成功地模擬了一個 AI 代理開發一個基於 Google Takeout 資料的 Web 應用程式。以下是已完成工作的總結和已實作的功能概述：\n",
        "\n",
        "**已完成的工作與實作功能：**\n",
        "\n",
        "1.  **前期準備與資料處理：**\n",
        "    *   設定了模擬的伺服器環境。\n",
        "    *   建立了 SQLite 資料庫並定義了活動記錄的綱要 (Schema)。\n",
        "    *   修改了資料處理流程，使其能讀取模擬的 Google Takeout 原始 JSON 資料，並將處理後的結構化資料寫入 SQLite 資料庫中。\n",
        "\n",
        "2.  **後端開發 (資料 API)：**\n",
        "    *   使用 Flask 框架開發了後端應用程式。\n",
        "    *   建立了 `/api/activities` API 端點，該端點能從 SQLite 資料庫中讀取活動記錄資料，並以 JSON 格式返回給前端。\n",
        "    *   處理了資料庫連線和查詢的錯誤。\n",
        "\n",
        "3.  **前端開發 (使用者介面與功能)：**\n",
        "    *   使用 HTML、CSS 和 JavaScript 建立了基本的網頁介面 (`index.html`, `style.css`, `script.js`)。\n",
        "    *   前端 JavaScript 能夠呼叫後端 API 獲取活動記錄資料，並將其呈現在網頁上。\n",
        "    *   實作了前端的**搜尋功能**，允許使用者根據活動標題或產品來篩選顯示的記錄。\n",
        "    *   實作了前端的**分頁功能**，將大量的活動記錄分頁顯示，提升使用者體驗。\n",
        "    *   為網頁添加了基本的**響應式設計**樣式，使其在不同的螢幕尺寸 (包括 Android 行動裝置) 上能有更好的佈局和顯示效果。\n",
        "\n",
        "4.  **部署與測試 (模擬)：**\n",
        "    *   概述了將後端 Flask 應用程式和前端靜態檔案部署到伺服器的典型步驟 (包括伺服器設定、依賴安裝、Web 伺服器配置等)。\n",
        "    *   描述了在不同裝置和瀏覽器上進行測試的過程，強調了功能驗證、跨瀏覽器相容性和響應式設計測試。\n",
        "\n",
        "整個流程模擬了 Web 應用程式從資料處理、後端 API 開發、前端介面與功能實作，到最終部署和測試的關鍵步驟。雖然資料和環境是模擬的，但程式碼結構和邏輯反映了真實專案的開發流程。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75d3f141"
      },
      "source": [
        "# Task\n",
        "Modify the code in the selected cell to implement incremental data updates instead of clearing and rewriting the data each time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5a2b77a4"
      },
      "source": [
        "## 修改資料處理邏輯\n",
        "\n",
        "### Subtask:\n",
        "更新 `process_and_insert_data` 函式，使其在插入資料前檢查資料庫中是否已存在相同或相似的活動記錄，以避免重複插入。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cc39d02"
      },
      "source": [
        "**Reasoning**:\n",
        "Modify the `process_and_insert_data` function to implement incremental data updates by checking for existing records before inserting, as described in the instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8f89a5aa"
      },
      "source": [
        "import json\n",
        "import os\n",
        "import sqlite3\n",
        "\n",
        "# Reusing the database file path and get_db_connection function from previous steps\n",
        "# DATABASE_FILE is defined in previous cells\n",
        "# get_db_connection() function is defined in previous cells\n",
        "\n",
        "# Simulate the path where raw Google Takeout JSON would be located initially\n",
        "simulated_raw_data_path = '/tmp/simulated_google_takeout_raw.json'\n",
        "\n",
        "# Create a dummy RAW JSON file to simulate the initial Google Takeout data structure\n",
        "# This file will be read by the processing script\n",
        "dummy_raw_data = [\n",
        "    {\n",
        "        \"header\": \"Google Search\",\n",
        "        \"title\": \"Searched for example\",\n",
        "        \"time\": \"2023-10-27T10:00:00.000Z\",\n",
        "        \"products\": [\"Search\"]\n",
        "    },\n",
        "    {\n",
        "        \"header\": \"YouTube\",\n",
        "        \"title\": \"Watched a video\",\n",
        "        \"time\": \"2023-10-27T10:05:00.000Z\",\n",
        "        \"products\": [\"YouTube\"]\n",
        "    },\n",
        "     {\n",
        "        \"header\": \"Google Maps\",\n",
        "        \"title\": \"Searched for a location\",\n",
        "        \"time\": \"2023-10-27T10:10:00.000Z\",\n",
        "        \"products\": [\"Maps\"]\n",
        "    },\n",
        "    # Add a duplicate record and a new record to test incremental update\n",
        "    {\n",
        "        \"header\": \"Google Search\",\n",
        "        \"title\": \"Searched for example\",\n",
        "        \"time\": \"2023-10-27T10:00:00.000Z\", # This is a duplicate\n",
        "        \"products\": [\"Search\"]\n",
        "    },\n",
        "    {\n",
        "        \"header\": \"Google Images\",\n",
        "        \"title\": \"Viewed an image\",\n",
        "        \"time\": \"2023-10-27T10:15:00.000Z\", # This is a new record\n",
        "        \"products\": [\"Images\"]\n",
        "    }\n",
        "]\n",
        "\n",
        "# Create the dummy raw data file if it doesn't exist or overwrite it with new dummy data for testing\n",
        "with open(simulated_raw_data_path, 'w') as f:\n",
        "    json.dump(dummy_raw_data, f, indent=4)\n",
        "print(f\"模擬原始資料檔案已建立/更新於: {simulated_raw_data_path}\")\n",
        "\n",
        "\n",
        "# Modified data processing function to read from the raw JSON and insert into DB incrementally\n",
        "def process_and_insert_data_incrementally():\n",
        "    \"\"\"\n",
        "    讀取模擬的 Google Takeout 原始資料，處理後增量插入 SQLite 資料庫。\n",
        "    在插入前檢查記錄是否存在以避免重複。\n",
        "    \"\"\"\n",
        "    conn = get_db_connection()\n",
        "    if conn is None:\n",
        "        print(\"無法建立資料庫連線，跳過資料處理及插入。\")\n",
        "        return\n",
        "\n",
        "    cursor = conn.cursor()\n",
        "    inserted_count = 0\n",
        "    skipped_count = 0\n",
        "\n",
        "    try:\n",
        "        # Read data from the simulated raw JSON file\n",
        "        with open(simulated_raw_data_path, 'r') as f:\n",
        "            takeout_data = json.load(f)\n",
        "\n",
        "        print(\"開始增量處理和插入資料...\")\n",
        "\n",
        "        # Process data and insert into the database\n",
        "        for item in takeout_data:\n",
        "            try:\n",
        "                processed_item = {\n",
        "                    'activity_title': item.get('title', '無標題'),\n",
        "                    'activity_time': item.get('time', '無時間資訊'),\n",
        "                    'product': ', '.join(item.get('products', [])) or '無產品資訊'\n",
        "                }\n",
        "\n",
        "                # Check if a similar record already exists\n",
        "                cursor.execute(\n",
        "                    \"SELECT COUNT(*) FROM activities WHERE activity_title = ? AND activity_time = ?\",\n",
        "                    (processed_item['activity_title'], processed_item['activity_time'])\n",
        "                )\n",
        "                exists = cursor.fetchone()[0] > 0\n",
        "\n",
        "                if exists:\n",
        "                    print(f\"記錄已存在，跳過插入: {processed_item['activity_title']} ({processed_item['activity_time']})\")\n",
        "                    skipped_count += 1\n",
        "                else:\n",
        "                    # Insert the record if it does not exist\n",
        "                    cursor.execute(\n",
        "                        \"INSERT INTO activities (activity_title, activity_time, product) VALUES (?, ?, ?)\",\n",
        "                        (processed_item['activity_title'], processed_item['activity_time'], processed_item['product'])\n",
        "                    )\n",
        "                    inserted_count += 1\n",
        "                    # print(f\"插入新記錄: {processed_item['activity_title']} ({processed_item['activity_time']})\") # Uncomment for verbose output\n",
        "\n",
        "            except sqlite3.Error as e:\n",
        "                print(f\"處理或插入單筆資料錯誤: {e} - 資料: {processed_item}\")\n",
        "                # Decide whether to continue or break on error\n",
        "\n",
        "        conn.commit() # Commit the transaction after the loop\n",
        "        print(f\"增量處理完成。已插入 {inserted_count} 筆新記錄，跳過 {skipped_count} 筆重複記錄。\")\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"錯誤: 模擬原始資料檔案未找到於 {simulated_raw_data_path}\")\n",
        "    except json.JSONDecodeError:\n",
        "        print(f\"錯誤: 無法解析模擬原始資料檔案 {simulated_raw_data_path} 中的 JSON\")\n",
        "    except Exception as e:\n",
        "        print(f\"處理和插入資料時發生未知錯誤: {e}\")\n",
        "    finally:\n",
        "        if conn:\n",
        "            conn.close() # Close the database connection\n",
        "            # print(\"資料庫連線已關閉。\") # Optional: uncomment for detailed logging\n",
        "\n",
        "\n",
        "# Execute the incremental data processing and insertion function\n",
        "process_and_insert_data_incrementally()\n",
        "\n",
        "# Verify the data in the database after incremental update\n",
        "def verify_data_in_db():\n",
        "    conn = get_db_connection()\n",
        "    if conn:\n",
        "        cursor = conn.cursor()\n",
        "        cursor.execute(\"SELECT COUNT(*) FROM activities\")\n",
        "        count = cursor.fetchone()[0]\n",
        "        print(f\"\\n資料庫中目前的活動記錄總筆數: {count}\")\n",
        "        cursor.execute(\"SELECT * FROM activities LIMIT 10\") # Show first 10 records\n",
        "        rows = cursor.fetchall()\n",
        "        print(\"資料庫中前 10 筆記錄:\")\n",
        "        for row in rows:\n",
        "            print(dict(row)) # Print as dictionary\n",
        "        conn.close()\n",
        "\n",
        "verify_data_in_db()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6a1570f"
      },
      "source": [
        "## 處理資料衝突 (可選)\n",
        "\n",
        "### Subtask:\n",
        "根據需求決定如何處理已存在但內容可能不同的記錄 (例如：更新現有記錄或記錄衝突)。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4ba1606"
      },
      "source": [
        "**Reasoning**:\n",
        "Based on the project requirements and the previous steps, the most suitable strategy for handling existing records with potentially different content (e.g., product) when title and time match is to update the existing record with the new data. This ensures that the database always reflects the most recent information for a given activity at a specific time. I will modify the `process_and_insert_data_incrementally` function to implement this update strategy, adding logic to check for existing records, and if found, update the `product` field. I will also update the print statements to indicate whether a record was inserted, updated, or skipped.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fd32bb6e"
      },
      "source": [
        "import json\n",
        "import os\n",
        "import sqlite3\n",
        "import time # Import time for potential time-related operations if needed\n",
        "\n",
        "# Reusing database configuration and connection function\n",
        "# DATABASE_FILE and get_db_connection are assumed to be defined in previous cells\n",
        "\n",
        "# Simulate the path where raw Google Takeout JSON would be located initially\n",
        "simulated_raw_data_path = '/tmp/simulated_google_takeout_raw.json'\n",
        "\n",
        "# Create or update a dummy RAW JSON file with data to test updates\n",
        "# Added a record with the same title and time as an existing one, but different product(s)\n",
        "dummy_raw_data = [\n",
        "    {\n",
        "        \"header\": \"Google Search\",\n",
        "        \"title\": \"Searched for example\",\n",
        "        \"time\": \"2023-10-27T10:00:00.000Z\",\n",
        "        \"products\": [\"Search\"]\n",
        "    },\n",
        "    {\n",
        "        \"header\": \"YouTube\",\n",
        "        \"title\": \"Watched a video\",\n",
        "        \"time\": \"2023-10-27T10:05:00.000Z\",\n",
        "        \"products\": [\"YouTube\"]\n",
        "    },\n",
        "     {\n",
        "        \"header\": \"Google Maps\",\n",
        "        \"title\": \"Searched for a location\",\n",
        "        \"time\": \"2023-10-27T10:10:00.000Z\",\n",
        "        \"products\": [\"Maps\"]\n",
        "    },\n",
        "    # Duplicate record (should be skipped based on title and time match)\n",
        "    {\n",
        "        \"header\": \"Google Search\",\n",
        "        \"title\": \"Searched for example\",\n",
        "        \"time\": \"2023-10-27T10:00:00.000Z\",\n",
        "        \"products\": [\"Web & App Activity\"] # Slightly different product(s) - this will test the update logic\n",
        "    },\n",
        "    # New record\n",
        "    {\n",
        "        \"header\": \"Google Images\",\n",
        "        \"title\": \"Viewed an image\",\n",
        "        \"time\": \"2023-10-27T10:15:00.000Z\",\n",
        "        \"products\": [\"Images\"]\n",
        "    }\n",
        "]\n",
        "\n",
        "# Overwrite the dummy raw data file with new dummy data for testing update scenarios\n",
        "with open(simulated_raw_data_path, 'w') as f:\n",
        "    json.dump(dummy_raw_data, f, indent=4)\n",
        "print(f\"模擬原始資料檔案已建立/更新於: {simulated_raw_data_path}\")\n",
        "\n",
        "\n",
        "# Modified data processing function to read from the raw JSON and incrementally update/insert into DB\n",
        "def process_and_insert_data_incrementally():\n",
        "    \"\"\"\n",
        "    讀取模擬的 Google Takeout 原始資料，處理後增量更新或插入 SQLite 資料庫。\n",
        "    在處理資料時，檢查記錄是否存在，如果存在則更新產品資訊，否則插入新記錄。\n",
        "    \"\"\"\n",
        "    conn = get_db_connection()\n",
        "    if conn is None:\n",
        "        print(\"無法建立資料庫連線，跳過資料處理及插入。\")\n",
        "        return\n",
        "\n",
        "    cursor = conn.cursor()\n",
        "    inserted_count = 0\n",
        "    updated_count = 0\n",
        "    skipped_count = 0 # For cases where we might skip based on other criteria in the future\n",
        "\n",
        "    try:\n",
        "        # Read data from the simulated raw JSON file\n",
        "        with open(simulated_raw_data_path, 'r') as f:\n",
        "            takeout_data = json.load(f)\n",
        "\n",
        "        print(\"\\n開始增量處理和插入/更新資料...\")\n",
        "\n",
        "        # Process data and insert/update into the database\n",
        "        for item in takeout_data:\n",
        "            try:\n",
        "                processed_item = {\n",
        "                    'activity_title': item.get('title', '無標題'),\n",
        "                    'activity_time': item.get('time', '無時間資訊'),\n",
        "                    'product': ', '.join(item.get('products', [])) or '無產品資訊'\n",
        "                }\n",
        "\n",
        "                # Check if a record with the same title and time already exists\n",
        "                cursor.execute(\n",
        "                    \"SELECT id, product FROM activities WHERE activity_title = ? AND activity_time = ?\",\n",
        "                    (processed_item['activity_title'], processed_item['activity_time'])\n",
        "                )\n",
        "                existing_record = cursor.fetchone()\n",
        "\n",
        "                if existing_record:\n",
        "                    # Record exists, check if product needs update\n",
        "                    existing_id, existing_product = existing_record\n",
        "                    if existing_product != processed_item['product']:\n",
        "                        # Product information is different, update the existing record\n",
        "                        cursor.execute(\n",
        "                            \"UPDATE activities SET product = ? WHERE id = ?\",\n",
        "                            (processed_item['product'], existing_id)\n",
        "                        )\n",
        "                        updated_count += 1\n",
        "                        print(f\"更新記錄 (ID: {existing_id}): {processed_item['activity_title']} ({processed_item['activity_time']}) - 新產品: {processed_item['product']}\")\n",
        "                    else:\n",
        "                        # Record exists and product is the same, skip\n",
        "                        skipped_count += 1\n",
        "                        print(f\"記錄已存在且內容相同，跳過插入/更新: {processed_item['activity_title']} ({processed_item['activity_time']})\")\n",
        "                else:\n",
        "                    # Record does not exist, insert a new one\n",
        "                    cursor.execute(\n",
        "                        \"INSERT INTO activities (activity_title, activity_time, product) VALUES (?, ?, ?)\",\n",
        "                        (processed_item['activity_title'], processed_item['activity_time'], processed_item['product'])\n",
        "                    )\n",
        "                    inserted_count += 1\n",
        "                    print(f\"插入新記錄: {processed_item['activity_title']} ({processed_item['activity_time']})\")\n",
        "\n",
        "            except sqlite3.Error as e:\n",
        "                print(f\"處理或插入/更新單筆資料錯誤: {e} - 資料: {processed_item}\")\n",
        "                # Decide whether to continue or break on error\n",
        "\n",
        "        conn.commit() # Commit the transaction after the loop\n",
        "        print(f\"\\n增量處理完成。已插入 {inserted_count} 筆新記錄，更新 {updated_count} 筆記錄，跳過 {skipped_count} 筆記錄。\")\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"錯誤: 模擬原始資料檔案未找到於 {simulated_raw_data_path}\")\n",
        "    except json.JSONDecodeError:\n",
        "        print(f\"錯誤: 無法解析模擬原始資料檔案 {simulated_raw_data_path} 中的 JSON\")\n",
        "    except Exception as e:\n",
        "        print(f\"處理和插入/更新資料時發生未知錯誤: {e}\")\n",
        "    finally:\n",
        "        if conn:\n",
        "            conn.close() # Close the database connection\n",
        "            # print(\"資料庫連線已關閉。\") # Optional: uncomment for detailed logging\n",
        "\n",
        "\n",
        "# Execute the incremental data processing and insertion/update function\n",
        "process_and_insert_data_incrementally()\n",
        "\n",
        "# Verify the data in the database after incremental update\n",
        "def verify_data_in_db():\n",
        "    conn = get_db_connection()\n",
        "    if conn:\n",
        "        cursor = conn.cursor()\n",
        "        cursor.execute(\"SELECT COUNT(*) FROM activities\")\n",
        "        count = cursor.fetchone()[0]\n",
        "        print(f\"\\n資料庫中目前的活動記錄總筆數: {count}\")\n",
        "        cursor.execute(\"SELECT id, activity_title, activity_time, product FROM activities ORDER BY activity_time LIMIT 10\") # Show first 10 records, ordered by time\n",
        "        rows = cursor.fetchall()\n",
        "        print(\"資料庫中前 10 筆記錄 (包含 ID):\")\n",
        "        for row in rows:\n",
        "            print(dict(row)) # Print as dictionary\n",
        "        conn.close()\n",
        "\n",
        "verify_data_in_db()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73b60c78"
      },
      "source": [
        "## 測試更新的資料處理\n",
        "\n",
        "### Subtask:\n",
        "執行修改後的資料處理程式碼，並驗證資料庫中的資料是否按預期進行增量更新，沒有重複記錄。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "496e9666"
      },
      "source": [
        "**Reasoning**:\n",
        "Execute the code block containing the modified data processing function and the verification function to perform the incremental data update and verify the results in the database, addressing steps 1, 2, 3, and 4 of the subtask.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9207aed"
      },
      "source": [
        "import json\n",
        "import os\n",
        "import sqlite3\n",
        "\n",
        "# Reusing the database file path and get_db_connection function from previous steps\n",
        "# DATABASE_FILE is defined in previous cells\n",
        "# get_db_connection() function is defined in previous cells\n",
        "\n",
        "# Simulate the path where raw Google Takeout JSON would be located initially\n",
        "simulated_raw_data_path = '/tmp/simulated_google_takeout_raw.json'\n",
        "\n",
        "# Create or update a dummy RAW JSON file with data to test updates\n",
        "# Added a record with the same title and time as an existing one, but different product(s)\n",
        "dummy_raw_data = [\n",
        "    {\n",
        "        \"header\": \"Google Search\",\n",
        "        \"title\": \"Searched for example\",\n",
        "        \"time\": \"2023-10-27T10:00:00.000Z\",\n",
        "        \"products\": [\"Search\"]\n",
        "    },\n",
        "    {\n",
        "        \"header\": \"YouTube\",\n",
        "        \"title\": \"Watched a video\",\n",
        "        \"time\": \"2023-10-27T10:05:00.000Z\",\n",
        "        \"products\": [\"YouTube\"]\n",
        "    },\n",
        "     {\n",
        "        \"header\": \"Google Maps\",\n",
        "        \"title\": \"Searched for a location\",\n",
        "        \"time\": \"2023-10-27T10:10:00.000Z\",\n",
        "        \"products\": [\"Maps\"]\n",
        "    },\n",
        "    # Duplicate record (should be skipped based on title and time match)\n",
        "    {\n",
        "        \"header\": \"Google Search\",\n",
        "        \"title\": \"Searched for example\",\n",
        "        \"time\": \"2023-10-27T10:00:00.000Z\",\n",
        "        \"products\": [\"Web & App Activity\"] # Slightly different product(s) - this will test the update logic\n",
        "    },\n",
        "    # New record\n",
        "    {\n",
        "        \"header\": \"Google Images\",\n",
        "        \"title\": \"Viewed an image\",\n",
        "        \"time\": \"2023-10-27T10:15:00.000Z\",\n",
        "        \"products\": [\"Images\"]\n",
        "    }\n",
        "]\n",
        "\n",
        "# Overwrite the dummy raw data file with new dummy data for testing update scenarios\n",
        "with open(simulated_raw_data_path, 'w') as f:\n",
        "    json.dump(dummy_raw_data, f, indent=4)\n",
        "print(f\"模擬原始資料檔案已建立/更新於: {simulated_raw_data_path}\")\n",
        "\n",
        "\n",
        "# Modified data processing function to read from the raw JSON and incrementally update/insert into DB\n",
        "def process_and_insert_data_incrementally():\n",
        "    \"\"\"\n",
        "    讀取模擬的 Google Takeout 原始資料，處理後增量更新或插入 SQLite 資料庫。\n",
        "    在處理資料時，檢查記錄是否存在，如果存在則更新產品資訊，否則插入新記錄。\n",
        "    \"\"\"\n",
        "    conn = get_db_connection()\n",
        "    if conn is None:\n",
        "        print(\"無法建立資料庫連線，跳過資料處理及插入。\")\n",
        "        return\n",
        "\n",
        "    cursor = conn.cursor()\n",
        "    inserted_count = 0\n",
        "    updated_count = 0\n",
        "    skipped_count = 0 # For cases where we might skip based on other criteria in the future\n",
        "\n",
        "    try:\n",
        "        # Read data from the simulated raw JSON file\n",
        "        with open(simulated_raw_data_path, 'r') as f:\n",
        "            takeout_data = json.load(f)\n",
        "\n",
        "        print(\"\\n開始增量處理和插入/更新資料...\")\n",
        "\n",
        "        # Process data and insert/update into the database\n",
        "        for item in takeout_data:\n",
        "            try:\n",
        "                processed_item = {\n",
        "                    'activity_title': item.get('title', '無標題'),\n",
        "                    'activity_time': item.get('time', '無時間資訊'),\n",
        "                    'product': ', '.join(item.get('products', [])) or '無產品資訊'\n",
        "                }\n",
        "\n",
        "                # Check if a record with the same title and time already exists\n",
        "                cursor.execute(\n",
        "                    \"SELECT id, product FROM activities WHERE activity_title = ? AND activity_time = ?\",\n",
        "                    (processed_item['activity_title'], processed_item['activity_time'])\n",
        "                )\n",
        "                existing_record = cursor.fetchone()\n",
        "\n",
        "                if existing_record:\n",
        "                    # Record exists, check if product needs update\n",
        "                    existing_id, existing_product = existing_record\n",
        "                    if existing_product != processed_item['product']:\n",
        "                        # Product information is different, update the existing record\n",
        "                        cursor.execute(\n",
        "                            \"UPDATE activities SET product = ? WHERE id = ?\",\n",
        "                            (processed_item['product'], existing_id)\n",
        "                        )\n",
        "                        updated_count += 1\n",
        "                        print(f\"更新記錄 (ID: {existing_id}): {processed_item['activity_title']} ({processed_item['activity_time']}) - 新產品: {processed_item['product']}\")\n",
        "                    else:\n",
        "                        # Record exists and product is the same, skip\n",
        "                        skipped_count += 1\n",
        "                        print(f\"記錄已存在且內容相同，跳過插入/更新: {processed_item['activity_title']} ({processed_item['activity_time']})\")\n",
        "                else:\n",
        "                    # Record does not exist, insert a new one\n",
        "                    cursor.execute(\n",
        "                        \"INSERT INTO activities (activity_title, activity_time, product) VALUES (?, ?, ?)\",\n",
        "                        (processed_item['activity_title'], processed_item['activity_time'], processed_item['product'])\n",
        "                    )\n",
        "                    inserted_count += 1\n",
        "                    print(f\"插入新記錄: {processed_item['activity_title']} ({processed_item['activity_time']})\")\n",
        "\n",
        "            except sqlite3.Error as e:\n",
        "                print(f\"處理或插入/更新單筆資料錯誤: {e} - 資料: {processed_item}\")\n",
        "                # Decide whether to continue or break on error\n",
        "\n",
        "        conn.commit() # Commit the transaction after the loop\n",
        "        print(f\"\\n增量處理完成。已插入 {inserted_count} 筆新記錄，更新 {updated_count} 筆記錄，跳過 {skipped_count} 筆記錄。\")\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"錯誤: 模擬原始資料檔案未找到於 {simulated_raw_data_path}\")\n",
        "    except json.JSONDecodeError:\n",
        "        print(f\"錯誤: 無法解析模擬原始資料檔案 {simulated_raw_data_path} 中的 JSON\")\n",
        "    except Exception as e:\n",
        "        print(f\"處理和插入/更新資料時發生未知錯誤: {e}\")\n",
        "    finally:\n",
        "        if conn:\n",
        "            conn.close() # Close the database connection\n",
        "            # print(\"資料庫連線已關閉。\") # Optional: uncomment for detailed logging\n",
        "\n",
        "\n",
        "# Execute the incremental data processing and insertion/update function\n",
        "process_and_insert_data_incrementally()\n",
        "\n",
        "# Verify the data in the database after incremental update\n",
        "def verify_data_in_db():\n",
        "    conn = get_db_connection()\n",
        "    if conn:\n",
        "        cursor = conn.cursor()\n",
        "        cursor.execute(\"SELECT COUNT(*) FROM activities\")\n",
        "        count = cursor.fetchone()[0]\n",
        "        print(f\"\\n資料庫中目前的活動記錄總筆數: {count}\")\n",
        "        cursor.execute(\"SELECT id, activity_title, activity_time, product FROM activities ORDER BY activity_time LIMIT 10\") # Show first 10 records, ordered by time\n",
        "        rows = cursor.fetchall()\n",
        "        print(\"資料庫中前 10 筆記錄 (包含 ID):\")\n",
        "        for row in rows:\n",
        "            print(dict(row)) # Print as dictionary\n",
        "        conn.close()\n",
        "\n",
        "verify_data_in_db()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7c0e9ede"
      },
      "source": [
        "## 完成任務\n",
        "\n",
        "### Subtask:\n",
        "總結已完成的工作，並概述已實作的功能。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14c8df2d"
      },
      "source": [
        "## 測試更新的資料處理\n",
        "\n",
        "### Subtask:\n",
        "執行修改後的資料處理程式碼，並驗證資料庫中的資料是否按預期進行增量更新，沒有重複記錄。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90ed9d47"
      },
      "source": [
        "**Reasoning**:\n",
        "Execute the modified data processing function to perform the incremental update and then verify the data in the database to ensure the incremental update was successful and there are no duplicate records.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23d69ed4"
      },
      "source": [
        "# Execute the incremental data processing and insertion/update function\n",
        "process_and_insert_data_incrementally()\n",
        "\n",
        "# Verify the data in the database after incremental update\n",
        "# Re-using the function definition from previous cells\n",
        "def verify_data_in_db():\n",
        "    conn = get_db_connection()\n",
        "    if conn:\n",
        "        cursor = conn.cursor()\n",
        "        cursor.execute(\"SELECT COUNT(*) FROM activities\")\n",
        "        count = cursor.fetchone()[0]\n",
        "        print(f\"\\n資料庫中目前的活動記錄總筆數: {count}\")\n",
        "        cursor.execute(\"SELECT id, activity_title, activity_time, product FROM activities ORDER BY activity_time LIMIT 10\") # Show first 10 records, ordered by time\n",
        "        rows = cursor.fetchall()\n",
        "        print(\"資料庫中前 10 筆記錄 (包含 ID):\")\n",
        "        for row in rows:\n",
        "            print(dict(row)) # Print as dictionary\n",
        "        conn.close()\n",
        "\n",
        "verify_data_in_db()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bf7820b"
      },
      "source": [
        "## 更新後端 api\n",
        "\n",
        "### Subtask:\n",
        "修改 `/api/activities` 接口，使其從 SQLite 資料庫中讀取資料，並支援分頁和篩選功能。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dd08aa6"
      },
      "source": [
        "**Reasoning**:\n",
        "Modify the `/api/activities` endpoint in the Flask application to accept `page`, `limit`, and `search` query parameters. Implement pagination and filtering logic in the SQLite query based on these parameters. Calculate and return the total number of records (after filtering) and the total number of pages along with the paginated and filtered activity data. This addresses all steps of the current subtask.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91198788"
      },
      "source": [
        "import sqlite3\n",
        "import os\n",
        "import json\n",
        "from flask import Flask, jsonify, request # Import request to access query parameters\n",
        "import threading\n",
        "import time\n",
        "import socket\n",
        "import math # Import math for calculating total pages\n",
        "\n",
        "# Re-use the Flask app instance if it exists\n",
        "try:\n",
        "    app\n",
        "except NameError:\n",
        "    app = Flask(__name__)\n",
        "\n",
        "# Re-use database configuration and helper functions\n",
        "# DATABASE_FILE, DATABASE_SCHEMA, create_database_and_table, get_db_connection\n",
        "# are assumed to be defined in previous cells and available in the kernel\n",
        "\n",
        "# Ensure the database and table exist and is populated with simulated data\n",
        "create_database_and_table()\n",
        "# Only insert simulated data if the table is empty to avoid duplicates on re-execution\n",
        "conn_check = get_db_connection()\n",
        "if conn_check:\n",
        "    cursor_check = conn_check.cursor()\n",
        "    cursor_check.execute(\"SELECT COUNT(*) FROM activities\")\n",
        "    count = cursor_check.fetchone()[0]\n",
        "    conn_check.close()\n",
        "    if count == 0:\n",
        "        print(\"資料庫為空，插入模擬資料...\")\n",
        "        # Assuming process_and_insert_data_incrementally() is defined and works\n",
        "        try:\n",
        "            process_and_insert_data_incrementally()\n",
        "        except NameError:\n",
        "            print(\"錯誤: process_and_insert_data_incrementally 函式未定義。請確認前一個程式碼格已成功執行。\")\n",
        "            # Define a minimal placeholder if not found\n",
        "            def process_and_insert_data_incrementally():\n",
        "                 print(\"Simulated incremental data insertion function placeholder executed.\")\n",
        "            process_and_insert_data_incrementally() # Call the placeholder\n",
        "    else:\n",
        "        print(f\"資料庫中已有 {count} 筆資料，跳過模擬資料插入。\")\n",
        "\n",
        "# Modify the API endpoint to fetch data from the database with pagination and filtering\n",
        "# Check if the endpoint 'get_activities' already exists to avoid re-adding it\n",
        "existing_rule = None\n",
        "for rule in app.url_map.iter_rules():\n",
        "    if rule.endpoint == 'get_activities' and '/api/activities' in rule.rule:\n",
        "        existing_rule = rule\n",
        "        break\n",
        "\n",
        "if existing_rule:\n",
        "    print(f\"移除現有路由 '{existing_rule.rule}'，端點名稱 '{existing_rule.endpoint}'\")\n",
        "    app.url_map._rules.remove(existing_rule)\n",
        "    # Also remove the endpoint from view_functions to be safe\n",
        "    if 'get_activities' in app.view_functions:\n",
        "         del app.view_functions['get_activities']\n",
        "\n",
        "@app.route('/api/activities', methods=['GET'])\n",
        "def get_activities():\n",
        "    \"\"\"\n",
        "    API endpoint to get processed activity data from the database with pagination and filtering.\n",
        "    Reads from the SQLite database.\n",
        "    Query Parameters:\n",
        "        - page: int (default: 1) - the page number\n",
        "        - limit: int (default: 10) - items per page\n",
        "        - search: str (optional) - keyword to search in activity_title or product\n",
        "    \"\"\"\n",
        "    conn = get_db_connection()\n",
        "    if conn is None:\n",
        "        print(\"無法建立資料庫連線。\")\n",
        "        return jsonify({\"error\": \"無法連接資料庫\"}), 500\n",
        "\n",
        "    try:\n",
        "        cursor = conn.cursor()\n",
        "\n",
        "        # Get query parameters with default values\n",
        "        page = request.args.get('page', 1, type=int)\n",
        "        limit = request.args.get('limit', 10, type=int)\n",
        "        search_term = request.args.get('search', type=str)\n",
        "\n",
        "        # Ensure limit is positive\n",
        "        if limit <= 0:\n",
        "            limit = 10 # Default to 10 if invalid limit is provided\n",
        "\n",
        "        # Build the base query\n",
        "        base_query = \"SELECT activity_title, activity_time, product FROM activities\"\n",
        "        count_query = \"SELECT COUNT(*) FROM activities\"\n",
        "        where_clause = \"\"\n",
        "        query_params = []\n",
        "\n",
        "        # Add filtering if search term is provided\n",
        "        if search_term:\n",
        "            where_clause = \" WHERE activity_title LIKE ? OR product LIKE ?\"\n",
        "            # Use '%' for SQL LIKE matching\n",
        "            query_params = [f\"%{search_term}%\", f\"%{search_term}%\"]\n",
        "\n",
        "        # Construct the final queries\n",
        "        final_data_query = base_query + where_clause + \" ORDER BY activity_time DESC LIMIT ? OFFSET ?\"\n",
        "        final_count_query = count_query + where_clause\n",
        "\n",
        "        # Add pagination parameters to the data query params\n",
        "        data_query_params = query_params + [limit, (page - 1) * limit]\n",
        "\n",
        "        # Execute the count query first (considering filtering)\n",
        "        cursor.execute(final_count_query, query_params)\n",
        "        total_records = cursor.fetchone()[0]\n",
        "\n",
        "        # Calculate total pages\n",
        "        total_pages = math.ceil(total_records / limit) if limit > 0 else 0\n",
        "\n",
        "        # Execute the data query with filtering and pagination\n",
        "        cursor.execute(final_data_query, data_query_params)\n",
        "\n",
        "        # Fetch all rows and convert them to a list of dictionaries\n",
        "        activities = [dict(row) for row in cursor.fetchall()]\n",
        "\n",
        "        # Return the data along with pagination info\n",
        "        return jsonify({\n",
        "            \"activities\": activities,\n",
        "            \"total_records\": total_records,\n",
        "            \"total_pages\": total_pages,\n",
        "            \"current_page\": page,\n",
        "            \"items_per_page\": limit\n",
        "        })\n",
        "\n",
        "    except sqlite3.Error as e:\n",
        "        print(f\"查詢資料庫錯誤: {e}\")\n",
        "        return jsonify({\"error\": \"無法從資料庫獲取資料\"}), 500\n",
        "    except Exception as e:\n",
        "        print(f\"獲取活動資料時發生未知錯誤: {e}\")\n",
        "        return jsonify({\"error\": str(e)}), 500\n",
        "    finally:\n",
        "        # Ensure the database connection is closed\n",
        "        if conn:\n",
        "            conn.close()\n",
        "            # print(\"資料庫連線已關閉。\") # Optional: uncomment for detailed logging\n",
        "\n",
        "# Function to run the Flask app in a separate thread for notebook environment\n",
        "# Re-using the function definition from previous cells\n",
        "def run_flask_app():\n",
        "    print(\"Flask app正在背景執行緒中啟動 (本地測試)...\")\n",
        "    # Explicitly use Flask's built-in development server\n",
        "    # use_reloader=False is important to prevent issues with threading in notebooks\n",
        "    app.run(port=5000, debug=False, use_reloader=False)\n",
        "\n",
        "# Check if the thread is already running and port is free before starting\n",
        "def is_port_in_use(port):\n",
        "    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
        "        try:\n",
        "            s.bind(('localhost', port))\n",
        "            return False # Port is free\n",
        "        except socket.error:\n",
        "            return True # Port is in use\n",
        "\n",
        "# Check if the thread is alive or if the port is in use\n",
        "# Use locals() to check for the thread variable in the current scope\n",
        "if 'flask_thread' not in locals() or not flask_thread.is_alive():\n",
        "    if not is_port_in_use(5000):\n",
        "        flask_thread = threading.Thread(target=run_flask_app)\n",
        "        flask_thread.daemon = True # Allow the main thread to exit even if the Flask thread is running\n",
        "        flask_thread.start()\n",
        "        print(\"Flask app正在背景執行緒中啟動...\")\n",
        "        print(\"請等待片刻，然後執行下一個程式碼格來測試 API。\")\n",
        "    else:\n",
        "        print(\"Port 5000 已經在使用中，無法啟動 Flask app。\")\n",
        "        print(\"請嘗試重新啟動執行階段，或手動停止佔用 Port 5000 的程序。\")\n",
        "else:\n",
        "    print(\"Flask app已經在背景執行緒中運行。\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76df7925"
      },
      "source": [
        "**Reasoning**:\n",
        "Test the updated `/api/activities` endpoint to verify that pagination and filtering work correctly by making requests with different query parameters and checking the JSON response structure and content. This addresses steps 1, 2, and 3 of the instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3f510b9"
      },
      "source": [
        "import requests\n",
        "import time\n",
        "\n",
        "# Give the Flask app a moment to ensure the new endpoint is active (though it should be quick)\n",
        "time.sleep(2)\n",
        "\n",
        "print(\"--- 測試包含分頁和篩選功能的 API 端點 ---\")\n",
        "\n",
        "# Test Case 1: Get the first page with default limit\n",
        "print(\"\\n測試案例 1: 獲取第一頁 (預設每頁筆數)...\")\n",
        "try:\n",
        "    response1 = requests.get('http://127.0.0.1:5000/api/activities')\n",
        "    if response1.status_code == 200:\n",
        "        data1 = response1.json()\n",
        "        print(\"API 請求成功。回應資料結構:\")\n",
        "        print(json.dumps(data1, indent=2))\n",
        "        print(f\"總記錄數: {data1.get('total_records')}\")\n",
        "        print(f\"總頁數: {data1.get('total_pages')}\")\n",
        "        print(f\"目前頁碼: {data1.get('current_page')}\")\n",
        "        print(f\"每頁筆數: {data1.get('items_per_page')}\")\n",
        "        print(f\"獲取到的活動記錄筆數: {len(data1.get('activities', []))}\")\n",
        "    else:\n",
        "        print(f\"API 請求失敗，狀態碼：{response1.status_code}\")\n",
        "        print(\"回應內容：\")\n",
        "        print(response1.text)\n",
        "except requests.exceptions.ConnectionError as e:\n",
        "    print(f\"無法連接到 Flask 應用程式。錯誤：{e}\")\n",
        "except Exception as e:\n",
        "    print(f\"測試 API 時發生錯誤：{e}\")\n",
        "\n",
        "\n",
        "# Test Case 2: Get the second page with a smaller limit\n",
        "print(\"\\n測試案例 2: 獲取第二頁，每頁 2 筆...\")\n",
        "try:\n",
        "    response2 = requests.get('http://127.0.0.1:5000/api/activities?page=2&limit=2')\n",
        "    if response2.status_code == 200:\n",
        "        data2 = response2.json()\n",
        "        print(\"API 請求成功。回應資料結構:\")\n",
        "        print(json.dumps(data2, indent=2))\n",
        "        print(f\"總記錄數: {data2.get('total_records')}\")\n",
        "        print(f\"總頁數: {data2.get('total_pages')}\")\n",
        "        print(f\"目前頁碼: {data2.get('current_page')}\")\n",
        "        print(f\"每頁筆數: {data2.get('items_per_page')}\")\n",
        "        print(f\"獲取到的活動記錄筆數: {len(data2.get('activities', []))}\")\n",
        "    else:\n",
        "        print(f\"API 請求失敗，狀態碼：{response2.status_code}\")\n",
        "        print(\"回應內容：\")\n",
        "        print(response2.text)\n",
        "except requests.exceptions.ConnectionError as e:\n",
        "    print(f\"無法連接到 Flask 應用程式。錯誤：{e}\")\n",
        "except Exception as e:\n",
        "    print(f\"測試 API 時發生錯誤：{e}\")\n",
        "\n",
        "\n",
        "# Test Case 3: Search for a keyword (e.g., \"Search\")\n",
        "print(\"\\n測試案例 3: 搜尋關鍵字 'Search'...\")\n",
        "try:\n",
        "    response3 = requests.get('http://127.0.0.1:5000/api/activities?search=Search')\n",
        "    if response3.status_code == 200:\n",
        "        data3 = response3.json()\n",
        "        print(\"API 請求成功。回應資料結構:\")\n",
        "        print(json.dumps(data3, indent=2))\n",
        "        print(f\"總記錄數 (篩選後): {data3.get('total_records')}\")\n",
        "        print(f\"總頁數 (篩選後): {data3.get('total_pages')}\")\n",
        "        print(f\"目前頁碼: {data3.get('current_page')}\")\n",
        "        print(f\"每頁筆數: {data3.get('items_per_page')}\")\n",
        "        print(f\"獲取到的活動記錄筆數: {len(data3.get('activities', []))}\")\n",
        "    else:\n",
        "        print(f\"API 請求失敗，狀態碼：{response3.status_code}\")\n",
        "        print(\"回應內容：\")\n",
        "        print(response3.text)\n",
        "except requests.exceptions.ConnectionError as e:\n",
        "    print(f\"無法連接到 Flask 應用程式。錯誤：{e}\")\n",
        "except Exception as e:\n",
        "    print(f\"測試 API 時發生錯誤：{e}\")\n",
        "\n",
        "# Test Case 4: Search for a keyword and apply pagination (e.g., \"Google\", page 1, limit 1)\n",
        "print(\"\\n測試案例 4: 搜尋關鍵字 'Google'，第一頁，每頁 1 筆...\")\n",
        "try:\n",
        "    response4 = requests.get('http://127.0.0.1:5000/api/activities?search=Google&page=1&limit=1')\n",
        "    if response4.status_code == 200:\n",
        "        data4 = response4.json()\n",
        "        print(\"API 請求成功。回應資料結構:\")\n",
        "        print(json.dumps(data4, indent=2))\n",
        "        print(f\"總記錄數 (篩選後): {data4.get('total_records')}\")\n",
        "        print(f\"總頁數 (篩選後): {data4.get('total_pages')}\")\n",
        "        print(f\"目前頁碼: {data4.get('current_page')}\")\n",
        "        print(f\"每頁筆數: {data4.get('items_per_page')}\")\n",
        "        print(f\"獲取到的活動記錄筆數: {len(data4.get('activities', []))}\")\n",
        "    else:\n",
        "        print(f\"API 請求失敗，狀態碼：{response4.status_code}\")\n",
        "        print(\"回應內容：\")\n",
        "        print(response4.text)\n",
        "except requests.exceptions.ConnectionError as e:\n",
        "    print(f\"無法連接到 Flask 應用程式。錯誤：{e}\")\n",
        "except Exception as e:\n",
        "    print(f\"測試 API 時發生錯誤：{e}\")\n",
        "\n",
        "print(\"\\n--- API 端點測試完成 ---\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bd4494e"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous API test failed because the Flask endpoint was returning a list of activities directly, not a dictionary containing the activities list and pagination metadata as intended. The error `'list' object has no attribute 'get'` occurred when trying to access `data.get('total_records')` etc. I need to fix the Flask endpoint's return value to match the expected dictionary structure. I will modify the `get_activities` function to return `jsonify` with the dictionary `{\"activities\": activities, \"total_records\": total_records, ...}`. This directly addresses the issue and allows the subsequent tests to correctly access the pagination and filtering information.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eo59xnwie02b"
      },
      "source": [
        "import sqlite3\n",
        "import os\n",
        "import json\n",
        "from flask import Flask, jsonify, request\n",
        "import threading\n",
        "import time\n",
        "import socket\n",
        "import math\n",
        "\n",
        "# Re-use the Flask app instance if it exists\n",
        "try:\n",
        "    app\n",
        "except NameError:\n",
        "    app = Flask(__name__)\n",
        "\n",
        "# Re-use database configuration and helper functions\n",
        "# DATABASE_FILE, DATABASE_SCHEMA, create_database_and_table, get_db_connection\n",
        "# are assumed to be defined in previous cells and available in the kernel\n",
        "\n",
        "# Ensure the database and table exist and is populated with simulated data\n",
        "create_database_and_table()\n",
        "# Only insert simulated data if the table is empty to avoid duplicates on re-execution\n",
        "conn_check = get_db_connection()\n",
        "if conn_check:\n",
        "    cursor_check = conn_check.cursor()\n",
        "    cursor_check.execute(\"SELECT COUNT(*) FROM activities\")\n",
        "    count = cursor_check.fetchone()[0]\n",
        "    conn_check.close()\n",
        "    if count == 0:\n",
        "        print(\"資料庫為空，插入模擬資料...\")\n",
        "        # Assuming process_and_insert_data_incrementally() is defined and works\n",
        "        try:\n",
        "            process_and_insert_data_incrementally()\n",
        "        except NameError:\n",
        "            print(\"錯誤: process_and_insert_data_incrementally 函式未定義。請確認前一個程式碼格已成功執行。\")\n",
        "            # Define a minimal placeholder if not found\n",
        "            def process_and_insert_data_incrementally():\n",
        "                 print(\"Simulated incremental data insertion function placeholder executed.\")\n",
        "            process_and_insert_data_incrementally() # Call the placeholder\n",
        "    else:\n",
        "        print(f\"資料庫中已有 {count} 筆資料，跳過模擬資料插入。\")\n",
        "\n",
        "# Modify the API endpoint to fetch data from the database with pagination and filtering\n",
        "# Check if the endpoint 'get_activities' already exists to avoid re-adding it\n",
        "existing_rule = None\n",
        "for rule in app.url_map.iter_rules():\n",
        "    if rule.endpoint == 'get_activities' and '/api/activities' in rule.rule:\n",
        "        existing_rule = rule\n",
        "        break\n",
        "\n",
        "if existing_rule:\n",
        "    print(f\"移除現有路由 '{existing_rule.rule}'，端點名稱 '{existing_rule.endpoint}'\")\n",
        "    app.url_map._rules.remove(existing_rule)\n",
        "    # Also remove the endpoint from view_functions to be safe\n",
        "    if 'get_activities' in app.view_functions:\n",
        "         del app.view_functions['get_activities']\n",
        "\n",
        "@app.route('/api/activities', methods=['GET'])\n",
        "def get_activities():\n",
        "    \"\"\"\n",
        "    API endpoint to get processed activity data from the database with pagination and filtering.\n",
        "    Reads from the SQLite database.\n",
        "    Query Parameters:\n",
        "        - page: int (default: 1) - the page number\n",
        "        - limit: int (default: 10) - items per page\n",
        "        - search: str (optional) - keyword to search in activity_title or product\n",
        "    \"\"\"\n",
        "    conn = get_db_connection()\n",
        "    if conn is None:\n",
        "        print(\"無法建立資料庫連線。\")\n",
        "        return jsonify({\"error\": \"無法連接資料庫\"}), 500\n",
        "\n",
        "    try:\n",
        "        cursor = conn.cursor()\n",
        "\n",
        "        # Get query parameters with default values\n",
        "        page = request.args.get('page', 1, type=int)\n",
        "        limit = request.args.get('limit', 10, type=int)\n",
        "        search_term = request.args.get('search', type=str)\n",
        "\n",
        "        # Ensure page and limit are positive\n",
        "        if page <= 0:\n",
        "            page = 1\n",
        "        if limit <= 0:\n",
        "            limit = 10 # Default to 10 if invalid limit is provided\n",
        "\n",
        "        # Build the base query\n",
        "        base_query = \"SELECT activity_title, activity_time, product FROM activities\"\n",
        "        count_query = \"SELECT COUNT(*) FROM activities\"\n",
        "        where_clause = \"\"\n",
        "        query_params = []\n",
        "\n",
        "        # Add filtering if search term is provided\n",
        "        if search_term:\n",
        "            where_clause = \" WHERE activity_title LIKE ? OR product LIKE ?\"\n",
        "            # Use '%' for SQL LIKE matching\n",
        "            query_params = [f\"%{search_term}%\", f\"%{search_term}%\"]\n",
        "\n",
        "        # Construct the final queries\n",
        "        # Ensure ordering for consistent pagination\n",
        "        final_data_query = base_query + where_clause + \" ORDER BY activity_time DESC LIMIT ? OFFSET ?\"\n",
        "        final_count_query = count_query + where_clause\n",
        "\n",
        "        # Add pagination parameters to the data query params\n",
        "        data_query_params = query_params + [limit, (page - 1) * limit]\n",
        "\n",
        "        # Execute the count query first (considering filtering)\n",
        "        cursor.execute(final_count_query, query_params)\n",
        "        total_records = cursor.fetchone()[0]\n",
        "\n",
        "        # Calculate total pages\n",
        "        total_pages = math.ceil(total_records / limit) if limit > 0 else 0\n",
        "\n",
        "        # Execute the data query with filtering and pagination\n",
        "        cursor.execute(final_data_query, data_query_params)\n",
        "\n",
        "        # Fetch all rows and convert them to a list of dictionaries\n",
        "        activities = [dict(row) for row in cursor.fetchall()]\n",
        "\n",
        "        # Return the data along with pagination info in a dictionary\n",
        "        return jsonify({\n",
        "            \"activities\": activities,\n",
        "            \"total_records\": total_records,\n",
        "            \"total_pages\": total_pages,\n",
        "            \"current_page\": page,\n",
        "            \"items_per_page\": limit\n",
        "        })\n",
        "\n",
        "    except sqlite3.Error as e:\n",
        "        print(f\"查詢資料庫錯誤: {e}\")\n",
        "        return jsonify({\"error\": \"無法從資料庫獲取資料\"}), 500\n",
        "    except Exception as e:\n",
        "        print(f\"獲取活動資料時發生未知錯誤: {e}\")\n",
        "        return jsonify({\"error\": str(e)}), 500\n",
        "    finally:\n",
        "        # Ensure the database connection is closed\n",
        "        if conn:\n",
        "            conn.close()\n",
        "            # print(\"資料庫連線已關閉。\") # Optional: uncomment for detailed logging\n",
        "\n",
        "\n",
        "# Function to run the Flask app in a separate thread for notebook environment\n",
        "# Re-using the function definition from previous cells\n",
        "def run_flask_app():\n",
        "    print(\"Flask app正在背景執行緒中啟動 (本地測試)...\")\n",
        "    # Explicitly use Flask's built-in development server\n",
        "    # use_reloader=False is important to prevent issues with threading in notebooks\n",
        "    app.run(port=5000, debug=False, use_reloader=False)\n",
        "\n",
        "# Check if the thread is already running and port is free before starting\n",
        "def is_port_in_use(port):\n",
        "    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
        "        try:\n",
        "            s.bind(('localhost', port))\n",
        "            return False # Port is free\n",
        "        except socket.error:\n",
        "            return True # Port is in use\n",
        "\n",
        "# Check if the thread is alive or if the port is in use\n",
        "# Use locals() to check for the thread variable in the current scope\n",
        "if 'flask_thread' not in locals() or not flask_thread.is_alive():\n",
        "    if not is_port_in_use(5000):\n",
        "        flask_thread = threading.Thread(target=run_flask_app)\n",
        "        flask_thread.daemon = True # Allow the main thread to exit even if the Flask thread is running\n",
        "        flask_thread.start()\n",
        "        print(\"Flask app正在背景執行緒中啟動...\")\n",
        "        print(\"請等待片刻，然後執行下一個程式碼格來測試 API。\")\n",
        "    else:\n",
        "        print(\"Port 5000 已經在使用中，無法啟動 Flask app。\")\n",
        "        print(\"請嘗試重新啟動執行階段，或手動停止佔用 Port 5000 的程序。\")\n",
        "else:\n",
        "    print(\"Flask app已經在背景執行緒中運行。\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5edbc529"
      },
      "source": [
        "**Reasoning**:\n",
        "Test the updated `/api/activities` endpoint again to verify that pagination and filtering work correctly, as the previous test failed due to an incorrect API response structure. This involves making requests with different query parameters and checking the JSON response structure and content, which addresses the remaining steps of the subtask.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3a6c4a27"
      },
      "source": [
        "import requests\n",
        "import time\n",
        "import json # Import json to pretty print the response\n",
        "\n",
        "# Give the Flask app a moment to ensure the new endpoint is active (though it should be quick)\n",
        "time.sleep(2)\n",
        "\n",
        "print(\"--- 測試包含分頁和篩選功能的 API 端點 ---\")\n",
        "\n",
        "# Test Case 1: Get the first page with default limit (10)\n",
        "print(\"\\n測試案例 1: 獲取第一頁 (預設每頁筆數 10)...\")\n",
        "try:\n",
        "    response1 = requests.get('http://127.0.0.1:5000/api/activities')\n",
        "    if response1.status_code == 200:\n",
        "        data1 = response1.json()\n",
        "        print(\"API 請求成功。回應資料結構:\")\n",
        "        print(json.dumps(data1, indent=2))\n",
        "        # Verify the structure and content\n",
        "        if isinstance(data1, dict) and 'activities' in data1:\n",
        "            print(f\"總記錄數: {data1.get('total_records')}\")\n",
        "            print(f\"總頁數: {data1.get('total_pages')}\")\n",
        "            print(f\"目前頁碼: {data1.get('current_page')}\")\n",
        "            print(f\"每頁筆數: {data1.get('items_per_page')}\")\n",
        "            print(f\"獲取到的活動記錄筆數: {len(data1.get('activities', []))}\")\n",
        "            # Basic checks\n",
        "            assert data1.get('total_records') == 4, \"總記錄數不正確\"\n",
        "            assert data1.get('total_pages') == 1, \"總頁數不正確\"\n",
        "            assert data1.get('current_page') == 1, \"目前頁碼不正確\"\n",
        "            assert data1.get('items_per_page') == 10, \"每頁筆數不正確\"\n",
        "            assert len(data1.get('activities', [])) == 4, \"獲取到的活動記錄筆數不正確\"\n",
        "            print(\"測試案例 1 驗證成功。\")\n",
        "        else:\n",
        "             print(\"回應資料結構不正確。\")\n",
        "    else:\n",
        "        print(f\"API 請求失敗，狀態碼：{response1.status_code}\")\n",
        "        print(\"回應內容：\")\n",
        "        print(response1.text)\n",
        "except requests.exceptions.ConnectionError as e:\n",
        "    print(f\"無法連接到 Flask 應用程式。錯誤：{e}\")\n",
        "except AssertionError as e:\n",
        "    print(f\"測試案例 1 驗證失敗: {e}\")\n",
        "except Exception as e:\n",
        "    print(f\"測試 API 時發生錯誤：{e}\")\n",
        "\n",
        "\n",
        "# Test Case 2: Get the second page with a smaller limit (2)\n",
        "print(\"\\n測試案例 2: 獲取第二頁，每頁 2 筆...\")\n",
        "try:\n",
        "    response2 = requests.get('http://127.0.0.1:5000/api/activities?page=2&limit=2')\n",
        "    if response2.status_code == 200:\n",
        "        data2 = response2.json()\n",
        "        print(\"API 請求成功。回應資料結構:\")\n",
        "        print(json.dumps(data2, indent=2))\n",
        "        # Verify the structure and content\n",
        "        if isinstance(data2, dict) and 'activities' in data2:\n",
        "            print(f\"總記錄數: {data2.get('total_records')}\")\n",
        "            print(f\"總頁數: {data2.get('total_pages')}\")\n",
        "            print(f\"目前頁碼: {data2.get('current_page')}\")\n",
        "            print(f\"每頁筆數: {data2.get('items_per_page')}\")\n",
        "            print(f\"獲取到的活動記錄筆數: {len(data2.get('activities', []))}\")\n",
        "            # Basic checks\n",
        "            assert data2.get('total_records') == 4, \"總記錄數不正確\"\n",
        "            assert data2.get('total_pages') == 2, \"總頁數不正確\"\n",
        "            assert data2.get('current_page') == 2, \"目前頁碼不正確\"\n",
        "            assert data2.get('items_per_page') == 2, \"每頁筆數不正確\"\n",
        "            assert len(data2.get('activities', [])) == 2, \"獲取到的活動記錄筆數不正確\"\n",
        "            # Check content of the second page (based on DESC time order)\n",
        "            # The two oldest activities should be on the second page\n",
        "            # Assuming the oldest is \"Searched for example\" (product \"Web & App Activity\" or \"Search\") and \"Watched a video\"\n",
        "            # The exact order depends on the time strings and sorting, but we expect the last two from the full list\n",
        "            full_list_ordered_desc = sorted(data1.get('activities', []), key=lambda x: x['activity_time'], reverse=True) if 'activities' in data1 else []\n",
        "            expected_page_2 = full_list_ordered_desc[2:4] # Assuming 4 total records\n",
        "            retrieved_page_2 = data2.get('activities', [])\n",
        "            # Simple check: ensure titles from expected page 2 are in retrieved page 2\n",
        "            expected_titles = [item['activity_title'] for item in expected_page_2]\n",
        "            retrieved_titles = [item['activity_title'] for item in retrieved_page_2]\n",
        "            assert set(expected_titles) == set(retrieved_titles), \"第二頁的活動記錄不正確\"\n",
        "\n",
        "            print(\"測試案例 2 驗證成功。\")\n",
        "        else:\n",
        "             print(\"回應資料結構不正確。\")\n",
        "except requests.exceptions.ConnectionError as e:\n",
        "    print(f\"無法連接到 Flask 應用程式。錯誤：{e}\")\n",
        "except AssertionError as e:\n",
        "    print(f\"測試案例 2 驗證失敗: {e}\")\n",
        "except Exception as e:\n",
        "    print(f\"測試 API 時發生錯誤：{e}\")\n",
        "\n",
        "\n",
        "# Test Case 3: Search for a keyword (e.g., \"Search\")\n",
        "print(\"\\n測試案例 3: 搜尋關鍵字 'Search'...\")\n",
        "try:\n",
        "    response3 = requests.get('http://127.0.0.1:5000/api/activities?search=Search')\n",
        "    if response3.status_code == 200:\n",
        "        data3 = response3.json()\n",
        "        print(\"API 請求成功。回應資料結構:\")\n",
        "        print(json.dumps(data3, indent=2))\n",
        "        # Verify the structure and content\n",
        "        if isinstance(data3, dict) and 'activities' in data3:\n",
        "            print(f\"總記錄數 (篩選後): {data3.get('total_records')}\")\n",
        "            print(f\"總頁數 (篩選後): {data3.get('total_pages')}\")\n",
        "            print(f\"目前頁碼: {data3.get('current_page')}\")\n",
        "            print(f\"每頁筆數: {data3.get('items_per_page')}\")\n",
        "            print(f\"獲取到的活動記錄筆數: {len(data3.get('activities', []))}\")\n",
        "            # Basic checks (assuming \"Search\" appears in \"Searched for example\" title or \"Search\" product)\n",
        "            # Based on dummy data, there are two records matching \"Search\" (title or product)\n",
        "            assert data3.get('total_records') == 2, \"篩選後的總記錄數不正確\"\n",
        "            assert data3.get('total_pages') == 1, \"篩選後的總頁數不正確\"\n",
        "            assert data3.get('current_page') == 1, \"目前頁碼不正確\"\n",
        "            assert data3.get('items_per_page') == 10, \"每頁筆數不正確\"\n",
        "            assert len(data3.get('activities', [])) == 2, \"獲取到的活動記錄筆數不正確\"\n",
        "            # Check content - both records should contain \"Search\" in title or product\n",
        "            for activity in data3.get('activities', []):\n",
        "                title = activity.get('activity_title', '').lower()\n",
        "                product = activity.get('product', '').lower()\n",
        "                assert 'search' in title or 'search' in product, \"篩選結果包含不相關的記錄\"\n",
        "\n",
        "            print(\"測試案例 3 驗證成功。\")\n",
        "        else:\n",
        "             print(\"回應資料結構不正確。\")\n",
        "except requests.exceptions.ConnectionError as e:\n",
        "    print(f\"無法連接到 Flask 應用程式。錯誤：{e}\")\n",
        "except AssertionError as e:\n",
        "    print(f\"測試案例 3 驗證失敗: {e}\")\n",
        "except Exception as e:\n",
        "    print(f\"測試 API 時發生錯誤：{e}\")\n",
        "\n",
        "# Test Case 4: Search for a keyword and apply pagination (e.g., \"Google\", page 1, limit 1)\n",
        "print(\"\\n測試案例 4: 搜尋關鍵字 'Google'，第一頁，每頁 1 筆...\")\n",
        "try:\n",
        "    response4 = requests.get('http://127.0.0.1:5000/api/activities?search=Google&page=1&limit=1')\n",
        "    if response4.status_code == 200:\n",
        "        data4 = response4.json()\n",
        "        print(\"API 請求成功。回應資料結構:\")\n",
        "        print(json.dumps(data4, indent=2))\n",
        "        # Verify the structure and content\n",
        "        if isinstance(data4, dict) and 'activities' in data4:\n",
        "            print(f\"總記錄數 (篩選後): {data4.get('total_records')}\")\n",
        "            print(f\"總頁數 (篩選後): {data4.get('total_pages')}\")\n",
        "            print(f\"目前頁碼: {data4.get('current_page')}\")\n",
        "            print(f\"每頁筆數: {data4.get('items_per_page')}\")\n",
        "            print(f\"獲取到的活動記錄筆數: {len(data4.get('activities', []))}\")\n",
        "             # Basic checks (assuming \"Google\" appears in title or product)\n",
        "            # Based on dummy data, there are two records matching \"Google\" (title or product)\n",
        "            assert data4.get('total_records') == 2, \"篩選後的總記錄數不正確\"\n",
        "            assert data4.get('total_pages') == 2, \"篩選後的總頁數不正確 (每頁 1 筆)\"\n",
        "            assert data4.get('current_page') == 1, \"目前頁碼不正確\"\n",
        "            assert data4.get('items_per_page') == 1, \"每頁筆數不正確\"\n",
        "            assert len(data4.get('activities', [])) == 1, \"獲取到的活動記錄筆數不正確\"\n",
        "            # Check content - the first record should match \"Google\" search\n",
        "            activity = data4.get('activities', [])[0]\n",
        "            title = activity.get('activity_title', '').lower()\n",
        "            product = activity.get('product', '').lower()\n",
        "            assert 'google' in title or 'google' in product, \"篩選/分頁結果不正確\"\n",
        "\n",
        "            print(\"測試案例 4 驗證成功。\")\n",
        "        else:\n",
        "             print(\"回應資料結構不正確。\")\n",
        "except requests.exceptions.ConnectionError as e:\n",
        "    print(f\"無法連接到 Flask 應用程式。錯誤：{e}\")\n",
        "except AssertionError as e:\n",
        "    print(f\"測試案例 4 驗證失敗: {e}\")\n",
        "except Exception as e:\n",
        "    print(f\"測試 API 時發生錯誤：{e}\")\n",
        "\n",
        "\n",
        "print(\"\\n--- API 端點測試完成 ---\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42219a4a"
      },
      "source": [
        "**Reasoning**:\n",
        "The tests still show that the API endpoint is returning a list instead of the expected dictionary structure, despite modifying the code in the previous cell to return a dictionary. This suggests that the previous cell either didn't execute correctly, or the Flask app instance running in the background thread is still using the old code for the `get_activities` endpoint. To ensure the correct endpoint logic is used, I need to stop the currently running background Flask thread, redefine the `get_activities` function with the correct dictionary return, and then restart the Flask app in a new thread. This will ensure the test requests hit the updated endpoint code. This addresses the need to re-run the API with the correct logic to enable testing.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXraKvYfe_IK"
      },
      "source": [
        "import sqlite3\n",
        "import os\n",
        "import json\n",
        "from flask import Flask, jsonify, request # Import request to access query parameters\n",
        "import threading\n",
        "import time\n",
        "import socket\n",
        "import math # Import math for calculating total pages\n",
        "\n",
        "# Re-use the Flask app instance if it exists, or create a new one\n",
        "try:\n",
        "    app\n",
        "except NameError:\n",
        "    app = Flask(__name__)\n",
        "\n",
        "# --- Stop the existing Flask thread if it's running ---\n",
        "# Check if the thread object exists and is alive\n",
        "if 'flask_thread' in locals() and flask_thread.is_alive():\n",
        "    print(\"偵測到背景中的 Flask app 執行緒正在運行，嘗試停止...\")\n",
        "    # It's difficult to cleanly stop a thread running Flask's development server\n",
        "    # in this context. The best approach in a notebook is often to\n",
        "    # let the old thread die naturally or restart the kernel.\n",
        "    # However, we can try to signal or wait briefly.\n",
        "    # A simple approach for this simulation is to just proceed,\n",
        "    # hoping the new definition is picked up or the old thread will terminate.\n",
        "    # In a real application, you'd use proper signaling mechanisms.\n",
        "    print(\"無法直接停止執行緒。將嘗試重新定義 API 端點並重新啟動應用程式。\")\n",
        "\n",
        "\n",
        "# Re-use database configuration and helper functions\n",
        "# DATABASE_FILE, DATABASE_SCHEMA, create_database_and_table, get_db_connection\n",
        "# are assumed to be defined in previous cells and available in the kernel\n",
        "\n",
        "# Ensure the database and table exist and is populated with simulated data\n",
        "create_database_and_table()\n",
        "# Only insert simulated data if the table is empty to avoid duplicates on re-execution\n",
        "conn_check = get_db_connection()\n",
        "if conn_check:\n",
        "    cursor_check = conn_check.cursor()\n",
        "    cursor_check.execute(\"SELECT COUNT(*) FROM activities\")\n",
        "    count = cursor_check.fetchone()[0]\n",
        "    conn_check.close()\n",
        "    if count == 0:\n",
        "        print(\"資料庫為空，插入模擬資料...\")\n",
        "        # Assuming process_and_insert_data_incrementally() is defined and works\n",
        "        try:\n",
        "            process_and_insert_data_incrementally()\n",
        "        except NameError:\n",
        "            print(\"錯誤: process_and_insert_data_incrementally 函式未定義。請確認前一個程式碼格已成功執行。\")\n",
        "            # Define a minimal placeholder if not found\n",
        "            def process_and_insert_data_incrementally():\n",
        "                 print(\"Simulated incremental data insertion function placeholder executed.\")\n",
        "            process_and_insert_data_incrementally() # Call the placeholder\n",
        "    else:\n",
        "        print(f\"資料庫中已有 {count} 筆資料，跳過模擬資料插入。\")\n",
        "\n",
        "# Modify the API endpoint to fetch data from the database with pagination and filtering\n",
        "# Check if the endpoint 'get_activities' already exists to avoid re-adding it\n",
        "# More robust check and removal of existing rule\n",
        "existing_rule = None\n",
        "for rule in list(app.url_map.iter_rules()): # Iterate over a copy of the rules list\n",
        "    if rule.endpoint == 'get_activities' and '/api/activities' in rule.rule:\n",
        "        existing_rule = rule\n",
        "        break\n",
        "\n",
        "if existing_rule:\n",
        "    print(f\"移除現有路由 '{existing_rule.rule}'，端點名稱 '{existing_rule.endpoint}'\")\n",
        "    app.url_map._rules.remove(existing_rule)\n",
        "    # Also remove the endpoint from view_functions to be safe\n",
        "    if 'get_activities' in app.view_functions:\n",
        "         del app.view_functions['get_activities']\n",
        "\n",
        "\n",
        "# --- Redefine the API endpoint with the correct dictionary return structure ---\n",
        "@app.route('/api/activities', methods=['GET'])\n",
        "def get_activities():\n",
        "    \"\"\"\n",
        "    API endpoint to get processed activity data from the database with pagination and filtering.\n",
        "    Reads from the SQLite database.\n",
        "    Query Parameters:\n",
        "        - page: int (default: 1) - the page number\n",
        "        - limit: int (default: 10) - items per page\n",
        "        - search: str (optional) - keyword to search in activity_title or product\n",
        "    \"\"\"\n",
        "    conn = get_db_connection()\n",
        "    if conn is None:\n",
        "        print(\"無法建立資料庫連線。\")\n",
        "        return jsonify({\"error\": \"無法連接資料庫\"}), 500\n",
        "\n",
        "    try:\n",
        "        cursor = conn.cursor()\n",
        "\n",
        "        # Get query parameters with default values\n",
        "        page = request.args.get('page', 1, type=int)\n",
        "        limit = request.args.get('limit', 10, type=int)\n",
        "        search_term = request.args.get('search', type=str)\n",
        "\n",
        "        # Ensure page and limit are positive\n",
        "        if page <= 0:\n",
        "            page = 1\n",
        "        if limit <= 0:\n",
        "            limit = 10 # Default to 10 if invalid limit is provided\n",
        "\n",
        "        # Build the base query\n",
        "        base_query = \"SELECT activity_title, activity_time, product FROM activities\"\n",
        "        count_query = \"SELECT COUNT(*) FROM activities\"\n",
        "        where_clause = \"\"\n",
        "        query_params = []\n",
        "\n",
        "        # Add filtering if search term is provided\n",
        "        if search_term:\n",
        "            where_clause = \" WHERE activity_title LIKE ? OR product LIKE ?\"\n",
        "            # Use '%' for SQL LIKE matching\n",
        "            query_params = [f\"%{search_term}%\", f\"%{search_term}%\"]\n",
        "\n",
        "        # Construct the final queries\n",
        "        # Ensure ordering for consistent pagination (e.g., by time descending)\n",
        "        final_data_query = base_query + where_clause + \" ORDER BY activity_time DESC LIMIT ? OFFSET ?\"\n",
        "        final_count_query = count_query + where_clause\n",
        "\n",
        "        # Add pagination parameters to the data query params\n",
        "        offset = (page - 1) * limit\n",
        "        data_query_params = query_params + [limit, offset]\n",
        "\n",
        "        # Execute the count query first (considering filtering)\n",
        "        cursor.execute(final_count_query, query_params)\n",
        "        total_records = cursor.fetchone()[0]\n",
        "\n",
        "        # Calculate total pages\n",
        "        total_pages = math.ceil(total_records / limit) if limit > 0 else 0\n",
        "\n",
        "        # Execute the data query with filtering and pagination\n",
        "        cursor.execute(final_data_query, data_query_params)\n",
        "\n",
        "        # Fetch all rows and convert them to a list of dictionaries\n",
        "        activities = [dict(row) for row in cursor.fetchall()]\n",
        "\n",
        "        # --- Return the data along with pagination info in a dictionary ---\n",
        "        return jsonify({\n",
        "            \"activities\": activities,\n",
        "            \"total_records\": total_records,\n",
        "            \"total_pages\": total_pages,\n",
        "            \"current_page\": page,\n",
        "            \"items_per_page\": limit\n",
        "        })\n",
        "\n",
        "    except sqlite3.Error as e:\n",
        "        print(f\"查詢資料庫錯誤: {e}\")\n",
        "        return jsonify({\"error\": \"無法從資料庫獲取資料\"}), 500\n",
        "    except Exception as e:\n",
        "        print(f\"獲取活動資料時發生未知錯誤: {e}\")\n",
        "        return jsonify({\"error\": str(e)}), 500\n",
        "    finally:\n",
        "        # Ensure the database connection is closed\n",
        "        if conn:\n",
        "            conn.close()\n",
        "            # print(\"資料庫連線已關閉。\") # Optional: uncomment for detailed logging\n",
        "\n",
        "\n",
        "# Function to run the Flask app in a separate thread for notebook environment\n",
        "# Re-using the function definition from previous cells\n",
        "def run_flask_app():\n",
        "    print(\"Flask app正在背景執行緒中啟動 (本地測試)...\")\n",
        "    # Explicitly use Flask's built-in development server\n",
        "    # use_reloader=False is important to prevent issues with threading in notebooks\n",
        "    # Setting a different port just in case the old thread is still bound to 5000\n",
        "    try:\n",
        "        app.run(port=5001, debug=False, use_reloader=False)\n",
        "    except OSError as e:\n",
        "        print(f\"啟動 Flask app 失敗，可能是 Port 5001 已經在使用中。錯誤: {e}\")\n",
        "        print(\"請嘗試重新啟動執行階段，或手動停止佔用 Port 5001 的程序。\")\n",
        "\n",
        "\n",
        "# Check if the thread is already running and port is free before starting\n",
        "def is_port_in_use(port):\n",
        "    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
        "        try:\n",
        "            s.bind(('localhost', port))\n",
        "            return False # Port is free\n",
        "        except socket.error:\n",
        "            return True # Port is in use\n",
        "\n",
        "# Check if the thread is alive or if a suitable port is free before starting\n",
        "# Try port 5001 first, then fallback to 5000 if needed\n",
        "port_to_use = 5001\n",
        "if is_port_in_use(port_to_use):\n",
        "    print(f\"Port {port_to_use} 已經在使用中，嘗試 Port 5000...\")\n",
        "    port_to_use = 5000\n",
        "    if is_port_in_use(port_to_use):\n",
        "         print(f\"Port {port_to_use} 也已經在使用中。無法啟動 Flask app。\")\n",
        "         print(\"請嘗試重新啟動執行階段，或手動停止佔用這些 Port 的程序。\")\n",
        "         # Set flask_thread to None or a dummy to indicate no thread started\n",
        "         flask_thread = None\n",
        "    else:\n",
        "        # Port 5000 is free\n",
        "        if 'flask_thread' not in locals() or not (flask_thread and flask_thread.is_alive()):\n",
        "             flask_thread = threading.Thread(target=run_flask_app)\n",
        "             flask_thread.daemon = True\n",
        "             flask_thread.start()\n",
        "             print(f\"Flask app正在背景執行緒中啟動 (本地測試 Port {port_to_use})...\")\n",
        "             print(\"請等待片刻，然後執行下一個程式碼格來測試 API。\")\n",
        "        else:\n",
        "             print(\"Flask app已經在背景執行緒中運行 (可能是 Port 5000)。\")\n",
        "else:\n",
        "    # Port 5001 is free\n",
        "    if 'flask_thread' not in locals() or not (flask_thread and flask_thread.is_alive()):\n",
        "        flask_thread = threading.Thread(target=run_flask_app)\n",
        "        flask_thread.daemon = True\n",
        "        flask_thread.start()\n",
        "        print(f\"Flask app正在背景執行緒中啟動 (本地測試 Port {port_to_use})...\")\n",
        "        print(\"請等待片刻，然後執行下一個程式碼格來測試 API。\")\n",
        "    else:\n",
        "        print(f\"Flask app已經在背景執行緒中運行 (可能是 Port {port_to_use} 或 Port 5000)。\")\n",
        "\n",
        "# Store the port being used so the test script knows where to send requests\n",
        "flask_port = port_to_use\n",
        "print(f\"Flask app 預計運行在 Port {flask_port}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53ded77a"
      },
      "source": [
        "**Reasoning**:\n",
        "The Flask API endpoint has been redefined with the correct dictionary return structure and is running on a potentially different port (stored in `flask_port`). The next step is to re-run the API tests, this time using the `flask_port` variable to ensure requests are sent to the correct address and verifying that the JSON response structure and content match the expected format with pagination and filtering applied. This addresses the remaining steps of the subtask and validates the implementation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdb4e9a4"
      },
      "source": [
        "import requests\n",
        "import time\n",
        "import json\n",
        "\n",
        "# Give the Flask app a moment to ensure the new endpoint is active\n",
        "time.sleep(3)\n",
        "\n",
        "# Use the port determined in the previous cell\n",
        "# Ensure flask_port is defined, default to 5000 if not\n",
        "flask_port_to_test = locals().get('flask_port', 5000)\n",
        "\n",
        "print(f\"--- 測試包含分頁和篩選功能的 API 端點 (使用 Port {flask_port_to_test}) ---\")\n",
        "\n",
        "# Test Case 1: Get the first page with default limit (10)\n",
        "print(\"\\n測試案例 1: 獲取第一頁 (預設每頁筆數 10)...\")\n",
        "try:\n",
        "    response1 = requests.get(f'http://127.0.0.1:{flask_port_to_test}/api/activities')\n",
        "    if response1.status_code == 200:\n",
        "        data1 = response1.json()\n",
        "        print(\"API 請求成功。回應資料結構:\")\n",
        "        print(json.dumps(data1, indent=2, ensure_ascii=False)) # ensure_ascii=False for Chinese characters\n",
        "        # Verify the structure and content\n",
        "        if isinstance(data1, dict) and 'activities' in data1 and 'total_records' in data1 and 'total_pages' in data1:\n",
        "            print(f\"總記錄數: {data1.get('total_records')}\")\n",
        "            print(f\"總頁數: {data1.get('total_pages')}\")\n",
        "            print(f\"目前頁碼: {data1.get('current_page')}\")\n",
        "            print(f\"每頁筆數: {data1.get('items_per_page')}\")\n",
        "            print(f\"獲取到的活動記錄筆數: {len(data1.get('activities', []))}\")\n",
        "            # Basic checks\n",
        "            assert data1.get('total_records') == 4, \"總記錄數不正確\"\n",
        "            assert data1.get('total_pages') == 1, \"總頁數不正確\"\n",
        "            assert data1.get('current_page') == 1, \"目前頁碼不正確\"\n",
        "            assert data1.get('items_per_page') == 10, \"每頁筆數不正確\"\n",
        "            assert len(data1.get('activities', [])) == 4, \"獲取到的活動記錄筆數不正確\"\n",
        "            print(\"測試案例 1 驗證成功。\")\n",
        "        else:\n",
        "             print(\"回應資料結構不正確。\")\n",
        "    else:\n",
        "        print(f\"API 請求失敗，狀態碼：{response1.status_code}\")\n",
        "        print(\"回應內容：\")\n",
        "        print(response1.text)\n",
        "except requests.exceptions.ConnectionError as e:\n",
        "    print(f\"無法連接到 Flask 應用程式 Port {flask_port_to_test}。錯誤：{e}\")\n",
        "except AssertionError as e:\n",
        "    print(f\"測試案例 1 驗證失敗: {e}\")\n",
        "except Exception as e:\n",
        "    print(f\"測試 API 時發生錯誤：{e}\")\n",
        "\n",
        "\n",
        "# Test Case 2: Get the second page with a smaller limit (2)\n",
        "print(\"\\n測試案例 2: 獲取第二頁，每頁 2 筆...\")\n",
        "try:\n",
        "    response2 = requests.get(f'http://127.0.0.1:{flask_port_to_test}/api/activities?page=2&limit=2')\n",
        "    if response2.status_code == 200:\n",
        "        data2 = response2.json()\n",
        "        print(\"API 請求成功。回應資料結構:\")\n",
        "        print(json.dumps(data2, indent=2, ensure_ascii=False))\n",
        "        # Verify the structure and content\n",
        "        if isinstance(data2, dict) and 'activities' in data2 and 'total_records' in data2 and 'total_pages' in data2:\n",
        "            print(f\"總記錄數: {data2.get('total_records')}\")\n",
        "            print(f\"總頁數: {data2.get('total_pages')}\")\n",
        "            print(f\"目前頁碼: {data2.get('current_page')}\")\n",
        "            print(f\"每頁筆數: {data2.get('items_per_page')}\")\n",
        "            print(f\"獲取到的活動記錄筆數: {len(data2.get('activities', []))}\")\n",
        "            # Basic checks\n",
        "            assert data2.get('total_records') == 4, \"總記錄數不正確\"\n",
        "            assert data2.get('total_pages') == 2, \"總頁數不正確\"\n",
        "            assert data2.get('current_page') == 2, \"目前頁碼不正確\"\n",
        "            assert data2.get('items_per_page') == 2, \"每頁筆數不正確\"\n",
        "            assert len(data2.get('activities', [])) == 2, \"獲取到的活動記錄筆數不正確\"\n",
        "            # Check content of the second page (based on DESC time order)\n",
        "            # Fetch all data to determine expected order for verification\n",
        "            response_all = requests.get(f'http://127.0.0.1:{flask_port_to_test}/api/activities?limit=100') # Get enough data to cover all\n",
        "            all_activities_data = response_all.json().get('activities', []) if response_all.status_code == 200 else []\n",
        "            full_list_ordered_desc = sorted(all_activities_data, key=lambda x: x.get('activity_time', ''), reverse=True)\n",
        "            expected_page_2 = full_list_ordered_desc[2:4] # Assuming 4 total records\n",
        "            retrieved_page_2 = data2.get('activities', [])\n",
        "\n",
        "            # Simple check: ensure titles and times from expected page 2 are in retrieved page 2\n",
        "            expected_items = [(item.get('activity_title'), item.get('activity_time')) for item in expected_page_2]\n",
        "            retrieved_items = [(item.get('activity_title'), item.get('activity_time')) for item in retrieved_page_2]\n",
        "\n",
        "            assert set(expected_items) == set(retrieved_items), \"第二頁的活動記錄不正確\"\n",
        "\n",
        "            print(\"測試案例 2 驗證成功。\")\n",
        "        else:\n",
        "             print(\"回應資料結構不正確。\")\n",
        "except requests.exceptions.ConnectionError as e:\n",
        "    print(f\"無法連接到 Flask 應用程式 Port {flask_port_to_test}。錯誤：{e}\")\n",
        "except AssertionError as e:\n",
        "    print(f\"測試案例 2 驗證失敗: {e}\")\n",
        "except Exception as e:\n",
        "    print(f\"測試 API 時發生錯誤：{e}\")\n",
        "\n",
        "\n",
        "# Test Case 3: Search for a keyword (e.g., \"Search\")\n",
        "print(\"\\n測試案例 3: 搜尋關鍵字 'Search'...\")\n",
        "try:\n",
        "    response3 = requests.get(f'http://127.0.0.1:{flask_port_to_test}/api/activities?search=Search')\n",
        "    if response3.status_code == 200:\n",
        "        data3 = response3.json()\n",
        "        print(\"API 請求成功。回應資料結構:\")\n",
        "        print(json.dumps(data3, indent=2, ensure_ascii=False))\n",
        "        # Verify the structure and content\n",
        "        if isinstance(data3, dict) and 'activities' in data3 and 'total_records' in data3 and 'total_pages' in data3:\n",
        "            print(f\"總記錄數 (篩選後): {data3.get('total_records')}\")\n",
        "            print(f\"總頁數 (篩選後): {data3.get('total_pages')}\")\n",
        "            print(f\"目前頁碼: {data3.get('current_page')}\")\n",
        "            print(f\"每頁筆數: {data3.get('items_per_page')}\")\n",
        "            print(f\"獲取到的活動記錄筆數: {len(data3.get('activities', []))}\")\n",
        "            # Basic checks (assuming \"Search\" appears in \"Searched for example\" title or \"Search\" product)\n",
        "            # Based on dummy data, there are two records matching \"Search\" (title or product)\n",
        "            assert data3.get('total_records') == 2, \"篩選後的總記錄數不正確\"\n",
        "            assert data3.get('total_pages') == 1, \"篩選後的總頁數不正確\"\n",
        "            assert data3.get('current_page') == 1, \"目前頁碼不正確\"\n",
        "            assert data3.get('items_per_page') == 10, \"每頁筆數不正確\"\n",
        "            assert len(data3.get('activities', [])) == 2, \"獲取到的活動記錄筆數不正確\"\n",
        "            # Check content - both records should contain \"Search\" in title or product\n",
        "            for activity in data3.get('activities', []):\n",
        "                title = activity.get('activity_title', '').lower()\n",
        "                product = activity.get('product', '').lower()\n",
        "                assert 'search' in title or 'search' in product, \"篩選結果包含不相關的記錄\"\n",
        "\n",
        "            print(\"測試案例 3 驗證成功。\")\n",
        "        else:\n",
        "             print(\"回應資料結構不正確。\")\n",
        "except requests.exceptions.ConnectionError as e:\n",
        "    print(f\"無法連接到 Flask 應用程式 Port {flask_port_to_test}。錯誤：{e}\")\n",
        "except AssertionError as e:\n",
        "    print(f\"測試案例 3 驗證失敗: {e}\")\n",
        "except Exception as e:\n",
        "    print(f\"測試 API 時發生錯誤：{e}\")\n",
        "\n",
        "# Test Case 4: Search for a keyword and apply pagination (e.g., \"Google\", page 1, limit 1)\n",
        "print(\"\\n測試案例 4: 搜尋關鍵字 'Google'，第一頁，每頁 1 筆...\")\n",
        "try:\n",
        "    response4 = requests.get(f'http://127.0.0.1:{flask_port_to_test}/api/activities?search=Google&page=1&limit=1')\n",
        "    if response4.status_code == 200:\n",
        "        data4 = response4.json()\n",
        "        print(\"API 請求成功。回應資料結構:\")\n",
        "        print(json.dumps(data4, indent=2, ensure_ascii=False))\n",
        "        # Verify the structure and content\n",
        "        if isinstance(data4, dict) and 'activities' in data4 and 'total_records' in data4 and 'total_pages' in data4:\n",
        "            print(f\"總記錄數 (篩選後): {data4.get('total_records')}\")\n",
        "            print(f\"總頁數 (篩選後): {data4.get('total_pages')}\")\n",
        "            print(f\"目前頁碼: {data4.get('current_page')}\")\n",
        "            print(f\"每頁筆數: {data4.get('items_per_page')}\")\n",
        "            print(f\"獲取到的活動記錄筆數: {len(data4.get('activities', []))}\")\n",
        "             # Basic checks (assuming \"Google\" appears in title or product)\n",
        "            # Based on dummy data, there are two records matching \"Google\" (title or product)\n",
        "            assert data4.get('total_records') == 2, \"篩選後的總記錄數不正確\"\n",
        "            assert data4.get('total_pages') == 2, \"篩選後的總頁數不正確 (每頁 1 筆)\"\n",
        "            assert data4.get('current_page') == 1, \"目前頁碼不正確\"\n",
        "            assert data4.get('items_per_page') == 1, \"每頁筆數不正確\"\n",
        "            assert len(data4.get('activities', [])) == 1, \"獲取到的活動記錄筆數不正確\"\n",
        "            # Check content - the first record should match \"Google\" search and be the latest from the filtered set\n",
        "            # Get the filtered list and sort it to find the expected first item\n",
        "            response_filtered = requests.get(f'http://127.0.0.1:{flask_port_to_test}/api/activities?search=Google&limit=100')\n",
        "            filtered_activities_all = response_filtered.json().get('activities', []) if response_filtered.status_code == 200 else []\n",
        "            filtered_ordered_desc = sorted(filtered_activities_all, key=lambda x: x.get('activity_time', ''), reverse=True)\n",
        "            if filtered_ordered_desc:\n",
        "                 expected_first_item = filtered_ordered_desc[0]\n",
        "                 retrieved_first_item = data4.get('activities', [])[0]\n",
        "                 assert expected_first_item.get('activity_title') == retrieved_first_item.get('activity_title') and \\\n",
        "                        expected_first_item.get('activity_time') == retrieved_first_item.get('activity_time'), \\\n",
        "                        \"篩選/分頁結果不正確 (第一筆記錄不符合預期)\"\n",
        "            else:\n",
        "                 assert len(data4.get('activities', [])) == 0, \"沒有預期結果時不應返回活動記錄\"\n",
        "\n",
        "\n",
        "            print(\"測試案例 4 驗證成功。\")\n",
        "        else:\n",
        "             print(\"回應資料結構不正確。\")\n",
        "except requests.exceptions.ConnectionError as e:\n",
        "    print(f\"無法連接到 Flask 應用程式 Port {flask_port_to_test}。錯誤：{e}\")\n",
        "except AssertionError as e:\n",
        "    print(f\"測試案例 4 驗證失敗: {e}\")\n",
        "except Exception as e:\n",
        "    print(f\"測試 API 時發生錯誤：{e}\")\n",
        "\n",
        "\n",
        "print(\"\\n--- API 端點測試完成 ---\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "248ef987"
      },
      "source": [
        "**Reasoning**:\n",
        "The API tests failed because the connection to the Flask app on port 5001 was refused. This indicates that the Flask development server is not running or not accessible on that port. This could be due to the background thread not starting correctly, or the port being blocked. I need to ensure the Flask app is running before testing. I will try to start the Flask app again in a separate thread, ensuring it attempts to use port 5001, and add a longer delay before attempting the tests to give the server more time to start. I will also add more verbose output during the Flask app startup process. This addresses the need to have the API running for the tests to succeed.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9fa61bc"
      },
      "source": [
        "import sqlite3\n",
        "import os\n",
        "import json\n",
        "from flask import Flask, jsonify, request # Import request to access query parameters\n",
        "import threading\n",
        "import time\n",
        "import socket\n",
        "import math\n",
        "\n",
        "# Re-use the Flask app instance if it exists, or create a new one\n",
        "try:\n",
        "    app\n",
        "except NameError:\n",
        "    app = Flask(__name__)\n",
        "\n",
        "# --- Stop the existing Flask thread if it's running ---\n",
        "# Check if the thread object exists and is alive\n",
        "if 'flask_thread' in locals() and flask_thread.is_alive():\n",
        "    print(\"偵測到背景中的 Flask app 執行緒正在運行，嘗試停止...\")\n",
        "    # It's difficult to cleanly stop a thread running Flask's development server\n",
        "    # in this context. The best approach in a notebook is often to\n",
        "    # let the old thread die naturally or restart the kernel.\n",
        "    # However, we can try to signal or wait briefly.\n",
        "    # A simple approach for this simulation is to just proceed,\n",
        "    # hoping the new definition is picked up or the old thread will terminate.\n",
        "    # In a real application, you'd use proper signaling mechanisms.\n",
        "    print(\"無法直接停止執行緒。將嘗試重新定義 API 端點並重新啟動應用程式。\")\n",
        "\n",
        "\n",
        "# Re-use database configuration and helper functions\n",
        "# DATABASE_FILE, DATABASE_SCHEMA, create_database_and_table, get_db_connection\n",
        "# are assumed to be defined in previous cells and available in the kernel\n",
        "\n",
        "# Ensure the database and table exist and is populated with simulated data\n",
        "create_database_and_table()\n",
        "# Only insert simulated data if the table is empty to avoid duplicates on re-execution\n",
        "conn_check = get_db_connection()\n",
        "if conn_check:\n",
        "    cursor_check = conn_check.cursor()\n",
        "    cursor_check.execute(\"SELECT COUNT(*) FROM activities\")\n",
        "    count = cursor_check.fetchone()[0]\n",
        "    conn_check.close()\n",
        "    if count == 0:\n",
        "        print(\"資料庫為空，插入模擬資料...\")\n",
        "        # Assuming process_and_insert_data_incrementally() is defined and works\n",
        "        try:\n",
        "            process_and_insert_data_incrementally()\n",
        "        except NameError:\n",
        "            print(\"錯誤: process_and_insert_data_incrementally 函式未定義。請確認前一個程式碼格已成功執行。\")\n",
        "            # Define a minimal placeholder if not found\n",
        "            def process_and_insert_data_incrementally():\n",
        "                 print(\"Simulated incremental data insertion function placeholder executed.\")\n",
        "            process_and_insert_data_incrementally() # Call the placeholder\n",
        "    else:\n",
        "        print(f\"資料庫中已有 {count} 筆資料，跳過模擬資料插入。\")\n",
        "\n",
        "# Modify the API endpoint to fetch data from the database with pagination and filtering\n",
        "# Check if the endpoint 'get_activities' already exists to avoid re-adding it\n",
        "# More robust check and removal of existing rule\n",
        "existing_rule = None\n",
        "for rule in list(app.url_map.iter_rules()): # Iterate over a copy of the rules list\n",
        "    if rule.endpoint == 'get_activities' and '/api/activities' in rule.rule:\n",
        "        existing_rule = rule\n",
        "        break\n",
        "\n",
        "if existing_rule:\n",
        "    print(f\"移除現有路由 '{existing_rule.rule}'，端點名稱 '{existing_rule.endpoint}'\")\n",
        "    app.url_map._rules.remove(existing_rule)\n",
        "    # Also remove the endpoint from view_functions to be safe\n",
        "    if 'get_activities' in app.view_functions:\n",
        "         del app.view_functions['get_activities']\n",
        "\n",
        "\n",
        "# --- Redefine the API endpoint with the correct dictionary return structure ---\n",
        "@app.route('/api/activities', methods=['GET'])\n",
        "def get_activities():\n",
        "    \"\"\"\n",
        "    API endpoint to get processed activity data from the database with pagination and filtering.\n",
        "    Reads from the SQLite database.\n",
        "    Query Parameters:\n",
        "        - page: int (default: 1) - the page number\n",
        "        - limit: int (default: 10) - items per page\n",
        "        - search: str (optional) - keyword to search in activity_title or product\n",
        "    \"\"\"\n",
        "    conn = get_db_connection()\n",
        "    if conn is None:\n",
        "        print(\"無法建立資料庫連線。\")\n",
        "        return jsonify({\"error\": \"無法連接資料庫\"}), 500\n",
        "\n",
        "    try:\n",
        "        cursor = conn.cursor()\n",
        "\n",
        "        # Get query parameters with default values\n",
        "        page = request.args.get('page', 1, type=int)\n",
        "        limit = request.args.get('limit', 10, type=int)\n",
        "        search_term = request.args.get('search', type=str)\n",
        "\n",
        "        # Ensure page and limit are positive\n",
        "        if page <= 0:\n",
        "            page = 1\n",
        "        if limit <= 0:\n",
        "            limit = 10 # Default to 10 if invalid limit is provided\n",
        "\n",
        "        # Build the base query\n",
        "        base_query = \"SELECT activity_title, activity_time, product FROM activities\"\n",
        "        count_query = \"SELECT COUNT(*) FROM activities\"\n",
        "        where_clause = \"\"\n",
        "        query_params = []\n",
        "\n",
        "        # Add filtering if search term is provided\n",
        "        if search_term:\n",
        "            where_clause = \" WHERE activity_title LIKE ? OR product LIKE ?\"\n",
        "            # Use '%' for SQL LIKE matching\n",
        "            query_params = [f\"%{search_term}%\", f\"%{search_term}%\"]\n",
        "\n",
        "        # Construct the final queries\n",
        "        # Ensure ordering for consistent pagination (e.g., by time descending)\n",
        "        final_data_query = base_query + where_clause + \" ORDER BY activity_time DESC LIMIT ? OFFSET ?\"\n",
        "        final_count_query = count_query + where_clause\n",
        "\n",
        "        # Add pagination parameters to the data query params\n",
        "        offset = (page - 1) * limit\n",
        "        data_query_params = query_params + [limit, offset]\n",
        "\n",
        "        # Execute the count query first (considering filtering)\n",
        "        cursor.execute(final_count_query, query_params)\n",
        "        total_records = cursor.fetchone()[0]\n",
        "\n",
        "        # Calculate total pages\n",
        "        total_pages = math.ceil(total_records / limit) if limit > 0 else 0\n",
        "\n",
        "        # Execute the data query with filtering and pagination\n",
        "        cursor.execute(final_data_query, data_query_params)\n",
        "\n",
        "        # Fetch all rows and convert them to a list of dictionaries\n",
        "        activities = [dict(row) for row in cursor.fetchall()]\n",
        "\n",
        "        # --- Return the data along with pagination info in a dictionary ---\n",
        "        return jsonify({\n",
        "            \"activities\": activities,\n",
        "            \"total_records\": total_records,\n",
        "            \"total_pages\": total_pages,\n",
        "            \"current_page\": page,\n",
        "            \"items_per_page\": limit\n",
        "        })\n",
        "\n",
        "    except sqlite3.Error as e:\n",
        "        print(f\"查詢資料庫錯誤: {e}\")\n",
        "        return jsonify({\"error\": \"無法從資料庫獲取資料\"}), 500\n",
        "    except Exception as e:\n",
        "        print(f\"獲取活動資料時發生未知錯誤: {e}\")\n",
        "        return jsonify({\"error\": str(e)}), 500\n",
        "    finally:\n",
        "        # Ensure the database connection is closed\n",
        "        if conn:\n",
        "            conn.close()\n",
        "            # print(\"資料庫連線已關閉。\") # Optional: uncomment for detailed logging\n",
        "\n",
        "\n",
        "# Function to run the Flask app in a separate thread for notebook environment\n",
        "# Re-using the function definition from previous cells\n",
        "def run_flask_app(port):\n",
        "    print(f\"Flask app正在背景執行緒中啟動 (本地測試 Port {port})...\")\n",
        "    # Explicitly use Flask's built-in development server\n",
        "    # use_reloader=False is important to prevent issues with threading in notebooks\n",
        "    try:\n",
        "        # Use the provided port\n",
        "        app.run(port=port, debug=False, use_reloader=False)\n",
        "    except OSError as e:\n",
        "        print(f\"啟動 Flask app 失敗，可能是 Port {port} 已經在使用中。錯誤: {e}\")\n",
        "        print(\"請嘗試重新啟動執行階段，或手動停止佔用 Port {port} 的程序。\")\n",
        "\n",
        "\n",
        "# Check if the thread is already running and port is free before starting\n",
        "def is_port_in_use(port):\n",
        "    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
        "        try:\n",
        "            s.bind(('localhost', port))\n",
        "            return False # Port is free\n",
        "        except socket.error:\n",
        "            return True # Port is in use\n",
        "\n",
        "# Check if the thread is alive or if a suitable port is free before starting\n",
        "# Try port 5001 first, then fallback to 5000 if needed\n",
        "port_to_use = 5001\n",
        "if is_port_in_use(port_to_use):\n",
        "    print(f\"Port {port_to_use} 已經在使用中，嘗試 Port 5000...\")\n",
        "    port_to_use = 5000\n",
        "    if is_port_in_use(port_to_use):\n",
        "         print(f\"Port {port_to_use} 也已經在使用中。無法啟動 Flask app。\")\n",
        "         print(\"請嘗試重新啟動執行階段，或手動停止佔用 Port {port} 的程序。\")\n",
        "         # Set flask_thread to None or a dummy to indicate no thread started\n",
        "         flask_thread = None\n",
        "    else:\n",
        "        # Port 5000 is free\n",
        "        if 'flask_thread' not in locals() or not (flask_thread and flask_thread.is_alive()):\n",
        "             flask_thread = threading.Thread(target=run_flask_app, args=(port_to_use,)) # Pass port to the target function\n",
        "             flask_thread.daemon = True\n",
        "             flask_thread.start()\n",
        "             print(f\"Flask app正在背景執行緒中啟動 (本地測試 Port {port_to_use})...\")\n",
        "             print(\"請等待片刻，然後執行下一個程式碼格來測試 API。\")\n",
        "        else:\n",
        "             print(\"Flask app已經在背景執行緒中運行 (可能是 Port 5000)。\")\n",
        "else:\n",
        "    # Port 5001 is free\n",
        "    if 'flask_thread' not in locals() or not (flask_thread and flask_thread.is_alive()):\n",
        "        flask_thread = threading.Thread(target=run_flask_app, args=(port_to_use,)) # Pass port to the target function\n",
        "        flask_thread.daemon = True\n",
        "        flask_thread.start()\n",
        "        print(f\"Flask app正在背景執行緒中啟動 (本地測試 Port {port_to_use})...\")\n",
        "        print(\"請等待片刻，然後執行下一個程式碼格來測試 API。\")\n",
        "    else:\n",
        "        print(f\"Flask app已經在背景執行緒中運行 (可能是 Port {port_to_use} 或 Port 5000)。\")\n",
        "\n",
        "# Store the port being used so the test script knows where to send requests\n",
        "flask_port = port_to_use\n",
        "print(f\"Flask app 預計運行在 Port {flask_port}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4e808ff"
      },
      "source": [
        "**Reasoning**:\n",
        "The Flask app should now be running in a background thread with the corrected API endpoint logic on the `flask_port` determined in the previous step. The next step is to re-run the API tests using the `flask_port` variable to confirm that the API returns the data in the correct dictionary format and that the pagination and filtering parameters are handled correctly. This will fully address the subtask of modifying and testing the `/api/activities` endpoint with pagination and filtering.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a430971f"
      },
      "source": [
        "import requests\n",
        "import time\n",
        "import json\n",
        "\n",
        "# Give the Flask app a moment to ensure the new endpoint is active\n",
        "time.sleep(3)\n",
        "\n",
        "# Use the port determined in the previous cell\n",
        "# Ensure flask_port is defined, default to 5000 if not\n",
        "flask_port_to_test = locals().get('flask_port', 5000)\n",
        "\n",
        "print(f\"--- 測試包含分頁和篩選功能的 API 端點 (使用 Port {flask_port_to_test}) ---\")\n",
        "\n",
        "# Test Case 1: Get the first page with default limit (10)\n",
        "print(\"\\n測試案例 1: 獲取第一頁 (預設每頁筆數 10)...\")\n",
        "try:\n",
        "    response1 = requests.get(f'http://127.0.0.1:{flask_port_to_test}/api/activities')\n",
        "    if response1.status_code == 200:\n",
        "        data1 = response1.json()\n",
        "        print(\"API 請求成功。回應資料結構:\")\n",
        "        print(json.dumps(data1, indent=2, ensure_ascii=False)) # ensure_ascii=False for Chinese characters\n",
        "        # Verify the structure and content\n",
        "        if isinstance(data1, dict) and 'activities' in data1 and 'total_records' in data1 and 'total_pages' in data1:\n",
        "            print(f\"總記錄數: {data1.get('total_records')}\")\n",
        "            print(f\"總頁數: {data1.get('total_pages')}\")\n",
        "            print(f\"目前頁碼: {data1.get('current_page')}\")\n",
        "            print(f\"每頁筆數: {data1.get('items_per_page')}\")\n",
        "            print(f\"獲取到的活動記錄筆數: {len(data1.get('activities', []))}\")\n",
        "            # Basic checks\n",
        "            assert data1.get('total_records') == 4, \"總記錄數不正確\"\n",
        "            assert data1.get('total_pages') == 1, \"總頁數不正確\"\n",
        "            assert data1.get('current_page') == 1, \"目前頁碼不正確\"\n",
        "            assert data1.get('items_per_page') == 10, \"每頁筆數不正確\"\n",
        "            assert len(data1.get('activities', [])) == 4, \"獲取到的活動記錄筆數不正確\"\n",
        "            print(\"測試案例 1 驗證成功。\")\n",
        "        else:\n",
        "             print(\"回應資料結構不正確。\")\n",
        "    else:\n",
        "        print(f\"API 請求失敗，狀態碼：{response1.status_code}\")\n",
        "        print(\"回應內容：\")\n",
        "        print(response1.text)\n",
        "except requests.exceptions.ConnectionError as e:\n",
        "    print(f\"無法連接到 Flask 應用程式 Port {flask_port_to_test}。錯誤：{e}\")\n",
        "except AssertionError as e:\n",
        "    print(f\"測試案例 1 驗證失敗: {e}\")\n",
        "except Exception as e:\n",
        "    print(f\"測試 API 時發生錯誤：{e}\")\n",
        "\n",
        "\n",
        "# Test Case 2: Get the second page with a smaller limit (2)\n",
        "print(\"\\n測試案例 2: 獲取第二頁，每頁 2 筆...\")\n",
        "try:\n",
        "    response2 = requests.get(f'http://127.0.0.1:{flask_port_to_test}/api/activities?page=2&limit=2')\n",
        "    if response2.status_code == 200:\n",
        "        data2 = response2.json()\n",
        "        print(\"API 請求成功。回應資料結構:\")\n",
        "        print(json.dumps(data2, indent=2, ensure_ascii=False))\n",
        "        # Verify the structure and content\n",
        "        if isinstance(data2, dict) and 'activities' in data2 and 'total_records' in data2 and 'total_pages' in data2:\n",
        "            print(f\"總記錄數: {data2.get('total_records')}\")\n",
        "            print(f\"總頁數: {data2.get('total_pages')}\")\n",
        "            print(f\"目前頁碼: {data2.get('current_page')}\")\n",
        "            print(f\"每頁筆數: {data2.get('items_per_page')}\")\n",
        "            print(f\"獲取到的活動記錄筆數: {len(data2.get('activities', []))}\")\n",
        "            # Basic checks\n",
        "            assert data2.get('total_records') == 4, \"總記錄數不正確\"\n",
        "            assert data2.get('total_pages') == 2, \"總頁數不正確\"\n",
        "            assert data2.get('current_page') == 2, \"目前頁碼不正確\"\n",
        "            assert data2.get('items_per_page') == 2, \"每頁筆數不正確\"\n",
        "            assert len(data2.get('activities', [])) == 2, \"獲取到的活動記錄筆數不正確\"\n",
        "            # Check content of the second page (based on DESC time order)\n",
        "            # Fetch all data to determine expected order for verification\n",
        "            response_all = requests.get(f'http://127.0.0.1:{flask_port_to_test}/api/activities?limit=100') # Get enough data to cover all\n",
        "            all_activities_data = response_all.json().get('activities', []) if response_all.status_code == 200 else []\n",
        "            full_list_ordered_desc = sorted(all_activities_data, key=lambda x: x.get('activity_time', ''), reverse=True)\n",
        "            expected_page_2 = full_list_ordered_desc[2:4] # Assuming 4 total records\n",
        "            retrieved_page_2 = data2.get('activities', [])\n",
        "\n",
        "            # Simple check: ensure titles and times from expected page 2 are in retrieved page 2\n",
        "            expected_items = [(item.get('activity_title'), item.get('activity_time')) for item in expected_page_2]\n",
        "            retrieved_items = [(item.get('activity_title'), item.get('activity_time')) for item in retrieved_page_2]\n",
        "\n",
        "            assert set(expected_items) == set(retrieved_items), \"第二頁的活動記錄不正確\"\n",
        "\n",
        "            print(\"測試案例 2 驗證成功。\")\n",
        "        else:\n",
        "             print(\"回應資料結構不正確。\")\n",
        "except requests.exceptions.ConnectionError as e:\n",
        "    print(f\"無法連接到 Flask 應用程式 Port {flask_port_to_test}。錯誤：{e}\")\n",
        "except AssertionError as e:\n",
        "    print(f\"測試案例 2 驗證失敗: {e}\")\n",
        "except Exception as e:\n",
        "    print(f\"測試 API 時發生錯誤：{e}\")\n",
        "\n",
        "\n",
        "# Test Case 3: Search for a keyword (e.g., \"Search\")\n",
        "print(\"\\n測試案例 3: 搜尋關鍵字 'Search'...\")\n",
        "try:\n",
        "    response3 = requests.get(f'http://127.0.0.1:{flask_port_to_test}/api/activities?search=Search')\n",
        "    if response3.status_code == 200:\n",
        "        data3 = response3.json()\n",
        "        print(\"API 請求成功。回應資料結構:\")\n",
        "        print(json.dumps(data3, indent=2, ensure_ascii=False))\n",
        "        # Verify the structure and content\n",
        "        if isinstance(data3, dict) and 'activities' in data3 and 'total_records' in data3 and 'total_pages' in data3:\n",
        "            print(f\"總記錄數 (篩選後): {data3.get('total_records')}\")\n",
        "            print(f\"總頁數 (篩選後): {data3.get('total_pages')}\")\n",
        "            print(f\"目前頁碼: {data3.get('current_page')}\")\n",
        "            print(f\"每頁筆數: {data3.get('items_per_page')}\")\n",
        "            print(f\"獲取到的活動記錄筆數: {len(data3.get('activities', []))}\")\n",
        "            # Basic checks (assuming \"Search\" appears in \"Searched for example\" title or \"Search\" product)\n",
        "            # Based on dummy data, there are two records matching \"Search\" (title or product)\n",
        "            assert data3.get('total_records') == 2, \"篩選後的總記錄數不正確\"\n",
        "            assert data3.get('total_pages') == 1, \"篩選後的總頁數不正確\"\n",
        "            assert data3.get('current_page') == 1, \"目前頁碼不正確\"\n",
        "            assert data3.get('items_per_page') == 10, \"每頁筆數不正確\"\n",
        "            assert len(data3.get('activities', [])) == 2, \"獲取到的活動記錄筆數不正確\"\n",
        "            # Check content - both records should contain \"Search\" in title or product\n",
        "            for activity in data3.get('activities', []):\n",
        "                title = activity.get('activity_title', '').lower()\n",
        "                product = activity.get('product', '').lower()\n",
        "                assert 'search' in title or 'search' in product, \"篩選結果包含不相關的記錄\"\n",
        "\n",
        "            print(\"測試案例 3 驗證成功。\")\n",
        "        else:\n",
        "             print(\"回應資料結構不正確。\")\n",
        "except requests.exceptions.ConnectionError as e:\n",
        "    print(f\"無法連接到 Flask 應用程式 Port {flask_port_to_test}。錯誤：{e}\")\n",
        "except AssertionError as e:\n",
        "    print(f\"測試案例 3 驗證失敗: {e}\")\n",
        "except Exception as e:\n",
        "    print(f\"測試 API 時發生錯誤：{e}\")\n",
        "\n",
        "# Test Case 4: Search for a keyword and apply pagination (e.g., \"Google\", page 1, limit 1)\n",
        "print(\"\\n測試案例 4: 搜尋關鍵字 'Google'，第一頁，每頁 1 筆...\")\n",
        "try:\n",
        "    response4 = requests.get(f'http://127.0.0.1:{flask_port_to_test}/api/activities?search=Google&page=1&limit=1')\n",
        "    if response4.status_code == 200:\n",
        "        data4 = response4.json()\n",
        "        print(\"API 請求成功。回應資料結構:\")\n",
        "        print(json.dumps(data4, indent=2, ensure_ascii=False))\n",
        "        # Verify the structure and content\n",
        "        if isinstance(data4, dict) and 'activities' in data4 and 'total_records' in data4 and 'total_pages' in data4:\n",
        "            print(f\"總記錄數 (篩選後): {data4.get('total_records')}\")\n",
        "            print(f\"總頁數 (篩選後): {data4.get('total_pages')}\")\n",
        "            print(f\"目前頁碼: {data4.get('current_page')}\")\n",
        "            print(f\"每頁筆數: {data4.get('items_per_page')}\")\n",
        "            print(f\"獲取到的活動記錄筆數: {len(data4.get('activities', []))}\")\n",
        "             # Basic checks (assuming \"Google\" appears in title or product)\n",
        "            # Based on dummy data, there are two records matching \"Google\" (title or product)\n",
        "            assert data4.get('total_records') == 2, \"篩選後的總記錄數不正確\"\n",
        "            assert data4.get('total_pages') == 2, \"篩選後的總頁數不正確 (每頁 1 筆)\"\n",
        "            assert data4.get('current_page') == 1, \"目前頁碼不正確\"\n",
        "            assert data4.get('items_per_page') == 1, \"每頁筆數不正確\"\n",
        "            assert len(data4.get('activities', [])) == 1, \"獲取到的活動記錄筆數不正確\"\n",
        "            # Check content - the first record should match \"Google\" search and be the latest from the filtered set\n",
        "            # Get the filtered list and sort it to find the expected first item\n",
        "            response_filtered = requests.get(f'http://127.0.0.1:{flask_port_to_test}/api/activities?search=Google&limit=100')\n",
        "            filtered_activities_all = response_filtered.json().get('activities', []) if response_filtered.status_code == 200 else []\n",
        "            filtered_ordered_desc = sorted(filtered_activities_all, key=lambda x: x.get('activity_time', ''), reverse=True)\n",
        "            if filtered_ordered_desc:\n",
        "                 expected_first_item = filtered_ordered_desc[0]\n",
        "                 retrieved_first_item = data4.get('activities', [])[0]\n",
        "                 assert expected_first_item.get('activity_title') == retrieved_first_item.get('activity_title') and \\\n",
        "                        expected_first_item.get('activity_time') == retrieved_first_item.get('activity_time'), \\\n",
        "                        \"篩選/分頁結果不正確 (第一筆記錄不符合預期)\"\n",
        "            else:\n",
        "                 assert len(data4.get('activities', [])) == 0, \"沒有預期結果時不應返回活動記錄\"\n",
        "\n",
        "\n",
        "            print(\"測試案例 4 驗證成功。\")\n",
        "        else:\n",
        "             print(\"回應資料結構不正確。\")\n",
        "except requests.exceptions.ConnectionError as e:\n",
        "    print(f\"無法連接到 Flask 應用程式 Port {flask_port_to_test}。錯誤：{e}\")\n",
        "except AssertionError as e:\n",
        "    print(f\"測試案例 4 驗證失敗: {e}\")\n",
        "except Exception as e:\n",
        "    print(f\"測試 API 時發生錯誤：{e}\")\n",
        "\n",
        "\n",
        "print(\"\\n--- API 端點測試完成 ---\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6e646666"
      },
      "source": [
        "## 測試更新的資料處理\n",
        "\n",
        "### Subtask:\n",
        "執行修改後的資料處理程式碼，並驗證資料庫中的資料是否按預期進行增量更新，沒有重複記錄。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7990334"
      },
      "source": [
        "**Reasoning**:\n",
        "Execute the code block containing the `process_and_insert_data_incrementally()` function call and the `verify_data_in_db()` function call to perform the incremental data update and verify the database content.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ea117b4f"
      },
      "source": [
        "# Execute the incremental data processing and insertion/update function\n",
        "# Assuming process_and_insert_data_incrementally() is defined in a previous cell\n",
        "try:\n",
        "    process_and_insert_data_incrementally()\n",
        "except NameError:\n",
        "    print(\"錯誤: process_and_insert_data_incrementally 函式未定義。請確認前一個程式碼格已成功執行。\")\n",
        "    # Define a minimal placeholder if not found\n",
        "    def process_and_insert_data_incrementally():\n",
        "         print(\"Simulated incremental data insertion function placeholder executed.\")\n",
        "    process_and_insert_data_incrementally() # Call the placeholder\n",
        "\n",
        "\n",
        "# Verify the data in the database after incremental update\n",
        "# Re-using the function definition from previous cells\n",
        "def verify_data_in_db():\n",
        "    conn = get_db_connection()\n",
        "    if conn:\n",
        "        cursor = conn.cursor()\n",
        "        cursor.execute(\"SELECT COUNT(*) FROM activities\")\n",
        "        count = cursor.fetchone()[0]\n",
        "        print(f\"\\n資料庫中目前的活動記錄總筆數: {count}\")\n",
        "        cursor.execute(\"SELECT id, activity_title, activity_time, product FROM activities ORDER BY activity_time LIMIT 10\") # Show first 10 records, ordered by time\n",
        "        rows = cursor.fetchall()\n",
        "        print(\"資料庫中前 10 筆記錄 (包含 ID):\")\n",
        "        for row in rows:\n",
        "            print(dict(row)) # Print as dictionary\n",
        "        conn.close()\n",
        "    else:\n",
        "        print(\"無法建立資料庫連線，無法驗證資料。\")\n",
        "\n",
        "\n",
        "verify_data_in_db()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05f876a3"
      },
      "source": [
        "## 更新後端 api\n",
        "\n",
        "### Subtask:\n",
        "修改 `/api/activities` 接口，使其從 SQLite 資料庫中讀取資料，並支援分頁和篩選功能。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2c2ec010"
      },
      "source": [
        "**Reasoning**:\n",
        "Modify the `/api/activities` endpoint in the Flask application to fetch data from the SQLite database and support pagination and filtering based on query parameters. This involves getting parameters for page, limit, and search from the request, building dynamic SQL queries with `WHERE`, `LIMIT`, and `OFFSET` clauses, executing both a count query and a data query, calculating total pages, and returning the results and pagination information in a dictionary as a JSON response, ensuring database connection management. This addresses instructions 1 through 11 of the subtask. I will also set the Flask app to run on port 5001 to avoid conflicts with previous runs and update the test script accordingly (instructions 12 and 13 will be handled by setting the port and including the test script in the response).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dea04c8"
      },
      "source": [
        "import sqlite3\n",
        "import os\n",
        "import json\n",
        "from flask import Flask, jsonify, request # Import request to access query parameters\n",
        "import threading\n",
        "import time\n",
        "import socket\n",
        "import math # Import math for calculating total pages\n",
        "\n",
        "# Re-use the Flask app instance if it exists, or create a new one\n",
        "try:\n",
        "    app\n",
        "except NameError:\n",
        "    app = Flask(__name__)\n",
        "\n",
        "# --- Stop the existing Flask thread if it's running ---\n",
        "# Check if the thread object exists and is alive\n",
        "if 'flask_thread' in locals() and flask_thread.is_alive():\n",
        "    print(\"偵測到背景中的 Flask app 執行緒正在運行，嘗試停止...\")\n",
        "    # It's difficult to cleanly stop a thread running Flask's development server\n",
        "    # in this context. The best approach in a notebook is often to\n",
        "    # let the old thread die naturally or restart the kernel.\n",
        "    # However, we can try to signal or wait briefly.\n",
        "    # A simple approach for this simulation is to just proceed,\n",
        "    # hoping the new definition is picked up or the old thread will terminate.\n",
        "    # In a real application, you'd use proper signaling mechanisms.\n",
        "    print(\"無法直接停止執行緒。將嘗試重新定義 API 端點並重新啟動應用程式。\")\n",
        "\n",
        "\n",
        "# Re-use database configuration and helper functions\n",
        "# DATABASE_FILE, DATABASE_SCHEMA, create_database_and_table, get_db_connection\n",
        "# are assumed to be defined in previous cells and available in the kernel\n",
        "\n",
        "# Ensure the database and table exist and is populated with simulated data\n",
        "create_database_and_table()\n",
        "# Only insert simulated data if the table is empty to avoid duplicates on re-execution\n",
        "conn_check = get_db_connection()\n",
        "if conn_check:\n",
        "    cursor_check = conn_check.cursor()\n",
        "    cursor_check.execute(\"SELECT COUNT(*) FROM activities\")\n",
        "    count = cursor_check.fetchone()[0]\n",
        "    conn_check.close()\n",
        "    if count == 0:\n",
        "        print(\"資料庫為空，插入模擬資料...\")\n",
        "        # Assuming process_and_insert_data_incrementally() is defined and works\n",
        "        try:\n",
        "            process_and_insert_data_incrementally()\n",
        "        except NameError:\n",
        "            print(\"錯誤: process_and_insert_data_incrementally 函式未定義。請確認前一個程式碼格已成功執行。\")\n",
        "            # Define a minimal placeholder if not found\n",
        "            def process_and_insert_data_incrementally():\n",
        "                 print(\"Simulated incremental data insertion function placeholder executed.\")\n",
        "            process_and_insert_data_incrementally() # Call the placeholder\n",
        "    else:\n",
        "        print(f\"資料庫中已有 {count} 筆資料，跳過模擬資料插入。\")\n",
        "\n",
        "# Modify the API endpoint to fetch data from the database with pagination and filtering\n",
        "# Check if the endpoint 'get_activities' already exists to avoid re-adding it\n",
        "# More robust check and removal of existing rule\n",
        "existing_rule = None\n",
        "for rule in list(app.url_map.iter_rules()): # Iterate over a copy of the rules list\n",
        "    if rule.endpoint == 'get_activities' and '/api/activities' in rule.rule:\n",
        "        existing_rule = rule\n",
        "        break\n",
        "\n",
        "if existing_rule:\n",
        "    print(f\"移除現有路由 '{existing_rule.rule}'，端點名稱 '{existing_rule.endpoint}'\")\n",
        "    app.url_map._rules.remove(existing_rule)\n",
        "    # Also remove the endpoint from view_functions to be safe\n",
        "    if 'get_activities' in app.view_functions:\n",
        "         del app.view_functions['get_activities']\n",
        "\n",
        "\n",
        "# --- Redefine the API endpoint with the correct dictionary return structure ---\n",
        "@app.route('/api/activities', methods=['GET'])\n",
        "def get_activities():\n",
        "    \"\"\"\n",
        "    API endpoint to get processed activity data from the database with pagination and filtering.\n",
        "    Reads from the SQLite database.\n",
        "    Query Parameters:\n",
        "        - page: int (default: 1) - the page number\n",
        "        - limit: int (default: 10) - items per page\n",
        "        - search: str (optional) - keyword to search in activity_title or product\n",
        "    \"\"\"\n",
        "    conn = get_db_connection()\n",
        "    if conn is None:\n",
        "        print(\"無法建立資料庫連線。\")\n",
        "        return jsonify({\"error\": \"無法連接資料庫\"}), 500\n",
        "\n",
        "    try:\n",
        "        cursor = conn.cursor()\n",
        "\n",
        "        # Get query parameters with default values\n",
        "        page = request.args.get('page', 1, type=int)\n",
        "        limit = request.args.get('limit', 10, type=int)\n",
        "        search_term = request.args.get('search', type=str)\n",
        "\n",
        "        # Ensure page and limit are positive\n",
        "        if page <= 0:\n",
        "            page = 1\n",
        "        if limit <= 0:\n",
        "            limit = 10 # Default to 10 if invalid limit is provided\n",
        "\n",
        "        # Build the base query\n",
        "        base_query = \"SELECT activity_title, activity_time, product FROM activities\"\n",
        "        count_query = \"SELECT COUNT(*) FROM activities\"\n",
        "        where_clause = \"\"\n",
        "        query_params = []\n",
        "\n",
        "        # Add filtering if search term is provided\n",
        "        if search_term:\n",
        "            where_clause = \" WHERE activity_title LIKE ? OR product LIKE ?\"\n",
        "            # Use '%' for SQL LIKE matching\n",
        "            query_params = [f\"%{search_term}%\", f\"%{search_term}%\"]\n",
        "\n",
        "        # Construct the final queries\n",
        "        # Ensure ordering for consistent pagination (e.g., by time descending)\n",
        "        final_data_query = base_query + where_clause + \" ORDER BY activity_time DESC LIMIT ? OFFSET ?\"\n",
        "        final_count_query = count_query + where_clause\n",
        "\n",
        "        # Add pagination parameters to the data query params\n",
        "        offset = (page - 1) * limit\n",
        "        data_query_params = query_params + [limit, offset]\n",
        "\n",
        "        # Execute the count query first (considering filtering)\n",
        "        cursor.execute(final_count_query, query_params)\n",
        "        total_records = cursor.fetchone()[0]\n",
        "\n",
        "        # Calculate total pages\n",
        "        total_pages = math.ceil(total_records / limit) if limit > 0 else 0\n",
        "\n",
        "        # Execute the data query with filtering and pagination\n",
        "        cursor.execute(final_data_query, data_query_params)\n",
        "\n",
        "        # Fetch all rows and convert them to a list of dictionaries\n",
        "        activities = [dict(row) for row in cursor.fetchall()]\n",
        "\n",
        "        # --- Return the data along with pagination info in a dictionary ---\n",
        "        return jsonify({\n",
        "            \"activities\": activities,\n",
        "            \"total_records\": total_records,\n",
        "            \"total_pages\": total_pages,\n",
        "            \"current_page\": page,\n",
        "            \"items_per_page\": limit\n",
        "        })\n",
        "\n",
        "    except sqlite3.Error as e:\n",
        "        print(f\"查詢資料庫錯誤: {e}\")\n",
        "        return jsonify({\"error\": \"無法從資料庫獲取資料\"}), 500\n",
        "    except Exception as e:\n",
        "        print(f\"獲取活動資料時發生未知錯誤: {e}\")\n",
        "        return jsonify({\"error\": str(e)}), 500\n",
        "    finally:\n",
        "        # Ensure the database connection is closed\n",
        "        if conn:\n",
        "            conn.close()\n",
        "            # print(\"資料庫連線已關閉。\") # Optional: uncomment for detailed logging\n",
        "\n",
        "\n",
        "# Function to run the Flask app in a separate thread for notebook environment\n",
        "# Re-using the function definition from previous cells\n",
        "def run_flask_app(port):\n",
        "    print(f\"Flask app正在背景執行緒中啟動 (本地測試 Port {port})...\")\n",
        "    # Explicitly use Flask's built-in development server\n",
        "    # use_reloader=False is important to prevent issues with threading in notebooks\n",
        "    try:\n",
        "        # Use the provided port\n",
        "        app.run(port=port, debug=False, use_reloader=False)\n",
        "    except OSError as e:\n",
        "        print(f\"啟動 Flask app 失敗，可能是 Port {port} 已經在使用中。錯誤: {e}\")\n",
        "        print(\"請嘗試重新啟動執行階段，或手動停止佔用 Port {port} 的程序。\")\n",
        "\n",
        "\n",
        "# Check if the thread is already running and port is free before starting\n",
        "def is_port_in_use(port):\n",
        "    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
        "        try:\n",
        "            s.bind(('localhost', port))\n",
        "            return False # Port is free\n",
        "        except socket.error:\n",
        "            return True # Port is in use\n",
        "\n",
        "# Check if the thread is alive or if a suitable port is free before starting\n",
        "# Try port 5001 first, then fallback to 5000 if needed\n",
        "port_to_use = 5001\n",
        "if is_port_in_use(port_to_use):\n",
        "    print(f\"Port {port_to_use} 已經在使用中，嘗試 Port 5000...\")\n",
        "    port_to_use = 5000\n",
        "    if is_port_in_use(port_to_use):\n",
        "         print(f\"Port {port_to_use} 也已經在使用中。無法啟動 Flask app。\")\n",
        "         print(\"請嘗試重新啟動執行階段，或手動停止佔用 Port {port} 的程序。\")\n",
        "         # Set flask_thread to None or a dummy to indicate no thread started\n",
        "         flask_thread = None\n",
        "    else:\n",
        "        # Port 5000 is free\n",
        "        if 'flask_thread' not in locals() or not (flask_thread and flask_thread.is_alive()):\n",
        "             flask_thread = threading.Thread(target=run_flask_app, args=(port_to_use,)) # Pass port to the target function\n",
        "             flask_thread.daemon = True\n",
        "             flask_thread.start()\n",
        "             print(f\"Flask app正在背景執行緒中啟動 (本地測試 Port {port_to_use})...\")\n",
        "             print(\"請等待片刻，然後執行下一個程式碼格來測試 API。\")\n",
        "        else:\n",
        "             print(\"Flask app已經在背景執行緒中運行 (可能是 Port 5000)。\")\n",
        "else:\n",
        "    # Port 5001 is free\n",
        "    if 'flask_thread' not in locals() or not (flask_thread and flask_thread.is_alive()):\n",
        "        flask_thread = threading.Thread(target=run_flask_app, args=(port_to_use,)) # Pass port to the target function\n",
        "        flask_thread.daemon = True\n",
        "        flask_thread.start()\n",
        "        print(f\"Flask app正在背景執行緒中啟動 (本地測試 Port {port_to_use})...\")\n",
        "        print(\"請等待片刻，然後執行下一個程式碼格來測試 API。\")\n",
        "    else:\n",
        "        print(f\"Flask app已經在背景執行緒中運行 (可能是 Port {port_to_use} 或 Port 5000)。\")\n",
        "\n",
        "# Store the port being used so the test script knows where to send requests\n",
        "flask_port = port_to_use\n",
        "print(f\"Flask app 預計運行在 Port {flask_port}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81735b9e"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the Flask API endpoint has been updated to support pagination and filtering and is running in a background thread, I need to test the modified endpoint to verify that the pagination and filtering features are working correctly. This involves making HTTP requests to the API with different query parameters (`page`, `limit`, `search`) and checking the structure and content of the JSON responses. This addresses steps 13 and the testing aspect of the subtask.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63d2fc47"
      },
      "source": [
        "import requests\n",
        "import time\n",
        "import json\n",
        "\n",
        "# Give the Flask app a moment to ensure the new endpoint is active\n",
        "time.sleep(3)\n",
        "\n",
        "# Use the port determined in the previous cell\n",
        "# Ensure flask_port is defined, default to 5000 if not\n",
        "flask_port_to_test = locals().get('flask_port', 5000)\n",
        "\n",
        "print(f\"--- 測試包含分頁和篩選功能的 API 端點 (使用 Port {flask_port_to_test}) ---\")\n",
        "\n",
        "# Test Case 1: Get the first page with default limit (10)\n",
        "print(\"\\n測試案例 1: 獲取第一頁 (預設每頁筆數 10)...\")\n",
        "try:\n",
        "    response1 = requests.get(f'http://127.0.0.1:{flask_port_to_test}/api/activities')\n",
        "    if response1.status_code == 200:\n",
        "        data1 = response1.json()\n",
        "        print(\"API 請求成功。回應資料結構:\")\n",
        "        print(json.dumps(data1, indent=2, ensure_ascii=False)) # ensure_ascii=False for Chinese characters\n",
        "        # Verify the structure and content\n",
        "        if isinstance(data1, dict) and 'activities' in data1 and 'total_records' in data1 and 'total_pages' in data1:\n",
        "            print(f\"總記錄數: {data1.get('total_records')}\")\n",
        "            print(f\"總頁數: {data1.get('total_pages')}\")\n",
        "            print(f\"目前頁碼: {data1.get('current_page')}\")\n",
        "            print(f\"每頁筆數: {data1.get('items_per_page')}\")\n",
        "            print(f\"獲取到的活動記錄筆數: {len(data1.get('activities', []))}\")\n",
        "            # Basic checks\n",
        "            assert data1.get('total_records') == 4, \"總記錄數不正確\"\n",
        "            assert data1.get('total_pages') == 1, \"總頁數不正確\"\n",
        "            assert data1.get('current_page') == 1, \"目前頁碼不正確\"\n",
        "            assert data1.get('items_per_page') == 10, \"每頁筆數不正確\"\n",
        "            assert len(data1.get('activities', [])) == 4, \"獲取到的活動記錄筆數不正確\"\n",
        "            print(\"測試案例 1 驗證成功。\")\n",
        "        else:\n",
        "             print(\"回應資料結構不正確。\")\n",
        "    else:\n",
        "        print(f\"API 請求失敗，狀態碼：{response1.status_code}\")\n",
        "        print(\"回應內容：\")\n",
        "        print(response1.text)\n",
        "except requests.exceptions.ConnectionError as e:\n",
        "    print(f\"無法連接到 Flask 應用程式 Port {flask_port_to_test}。錯誤：{e}\")\n",
        "except AssertionError as e:\n",
        "    print(f\"測試案例 1 驗證失敗: {e}\")\n",
        "except Exception as e:\n",
        "    print(f\"測試 API 時發生錯誤：{e}\")\n",
        "\n",
        "\n",
        "# Test Case 2: Get the second page with a smaller limit (2)\n",
        "print(\"\\n測試案例 2: 獲取第二頁，每頁 2 筆...\")\n",
        "try:\n",
        "    response2 = requests.get(f'http://127.0.0.1:{flask_port_to_test}/api/activities?page=2&limit=2')\n",
        "    if response2.status_code == 200:\n",
        "        data2 = response2.json()\n",
        "        print(\"API 請求成功。回應資料結構:\")\n",
        "        print(json.dumps(data2, indent=2, ensure_ascii=False))\n",
        "        # Verify the structure and content\n",
        "        if isinstance(data2, dict) and 'activities' in data2 and 'total_records' in data2 and 'total_pages' in data2:\n",
        "            print(f\"總記錄數: {data2.get('total_records')}\")\n",
        "            print(f\"總頁數: {data2.get('total_pages')}\")\n",
        "            print(f\"目前頁碼: {data2.get('current_page')}\")\n",
        "            print(f\"每頁筆數: {data2.get('items_per_page')}\")\n",
        "            print(f\"獲取到的活動記錄筆數: {len(data2.get('activities', []))}\")\n",
        "            # Basic checks\n",
        "            assert data2.get('total_records') == 4, \"總記錄數不正確\"\n",
        "            assert data2.get('total_pages') == 2, \"總頁數不正確\"\n",
        "            assert data2.get('current_page') == 2, \"目前頁碼不正確\"\n",
        "            assert data2.get('items_per_page') == 2, \"每頁筆數不正確\"\n",
        "            assert len(data2.get('activities', [])) == 2, \"獲取到的活動記錄筆數不正確\"\n",
        "            # Check content of the second page (based on DESC time order)\n",
        "            # Fetch all data to determine expected order for verification\n",
        "            response_all = requests.get(f'http://127.0.0.1:{flask_port_to_test}/api/activities?limit=100') # Get enough data to cover all\n",
        "            all_activities_data = response_all.json().get('activities', []) if response_all.status_code == 200 else []\n",
        "            full_list_ordered_desc = sorted(all_activities_data, key=lambda x: x.get('activity_time', ''), reverse=True)\n",
        "            expected_page_2 = full_list_ordered_desc[2:4] # Assuming 4 total records\n",
        "            retrieved_page_2 = data2.get('activities', [])\n",
        "\n",
        "            # Simple check: ensure titles and times from expected page 2 are in retrieved page 2\n",
        "            expected_items = [(item.get('activity_title'), item.get('activity_time')) for item in expected_page_2]\n",
        "            retrieved_items = [(item.get('activity_title'), item.get('activity_time')) for item in retrieved_page_2]\n",
        "\n",
        "            assert set(expected_items) == set(retrieved_items), \"第二頁的活動記錄不正確\"\n",
        "\n",
        "            print(\"測試案例 2 驗證成功。\")\n",
        "        else:\n",
        "             print(\"回應資料結構不正確。\")\n",
        "except requests.exceptions.ConnectionError as e:\n",
        "    print(f\"無法連接到 Flask 應用程式 Port {flask_port_to_test}。錯誤：{e}\")\n",
        "except AssertionError as e:\n",
        "    print(f\"測試案例 2 驗證失敗: {e}\")\n",
        "except Exception as e:\n",
        "    print(f\"測試 API 時發生錯誤：{e}\")\n",
        "\n",
        "\n",
        "# Test Case 3: Search for a keyword (e.g., \"Search\")\n",
        "print(\"\\n測試案例 3: 搜尋關鍵字 'Search'...\")\n",
        "try:\n",
        "    response3 = requests.get(f'http://127.0.0.1:{flask_port_to_test}/api/activities?search=Search')\n",
        "    if response3.status_code == 200:\n",
        "        data3 = response3.json()\n",
        "        print(\"API 請求成功。回應資料結構:\")\n",
        "        print(json.dumps(data3, indent=2, ensure_ascii=False))\n",
        "        # Verify the structure and content\n",
        "        if isinstance(data3, dict) and 'activities' in data3 and 'total_records' in data3 and 'total_pages' in data3:\n",
        "            print(f\"總記錄數 (篩選後): {data3.get('total_records')}\")\n",
        "            print(f\"總頁數 (篩選後): {data3.get('total_pages')}\")\n",
        "            print(f\"目前頁碼: {data3.get('current_page')}\")\n",
        "            print(f\"每頁筆數: {data3.get('items_per_page')}\")\n",
        "            print(f\"獲取到的活動記錄筆數: {len(data3.get('activities', []))}\")\n",
        "            # Basic checks (assuming \"Search\" appears in \"Searched for example\" title or \"Search\" product)\n",
        "            # Based on dummy data, there are two records matching \"Search\" (title or product)\n",
        "            assert data3.get('total_records') == 2, \"篩選後的總記錄數不正確\"\n",
        "            assert data3.get('total_pages') == 1, \"篩選後的總頁數不正確\"\n",
        "            assert data3.get('current_page') == 1, \"目前頁碼不正確\"\n",
        "            assert data3.get('items_per_page') == 10, \"每頁筆數不正確\"\n",
        "            assert len(data3.get('activities', [])) == 2, \"獲取到的活動記錄筆數不正確\"\n",
        "            # Check content - both records should contain \"Search\" in title or product\n",
        "            for activity in data3.get('activities', []):\n",
        "                title = activity.get('activity_title', '').lower()\n",
        "                product = activity.get('product', '').lower()\n",
        "                assert 'search' in title or 'search' in product, \"篩選結果包含不相關的記錄\"\n",
        "\n",
        "            print(\"測試案例 3 驗證成功。\")\n",
        "        else:\n",
        "             print(\"回應資料結構不正確。\")\n",
        "except requests.exceptions.ConnectionError as e:\n",
        "    print(f\"無法連接到 Flask 應用程式 Port {flask_port_to_test}。錯誤：{e}\")\n",
        "except AssertionError as e:\n",
        "    print(f\"測試案例 3 驗證失敗: {e}\")\n",
        "except Exception as e:\n",
        "    print(f\"測試 API 時發生錯誤：{e}\")\n",
        "\n",
        "# Test Case 4: Search for a keyword and apply pagination (e.g., \"Google\", page 1, limit 1)\n",
        "print(\"\\n測試案例 4: 搜尋關鍵字 'Google'，第一頁，每頁 1 筆...\")\n",
        "try:\n",
        "    response4 = requests.get(f'http://127.0.0.1:{flask_port_to_test}/api/activities?search=Google&page=1&limit=1')\n",
        "    if response4.status_code == 200:\n",
        "        data4 = response4.json()\n",
        "        print(\"API 請求成功。回應資料結構:\")\n",
        "        print(json.dumps(data4, indent=2, ensure_ascii=False))\n",
        "        # Verify the structure and content\n",
        "        if isinstance(data4, dict) and 'activities' in data4 and 'total_records' in data4 and 'total_pages' in data4:\n",
        "            print(f\"總記錄數 (篩選後): {data4.get('total_records')}\")\n",
        "            print(f\"總頁數 (篩選後): {data4.get('total_pages')}\")\n",
        "            print(f\"目前頁碼: {data4.get('current_page')}\")\n",
        "            print(f\"每頁筆數: {data4.get('items_per_page')}\")\n",
        "            print(f\"獲取到的活動記錄筆數: {len(data4.get('activities', []))}\")\n",
        "             # Basic checks (assuming \"Google\" appears in title or product)\n",
        "            # Based on dummy data, there are two records matching \"Google\" (title or product)\n",
        "            assert data4.get('total_records') == 2, \"篩選後的總記錄數不正確\"\n",
        "            assert data4.get('total_pages') == 2, \"篩選後的總頁數不正確 (每頁 1 筆)\"\n",
        "            assert data4.get('current_page') == 1, \"目前頁碼不正確\"\n",
        "            assert data4.get('items_per_page') == 1, \"每頁筆數不正確\"\n",
        "            assert len(data4.get('activities', [])) == 1, \"獲取到的活動記錄筆數不正確\"\n",
        "            # Check content - the first record should match \"Google\" search and be the latest from the filtered set\n",
        "            # Get the filtered list and sort it to find the expected first item\n",
        "            response_filtered = requests.get(f'http://127.0.0.1:{flask_port_to_test}/api/activities?search=Google&limit=100')\n",
        "            filtered_activities_all = response_filtered.json().get('activities', []) if response_filtered.status_code == 200 else []\n",
        "            filtered_ordered_desc = sorted(filtered_activities_all, key=lambda x: x.get('activity_time', ''), reverse=True)\n",
        "            if filtered_ordered_desc:\n",
        "                 expected_first_item = filtered_ordered_desc[0]\n",
        "                 retrieved_first_item = data4.get('activities', [])[0]\n",
        "                 assert expected_first_item.get('activity_title') == retrieved_first_item.get('activity_title') and \\\n",
        "                        expected_first_item.get('activity_time') == retrieved_first_item.get('activity_time'), \\\n",
        "                        \"篩選/分頁結果不正確 (第一筆記錄不符合預期)\"\n",
        "            else:\n",
        "                 assert len(data4.get('activities', [])) == 0, \"沒有預期結果時不應返回活動記錄\"\n",
        "\n",
        "\n",
        "            print(\"測試案例 4 驗證成功。\")\n",
        "        else:\n",
        "             print(\"回應資料結構不正確。\")\n",
        "except requests.exceptions.ConnectionError as e:\n",
        "    print(f\"無法連接到 Flask 應用程式 Port {flask_port_to_test}。錯誤：{e}\")\n",
        "except AssertionError as e:\n",
        "    print(f\"測試案例 4 驗證失敗: {e}\")\n",
        "except Exception as e:\n",
        "    print(f\"測試 API 時發生錯誤：{e}\")\n",
        "\n",
        "\n",
        "print(\"\\n--- API 端點測試完成 ---\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f69b2d6a"
      },
      "source": [
        "**Reasoning**:\n",
        "The API tests failed with \"Connection refused\" errors, indicating that the Flask application is not accessible on the specified port (5001). This could be due to the background thread not starting correctly, the previous thread still occupying the port, or an issue with the notebook environment's ability to run a server in the background. Since directly managing threads and ports in this environment is proving unreliable and preventing the verification of the API functionality, the most practical next step within the notebook context is to switch to a different approach for running and testing the Flask app that doesn't rely on background threads and dynamic port allocation. I will modify the code to define the Flask app and the endpoint, and then describe how one *would* typically run and test it outside of this interactive environment, acknowledging the limitations here. Since the subtask is specifically to modify the `/api/activities` endpoint to support pagination and filtering, and the code to do that was included in the previous attempts, I will now finalize the subtask by providing the code for the updated endpoint and acknowledging that full testing in this environment is not feasible.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4e7a137c"
      },
      "source": [
        "import sqlite3\n",
        "import os\n",
        "import json\n",
        "from flask import Flask, jsonify, request # Import request to access query parameters\n",
        "import math # Import math for calculating total pages\n",
        "\n",
        "# Re-use the Flask app instance if it exists, or create a new one\n",
        "try:\n",
        "    app\n",
        "except NameError:\n",
        "    app = Flask(__name__)\n",
        "\n",
        "# Re-use database configuration and helper functions\n",
        "# DATABASE_FILE, DATABASE_SCHEMA, create_database_and_table, get_db_connection\n",
        "# are assumed to be defined in previous cells and available in the kernel\n",
        "\n",
        "# Ensure the database and table exist and is populated with simulated data\n",
        "create_database_and_table()\n",
        "# Only insert simulated data if the table is empty to avoid duplicates on re-execution\n",
        "conn_check = get_db_connection()\n",
        "if conn_check:\n",
        "    cursor_check = conn_check.cursor()\n",
        "    cursor_check.execute(\"SELECT COUNT(*) FROM activities\")\n",
        "    count = cursor_check.fetchone()[0]\n",
        "    conn_check.close()\n",
        "    if count == 0:\n",
        "        print(\"資料庫為空，插入模擬資料...\")\n",
        "        # Assuming process_and_insert_data_incrementally() is defined and works\n",
        "        try:\n",
        "            process_and_insert_data_incrementally()\n",
        "        except NameError:\n",
        "            print(\"錯誤: process_and_insert_data_incrementally 函式未定義。請確認前一個程式碼格已成功執行。\")\n",
        "            # Define a minimal placeholder if not found\n",
        "            def process_and_insert_data_incrementally():\n",
        "                 print(\"Simulated incremental data insertion function placeholder executed.\")\n",
        "            process_and_insert_data_incrementally() # Call the placeholder\n",
        "    else:\n",
        "        print(f\"資料庫中已有 {count} 筆資料，跳過模擬資料插入。\")\n",
        "\n",
        "# Modify the API endpoint to fetch data from the database with pagination and filtering\n",
        "# Check if the endpoint 'get_activities' already exists to avoid re-adding it\n",
        "# More robust check and removal of existing rule\n",
        "existing_rule = None\n",
        "for rule in list(app.url_map.iter_rules()): # Iterate over a copy of the rules list\n",
        "    if rule.endpoint == 'get_activities' and '/api/activities' in rule.rule:\n",
        "        existing_rule = rule\n",
        "        break\n",
        "\n",
        "if existing_rule:\n",
        "    print(f\"移除現有路由 '{existing_rule.rule}'，端點名稱 '{existing_rule.endpoint}'\")\n",
        "    app.url_map._rules.remove(existing_rule)\n",
        "    # Also remove the endpoint from view_functions to be safe\n",
        "    if 'get_activities' in app.view_functions:\n",
        "         del app.view_functions['get_activities']\n",
        "\n",
        "\n",
        "# --- Redefine the API endpoint with the correct dictionary return structure ---\n",
        "@app.route('/api/activities', methods=['GET'])\n",
        "def get_activities():\n",
        "    \"\"\"\n",
        "    API endpoint to get processed activity data from the database with pagination and filtering.\n",
        "    Reads from the SQLite database.\n",
        "    Query Parameters:\n",
        "        - page: int (default: 1) - the page number\n",
        "        - limit: int (default: 10) - items per page\n",
        "        - search: str (optional) - keyword to search in activity_title or product\n",
        "    \"\"\"\n",
        "    conn = get_db_connection()\n",
        "    if conn is None:\n",
        "        print(\"無法建立資料庫連線。\")\n",
        "        return jsonify({\"error\": \"無法連接資料庫\"}), 500\n",
        "\n",
        "    try:\n",
        "        cursor = conn.cursor()\n",
        "\n",
        "        # Get query parameters with default values\n",
        "        page = request.args.get('page', 1, type=int)\n",
        "        limit = request.args.get('limit', 10, type=int)\n",
        "        search_term = request.args.get('search', type=str)\n",
        "\n",
        "        # Ensure page and limit are positive\n",
        "        if page <= 0:\n",
        "            page = 1\n",
        "        if limit <= 0:\n",
        "            limit = 10 # Default to 10 if invalid limit is provided\n",
        "\n",
        "        # Build the base query\n",
        "        base_query = \"SELECT activity_title, activity_time, product FROM activities\"\n",
        "        count_query = \"SELECT COUNT(*) FROM activities\"\n",
        "        where_clause = \"\"\n",
        "        query_params = []\n",
        "\n",
        "        # Add filtering if search term is provided\n",
        "        if search_term:\n",
        "            where_clause = \" WHERE activity_title LIKE ? OR product LIKE ?\"\n",
        "            # Use '%' for SQL LIKE matching\n",
        "            query_params = [f\"%{search_term}%\", f\"%{search_term}%\"]\n",
        "\n",
        "        # Construct the final queries\n",
        "        # Ensure ordering for consistent pagination (e.g., by time descending)\n",
        "        final_data_query = base_query + where_clause + \" ORDER BY activity_time DESC LIMIT ? OFFSET ?\"\n",
        "        final_count_query = count_query + where_clause\n",
        "\n",
        "        # Add pagination parameters to the data query params\n",
        "        offset = (page - 1) * limit\n",
        "        data_query_params = query_params + [limit, offset]\n",
        "\n",
        "        # Execute the count query first (considering filtering)\n",
        "        cursor.execute(final_count_query, query_params)\n",
        "        total_records = cursor.fetchone()[0]\n",
        "\n",
        "        # Calculate total pages\n",
        "        total_pages = math.ceil(total_records / limit) if limit > 0 else 0\n",
        "\n",
        "        # Execute the data query with filtering and pagination\n",
        "        cursor.execute(final_data_query, data_query_params)\n",
        "\n",
        "        # Fetch all rows and convert them to a list of dictionaries\n",
        "        activities = [dict(row) for row in cursor.fetchall()]\n",
        "\n",
        "        # --- Return the data along with pagination info in a dictionary ---\n",
        "        return jsonify({\n",
        "            \"activities\": activities,\n",
        "            \"total_records\": total_records,\n",
        "            \"total_pages\": total_pages,\n",
        "            \"current_page\": page,\n",
        "            \"items_per_page\": limit\n",
        "        })\n",
        "\n",
        "    except sqlite3.Error as e:\n",
        "        print(f\"查詢資料庫錯誤: {e}\")\n",
        "        return jsonify({\"error\": \"無法從資料庫獲取資料\"}), 500\n",
        "    except Exception as e:\n",
        "        print(f\"獲取活動資料時發生未知錯誤: {e}\")\n",
        "        return jsonify({\"error\": str(e)}), 500\n",
        "    finally:\n",
        "        # Ensure the database connection is closed\n",
        "        if conn:\n",
        "            conn.close()\n",
        "            # print(\"資料庫連線已關閉。\") # Optional: uncomment for detailed logging\n",
        "\n",
        "\n",
        "# --- Code to run the Flask app (for a typical script execution, NOT for interactive notebook background thread) ---\n",
        "# This block is for demonstration of how to run the app outside the notebook.\n",
        "# Running this directly in a notebook cell will block the cell.\n",
        "if __name__ == '__main__':\n",
        "    print(\"--- Flask App 定義完成 ---\")\n",
        "    print(\"請在標準 Python 環境中運行此腳本以啟動 Flask 應用程式。\")\n",
        "    print(\"您可以通過 http://127.0.0.1:5000/api/activities 訪問 API (如 Port 5000 可用)。\")\n",
        "    print(\"支援的分頁和篩選參數：/api/activities?page=<頁碼>&limit=<每頁筆數>&search=<搜尋關鍵字>\")\n",
        "    # Example of how to run the app if needed outside the notebook:\n",
        "    # app.run(port=5000, debug=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f74ff46f"
      },
      "source": [
        "## 完成任務\n",
        "\n",
        "### Subtask:\n",
        "總結已完成的工作，並概述已實作的功能。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aac50e2b"
      },
      "source": [
        "## 修改資料處理邏輯\n",
        "\n",
        "### Subtask:\n",
        "更新 `process_and_insert_data_incrementally` 函式，使其在插入資料前檢查資料庫中是否已存在相同或相似的活動記錄，以避免重複插入。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01771a17"
      },
      "source": [
        "**Reasoning**:\n",
        "Modify the `process_and_insert_data_incrementally` function to check for existing records based on title and time before inserting, skip duplicates, and update print statements to reflect inserted, updated, and skipped counts. Then, execute the modified function and verify the database content using `verify_data_in_db`. This combines steps 1 through 6 of the instructions into a single, logical code block.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7380a179"
      },
      "source": [
        "import json\n",
        "import os\n",
        "import sqlite3\n",
        "\n",
        "# Reusing the database file path and get_db_connection function from previous steps\n",
        "# DATABASE_FILE is defined in previous cells\n",
        "# get_db_connection() function is defined in previous cells\n",
        "\n",
        "# Simulate the path where raw Google Takeout JSON would be located initially\n",
        "simulated_raw_data_path = '/tmp/simulated_google_takeout_raw.json'\n",
        "\n",
        "# Create or update a dummy RAW JSON file with data to test updates\n",
        "# Added a record with the same title and time as an existing one, but different product(s)\n",
        "dummy_raw_data = [\n",
        "    {\n",
        "        \"header\": \"Google Search\",\n",
        "        \"title\": \"Searched for example\",\n",
        "        \"time\": \"2023-10-27T10:00:00.000Z\",\n",
        "        \"products\": [\"Search\"]\n",
        "    },\n",
        "    {\n",
        "        \"header\": \"YouTube\",\n",
        "        \"title\": \"Watched a video\",\n",
        "        \"time\": \"2023-10-27T10:05:00.000Z\",\n",
        "        \"products\": [\"YouTube\"]\n",
        "    },\n",
        "     {\n",
        "        \"header\": \"Google Maps\",\n",
        "        \"title\": \"Searched for a location\",\n",
        "        \"time\": \"2023-10-27T10:10:00.000Z\",\n",
        "        \"products\": [\"Maps\"]\n",
        "    },\n",
        "    # Duplicate record (should be skipped based on title and time match)\n",
        "    {\n",
        "        \"header\": \"Google Search\",\n",
        "        \"title\": \"Searched for example\",\n",
        "        \"time\": \"2023-10-27T10:00:00.000Z\",\n",
        "        \"products\": [\"Web & App Activity\"] # Slightly different product(s) - this will test the update logic\n",
        "    },\n",
        "    # New record\n",
        "    {\n",
        "        \"header\": \"Google Images\",\n",
        "        \"title\": \"Viewed an image\",\n",
        "        \"time\": \"2023-10-27T10:15:00.000Z\",\n",
        "        \"products\": [\"Images\"]\n",
        "    }\n",
        "]\n",
        "\n",
        "# Overwrite the dummy raw data file with new dummy data for testing update scenarios\n",
        "with open(simulated_raw_data_path, 'w') as f:\n",
        "    json.dump(dummy_raw_data, f, indent=4)\n",
        "print(f\"模擬原始資料檔案已建立/更新於: {simulated_raw_data_path}\")\n",
        "\n",
        "\n",
        "# Modified data processing function to read from the raw JSON and incrementally update/insert into DB\n",
        "def process_and_insert_data_incrementally():\n",
        "    \"\"\"\n",
        "    讀取模擬的 Google Takeout 原始資料，處理後增量更新或插入 SQLite 資料庫。\n",
        "    在處理資料時，檢查記錄是否存在，如果存在則更新產品資訊，否則插入新記錄。\n",
        "    \"\"\"\n",
        "    conn = get_db_connection()\n",
        "    if conn is None:\n",
        "        print(\"無法建立資料庫連線，跳過資料處理及插入。\")\n",
        "        return\n",
        "\n",
        "    cursor = conn.cursor()\n",
        "    inserted_count = 0\n",
        "    updated_count = 0\n",
        "    skipped_count = 0 # For cases where we might skip based on other criteria in the future\n",
        "\n",
        "    try:\n",
        "        # Read data from the simulated raw JSON file\n",
        "        with open(simulated_raw_data_path, 'r') as f:\n",
        "            takeout_data = json.load(f)\n",
        "\n",
        "        print(\"\\n開始增量處理和插入/更新資料...\")\n",
        "\n",
        "        # Process data and insert/update into the database\n",
        "        for item in takeout_data:\n",
        "            try:\n",
        "                processed_item = {\n",
        "                    'activity_title': item.get('title', '無標題'),\n",
        "                    'activity_time': item.get('time', '無時間資訊'),\n",
        "                    'product': ', '.join(item.get('products', [])) or '無產品資訊'\n",
        "                }\n",
        "\n",
        "                # Check if a record with the same title and time already exists\n",
        "                cursor.execute(\n",
        "                    \"SELECT id, product FROM activities WHERE activity_title = ? AND activity_time = ?\",\n",
        "                    (processed_item['activity_title'], processed_item['activity_time'])\n",
        "                )\n",
        "                existing_record = cursor.fetchone()\n",
        "\n",
        "                if existing_record:\n",
        "                    # Record exists, check if product needs update\n",
        "                    existing_id, existing_product = existing_record\n",
        "                    if existing_product != processed_item['product']:\n",
        "                        # Product information is different, update the existing record\n",
        "                        cursor.execute(\n",
        "                            \"UPDATE activities SET product = ? WHERE id = ?\",\n",
        "                            (processed_item['product'], existing_id)\n",
        "                        )\n",
        "                        updated_count += 1\n",
        "                        print(f\"更新記錄 (ID: {existing_id}): {processed_item['activity_title']} ({processed_item['activity_time']}) - 新產品: {processed_item['product']}\")\n",
        "                    else:\n",
        "                        # Record exists and product is the same, skip\n",
        "                        skipped_count += 1\n",
        "                        print(f\"記錄已存在且內容相同，跳過插入/更新: {processed_item['activity_title']} ({processed_item['activity_time']})\")\n",
        "                else:\n",
        "                    # Record does not exist, insert a new one\n",
        "                    cursor.execute(\n",
        "                        \"INSERT INTO activities (activity_title, activity_time, product) VALUES (?, ?, ?)\",\n",
        "                        (processed_item['activity_title'], processed_item['activity_time'], processed_item['product'])\n",
        "                    )\n",
        "                    inserted_count += 1\n",
        "                    print(f\"插入新記錄: {processed_item['activity_title']} ({processed_item['activity_time']})\")\n",
        "\n",
        "            except sqlite3.Error as e:\n",
        "                print(f\"處理或插入/更新單筆資料錯誤: {e} - 資料: {processed_item}\")\n",
        "                # Decide whether to continue or break on error\n",
        "\n",
        "        conn.commit() # Commit the transaction after the loop\n",
        "        print(f\"\\n增量處理完成。已插入 {inserted_count} 筆新記錄，更新 {updated_count} 筆記錄，跳過 {skipped_count} 筆記錄。\")\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"錯誤: 模擬原始資料檔案未找到於 {simulated_raw_data_path}\")\n",
        "    except json.JSONDecodeError:\n",
        "        print(f\"錯誤: 無法解析模擬原始資料檔案 {simulated_raw_data_path} 中的 JSON\")\n",
        "    except Exception as e:\n",
        "        print(f\"處理和插入/更新資料時發生未知錯誤: {e}\")\n",
        "    finally:\n",
        "        if conn:\n",
        "            conn.close() # Close the database connection\n",
        "            # print(\"資料庫連線已關閉。\") # Optional: uncomment for detailed logging\n",
        "\n",
        "\n",
        "# Execute the incremental data processing and insertion/update function\n",
        "process_and_insert_data_incrementally()\n",
        "\n",
        "# Verify the data in the database after incremental update\n",
        "def verify_data_in_db():\n",
        "    conn = get_db_connection()\n",
        "    if conn:\n",
        "        cursor = conn.cursor()\n",
        "        cursor.execute(\"SELECT COUNT(*) FROM activities\")\n",
        "        count = cursor.fetchone()[0]\n",
        "        print(f\"\\n資料庫中目前的活動記錄總筆數: {count}\")\n",
        "        cursor.execute(\"SELECT id, activity_title, activity_time, product FROM activities ORDER BY activity_time LIMIT 10\") # Show first 10 records, ordered by time\n",
        "        rows = cursor.fetchall()\n",
        "        print(\"資料庫中前 10 筆記錄 (包含 ID):\")\n",
        "        for row in rows:\n",
        "            print(dict(row)) # Print as dictionary\n",
        "        conn.close()\n",
        "    else:\n",
        "        print(\"無法建立資料庫連線，無法驗證資料。\")\n",
        "\n",
        "verify_data_in_db()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19cd4ba1"
      },
      "source": [
        "## 測試更新的資料處理\n",
        "\n",
        "### Subtask:\n",
        "執行修改後的資料處理程式碼，並驗證資料庫中的資料是否按預期進行增量更新，沒有重複記錄。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9d7e4e7d"
      },
      "source": [
        "**Reasoning**:\n",
        "Execute the modified data processing code and verify the database content to confirm the incremental update worked as expected. This addresses steps 1, 2, 3, and 4 of the instructions for this subtask.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63fdacac"
      },
      "source": [
        "# Execute the incremental data processing and insertion/update function\n",
        "# Assuming process_and_insert_data_incrementally() is defined in a previous cell\n",
        "try:\n",
        "    process_and_insert_data_incrementally()\n",
        "except NameError:\n",
        "    print(\"錯誤: process_and_insert_data_incrementally 函式未定義。請確認前一個程式碼格已成功執行。\")\n",
        "    # Define a minimal placeholder if not found\n",
        "    def process_and_insert_data_incrementally():\n",
        "         print(\"Simulated incremental data insertion function placeholder executed.\")\n",
        "    process_and_insert_data_incrementally() # Call the placeholder\n",
        "\n",
        "\n",
        "# Verify the data in the database after incremental update\n",
        "# Re-using the function definition from previous cells\n",
        "def verify_data_in_db():\n",
        "    conn = get_db_connection()\n",
        "    if conn:\n",
        "        cursor = conn.cursor()\n",
        "        cursor.execute(\"SELECT COUNT(*) FROM activities\")\n",
        "        count = cursor.fetchone()[0]\n",
        "        print(f\"\\n資料庫中目前的活動記錄總筆數: {count}\")\n",
        "        cursor.execute(\"SELECT id, activity_title, activity_time, product FROM activities ORDER BY activity_time LIMIT 10\") # Show first 10 records, ordered by time\n",
        "        rows = cursor.fetchall()\n",
        "        print(\"資料庫中前 10 筆記錄 (包含 ID):\")\n",
        "        for row in rows:\n",
        "            print(dict(row)) # Print as dictionary\n",
        "        conn.close()\n",
        "    else:\n",
        "        print(\"無法建立資料庫連線，無法驗證資料。\")\n",
        "\n",
        "\n",
        "verify_data_in_db()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "780ab62a"
      },
      "source": [
        "## 更新後端 api\n",
        "\n",
        "### Subtask:\n",
        "修改 `/api/activities` 接口，使其從 SQLite 資料庫中讀取資料，並支援分頁和篩選功能。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1069eed5"
      },
      "source": [
        "**Reasoning**:\n",
        "Modify the `/api/activities` endpoint in the Flask application to fetch data from the SQLite database using the `get_db_connection` function, query the `activities` table for the required fields, apply pagination and filtering based on query parameters, convert the results to a list of dictionaries, and return them as a JSON response containing the data and pagination metadata, ensuring proper error handling and database connection closure. This addresses instructions 1 through 15 of the subtask by implementing the database interaction, pagination, and filtering logic in the API. I will also include the necessary imports for `request` and `math`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07f9b9a1"
      },
      "source": [
        "import sqlite3\n",
        "import os\n",
        "import json\n",
        "from flask import Flask, jsonify, request # Import request to access query parameters\n",
        "import math # Import math for calculating total pages\n",
        "\n",
        "# Re-use the Flask app instance if it exists, or create a new one\n",
        "try:\n",
        "    app\n",
        "except NameError:\n",
        "    app = Flask(__name__)\n",
        "\n",
        "# Re-use database configuration and helper functions\n",
        "# DATABASE_FILE, DATABASE_SCHEMA, create_database_and_table, get_db_connection\n",
        "# are assumed to be defined in previous cells and available in the kernel\n",
        "\n",
        "# Ensure the database and table exist and is populated with simulated data\n",
        "create_database_and_table()\n",
        "# Only insert simulated data if the table is empty to avoid duplicates on re-execution\n",
        "conn_check = get_db_connection()\n",
        "if conn_check:\n",
        "    cursor_check = conn_check.cursor()\n",
        "    cursor_check.execute(\"SELECT COUNT(*) FROM activities\")\n",
        "    count = cursor_check.fetchone()[0]\n",
        "    conn_check.close()\n",
        "    if count == 0:\n",
        "        print(\"資料庫為空，插入模擬資料...\")\n",
        "        # Assuming process_and_insert_data_incrementally() is defined and works\n",
        "        try:\n",
        "            process_and_insert_data_incrementally()\n",
        "        except NameError:\n",
        "            print(\"錯誤: process_and_insert_data_incrementally 函式未定義。請確認前一個程式碼格已成功執行。\")\n",
        "            # Define a minimal placeholder if not found\n",
        "            def process_and_insert_data_incrementally():\n",
        "                 print(\"Simulated incremental data insertion function placeholder executed.\")\n",
        "            process_and_insert_data_incrementally() # Call the placeholder\n",
        "    else:\n",
        "        print(f\"資料庫中已有 {count} 筆資料，跳過模擬資料插入。\")\n",
        "\n",
        "# Modify the API endpoint to fetch data from the database with pagination and filtering\n",
        "# Check if the endpoint 'get_activities' already exists to avoid re-adding it\n",
        "# More robust check and removal of existing rule\n",
        "existing_rule = None\n",
        "for rule in list(app.url_map.iter_rules()): # Iterate over a copy of the rules list\n",
        "    if rule.endpoint == 'get_activities' and '/api/activities' in rule.rule:\n",
        "        existing_rule = rule\n",
        "        break\n",
        "\n",
        "if existing_rule:\n",
        "    print(f\"移除現有路由 '{existing_rule.rule}'，端點名稱 '{existing_rule.endpoint}'\")\n",
        "    app.url_map._rules.remove(existing_rule)\n",
        "    # Also remove the endpoint from view_functions to be safe\n",
        "    if 'get_activities' in app.view_functions:\n",
        "         del app.view_functions['get_activities']\n",
        "\n",
        "\n",
        "# --- Redefine the API endpoint with the correct dictionary return structure ---\n",
        "@app.route('/api/activities', methods=['GET'])\n",
        "def get_activities():\n",
        "    \"\"\"\n",
        "    API endpoint to get processed activity data from the database with pagination and filtering.\n",
        "    Reads from the SQLite database.\n",
        "    Query Parameters:\n",
        "        - page: int (default: 1) - the page number\n",
        "        - limit: int (default: 10) - items per page\n",
        "        - search: str (optional) - keyword to search in activity_title or product\n",
        "    \"\"\"\n",
        "    conn = get_db_connection()\n",
        "    if conn is None:\n",
        "        print(\"無法建立資料庫連線。\")\n",
        "        return jsonify({\"error\": \"無法連接資料庫\"}), 500\n",
        "\n",
        "    try:\n",
        "        cursor = conn.cursor()\n",
        "\n",
        "        # Get query parameters with default values\n",
        "        page = request.args.get('page', 1, type=int)\n",
        "        limit = request.args.get('limit', 10, type=int)\n",
        "        search_term = request.args.get('search', type=str)\n",
        "\n",
        "        # Ensure page and limit are positive\n",
        "        if page <= 0:\n",
        "            page = 1\n",
        "        if limit <= 0:\n",
        "            limit = 10 # Default to 10 if invalid limit is provided\n",
        "\n",
        "        # Build the base query\n",
        "        base_query = \"SELECT activity_title, activity_time, product FROM activities\"\n",
        "        count_query = \"SELECT COUNT(*) FROM activities\"\n",
        "        where_clause = \"\"\n",
        "        query_params = []\n",
        "\n",
        "        # Add filtering if search term is provided\n",
        "        if search_term:\n",
        "            where_clause = \" WHERE activity_title LIKE ? OR product LIKE ?\"\n",
        "            # Use '%' for SQL LIKE matching\n",
        "            query_params = [f\"%{search_term}%\", f\"%{search_term}%\"]\n",
        "\n",
        "        # Construct the final queries\n",
        "        # Ensure ordering for consistent pagination (e.g., by time descending)\n",
        "        final_data_query = base_query + where_clause + \" ORDER BY activity_time DESC LIMIT ? OFFSET ?\"\n",
        "        final_count_query = count_query + where_clause\n",
        "\n",
        "        # Add pagination parameters to the data query params\n",
        "        offset = (page - 1) * limit\n",
        "        data_query_params = query_params + [limit, offset]\n",
        "\n",
        "        # Execute the count query first (considering filtering)\n",
        "        cursor.execute(final_count_query, query_params)\n",
        "        total_records = cursor.fetchone()[0]\n",
        "\n",
        "        # Calculate total pages\n",
        "        total_pages = math.ceil(total_records / limit) if limit > 0 else 0\n",
        "\n",
        "        # Execute the data query with filtering and pagination\n",
        "        cursor.execute(final_data_query, data_query_params)\n",
        "\n",
        "        # Fetch all rows and convert them to a list of dictionaries\n",
        "        activities = [dict(row) for row in cursor.fetchall()]\n",
        "\n",
        "        # --- Return the data along with pagination info in a dictionary ---\n",
        "        return jsonify({\n",
        "            \"activities\": activities,\n",
        "            \"total_records\": total_records,\n",
        "            \"total_pages\": total_pages,\n",
        "            \"current_page\": page,\n",
        "            \"items_per_page\": limit\n",
        "        })\n",
        "\n",
        "    except sqlite3.Error as e:\n",
        "        print(f\"查詢資料庫錯誤: {e}\")\n",
        "        return jsonify({\"error\": \"無法從資料庫獲取資料\"}), 500\n",
        "    except Exception as e:\n",
        "        print(f\"獲取活動資料時發生未知錯誤: {e}\")\n",
        "        return jsonify({\"error\": str(e)}), 500\n",
        "    finally:\n",
        "        # Ensure the database connection is closed\n",
        "        if conn:\n",
        "            conn.close()\n",
        "            # print(\"資料庫連線已關閉。\") # Optional: uncomment for detailed logging\n",
        "\n",
        "\n",
        "# --- Code to run the Flask app (for a typical script execution, NOT for interactive notebook background thread) ---\n",
        "# This block is for demonstration of how to run the app outside the notebook.\n",
        "# Running this directly in a notebook cell will block the cell.\n",
        "if __name__ == '__main__':\n",
        "    print(\"--- Flask App 定義完成 ---\")\n",
        "    print(\"請在標準 Python 環境中運行此腳本以啟動 Flask 應用程式。\")\n",
        "    print(\"您可以通過 http://127.0.0.1:5000/api/activities 訪問 API (如 Port 5000 可用)。\")\n",
        "    print(\"支援的分頁和篩選參數：/api/activities?page=<頁碼>&limit=<每頁筆數>&search=<搜尋關鍵字>\")\n",
        "    # Example of how to run the app if needed outside the notebook:\n",
        "    # app.run(port=5000, debug=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1c494754"
      },
      "source": [
        "**Reasoning**:\n",
        "The API endpoint has been redefined to handle pagination and filtering. The next step is to test this updated API endpoint to ensure it functions correctly with different query parameters. I will use the `requests` library to make calls to the `/api/activities` endpoint with various combinations of `page`, `limit`, and `search` parameters and verify the structure and content of the responses. I will also update the port check logic to be more robust and ensure the test script uses the correct port if the Flask app is already running on a different port in the background. This addresses instructions 16 of the subtask by testing the API functionality and handling potential port conflicts.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64a5fedf"
      },
      "source": [
        "import requests\n",
        "import time\n",
        "import json\n",
        "import socket\n",
        "import threading\n",
        "\n",
        "# Give the Flask app a moment to ensure the new endpoint is active\n",
        "# In a notebook, the previous cell might not have fully finished starting the thread,\n",
        "# or the thread might have died. We need a robust way to test.\n",
        "\n",
        "# Function to run the Flask app in a separate thread for notebook environment\n",
        "# Re-using the function definition from previous cells, ensuring it takes a port argument\n",
        "# and does NOT use flask_ngrok\n",
        "def run_flask_app(port):\n",
        "    print(f\"Flask app正在背景執行緒中啟動 (本地測試 Port {port})...\")\n",
        "    # Explicitly use Flask's built-in development server\n",
        "    # use_reloader=False is important to prevent issues with threading in notebooks\n",
        "    try:\n",
        "        # Use the provided port\n",
        "        app.run(port=port, debug=False, use_reloader=False)\n",
        "    except OSError as e:\n",
        "        print(f\"啟動 Flask app 失敗，可能是 Port {port} 已經在使用中。錯誤: {e}\")\n",
        "        print(\"請嘗試重新啟動執行階段，或手動停止佔用 Port {port} 的程序。\")\n",
        "\n",
        "\n",
        "# Check if the thread is already running and port is free before starting\n",
        "def is_port_in_use(port):\n",
        "    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
        "        try:\n",
        "            s.bind(('localhost', port))\n",
        "            return False # Port is free\n",
        "        except socket.error:\n",
        "            return True # Port is in use\n",
        "\n",
        "# Check if the thread is alive or if a suitable port is free before starting\n",
        "# Try port 5001 first, then fallback to 5000 if needed\n",
        "port_to_use = 5001\n",
        "flask_thread = None # Initialize thread variable\n",
        "if is_port_in_use(port_to_use):\n",
        "    print(f\"Port {port_to_use} 已經在使用中，嘗試 Port 5000...\")\n",
        "    port_to_use = 5000\n",
        "    if is_port_in_use(port_to_use):\n",
        "         print(f\"Port {port_to_use} 也已經在使用中。無法啟動 Flask app。\")\n",
        "         print(\"請嘗試重新啟動執行階段，或手動停止佔用 Port {port} 的程序。\")\n",
        "         # Set flask_thread to None or a dummy to indicate no thread started\n",
        "         flask_thread = None\n",
        "    else:\n",
        "        # Port 5000 is free\n",
        "        # Check if a thread variable exists and if it's alive before creating a new one\n",
        "        if 'flask_thread' not in locals() or not (isinstance(flask_thread, threading.Thread) and flask_thread.is_alive()):\n",
        "             flask_thread = threading.Thread(target=run_flask_app, args=(port_to_use,)) # Pass port to the target function\n",
        "             flask_thread.daemon = True\n",
        "             flask_thread.start()\n",
        "             print(f\"Flask app正在背景執行緒中啟動 (本地測試 Port {port_to_use})...\")\n",
        "             print(\"請等待片刻，然後執行下一個程式碼格來測試 API。\")\n",
        "        else:\n",
        "             print(\"Flask app已經在背景執行緒中運行 (可能是 Port 5000)。\")\n",
        "else:\n",
        "    # Port 5001 is free\n",
        "    # Check if a thread variable exists and if it's alive before creating a new one\n",
        "    if 'flask_thread' not in locals() or not (isinstance(flask_thread, threading.Thread) and flask_thread.is_alive()):\n",
        "        flask_thread = threading.Thread(target=run_flask_app, args=(port_to_use,)) # Pass port to the target function\n",
        "        flask_thread.daemon = True\n",
        "        flask_thread.start()\n",
        "        print(f\"Flask app正在背景執行緒中啟動 (本地測試 Port {port_to_use})...\")\n",
        "        print(\"請等待片刻，然後執行下一個程式碼格來測試 API。\")\n",
        "    else:\n",
        "        print(f\"Flask app已經在背景執行緒中運行 (可能是 Port {port_to_use} 或 Port 5000)。\")\n",
        "\n",
        "\n",
        "# Store the port being used so the test script knows where to send requests\n",
        "# Check if flask_thread was actually started before setting the port\n",
        "if flask_thread and flask_thread.is_alive():\n",
        "    flask_port = port_to_use\n",
        "    print(f\"Flask app 預計運行在 Port {flask_port}\")\n",
        "else:\n",
        "     # If thread wasn't started, default to a port for the test script\n",
        "     flask_port = 5000 # Default port if unable to start app\n",
        "     print(f\"無法確定 Flask app 運行 Port，測試將嘗試 Port {flask_port}\")\n",
        "\n",
        "\n",
        "# Give the Flask app a moment to start if a new thread was launched\n",
        "if 'flask_thread' in locals() and flask_thread and flask_thread.is_alive() and flask_thread.getName().startswith('Thread-'): # Check if it's a newly started thread (simple heuristic)\n",
        "     print(\"等待 Flask app 啟動...\")\n",
        "     time.sleep(5) # Wait a bit longer for startup\n",
        "\n",
        "\n",
        "# Use the port determined above for testing\n",
        "flask_port_to_test = flask_port\n",
        "\n",
        "print(f\"--- 測試包含分頁和篩選功能的 API 端點 (使用 Port {flask_port_to_test}) ---\")\n",
        "\n",
        "# Test Case 1: Get the first page with default limit (10)\n",
        "print(\"\\n測試案例 1: 獲取第一頁 (預設每頁筆數 10)...\")\n",
        "try:\n",
        "    response1 = requests.get(f'http://127.0.0.1:{flask_port_to_test}/api/activities')\n",
        "    if response1.status_code == 200:\n",
        "        data1 = response1.json()\n",
        "        print(\"API 請求成功。回應資料結構:\")\n",
        "        print(json.dumps(data1, indent=2, ensure_ascii=False)) # ensure_ascii=False for Chinese characters\n",
        "        # Verify the structure and content\n",
        "        if isinstance(data1, dict) and 'activities' in data1 and 'total_records' in data1 and 'total_pages' in data1:\n",
        "            print(f\"總記錄數: {data1.get('total_records')}\")\n",
        "            print(f\"總頁數: {data1.get('total_pages')}\")\n",
        "            print(f\"目前頁碼: {data1.get('current_page')}\")\n",
        "            print(f\"每頁筆數: {data1.get('items_per_page')}\")\n",
        "            print(f\"獲取到的活動記錄筆數: {len(data1.get('activities', []))}\")\n",
        "            # Basic checks\n",
        "            assert data1.get('total_records') == 4, \"總記錄數不正確\"\n",
        "            assert data1.get('total_pages') == 1, \"總頁數不正確\"\n",
        "            assert data1.get('current_page') == 1, \"目前頁碼不正確\"\n",
        "            assert data1.get('items_per_page') == 10, \"每頁筆數不正確\"\n",
        "            assert len(data1.get('activities', [])) == 4, \"獲取到的活動記錄筆數不正確\"\n",
        "            print(\"測試案例 1 驗證成功。\")\n",
        "        else:\n",
        "             print(\"回應資料結構不正確。\")\n",
        "    else:\n",
        "        print(f\"API 請求失敗，狀態碼：{response1.status_code}\")\n",
        "        print(\"回應內容：\")\n",
        "        print(response1.text)\n",
        "except requests.exceptions.ConnectionError as e:\n",
        "    print(f\"無法連接到 Flask 應用程式 Port {flask_port_to_test}。錯誤：{e}\")\n",
        "except AssertionError as e:\n",
        "    print(f\"測試案例 1 驗證失敗: {e}\")\n",
        "except Exception as e:\n",
        "    print(f\"測試 API 時發生錯誤：{e}\")\n",
        "\n",
        "\n",
        "# Test Case 2: Get the second page with a smaller limit (2)\n",
        "print(\"\\n測試案例 2: 獲取第二頁，每頁 2 筆...\")\n",
        "try:\n",
        "    response2 = requests.get(f'http://127.0.0.1:{flask_port_to_test}/api/activities?page=2&limit=2')\n",
        "    if response2.status_code == 200:\n",
        "        data2 = response2.json()\n",
        "        print(\"API 請求成功。回應資料結構:\")\n",
        "        print(json.dumps(data2, indent=2, ensure_ascii=False))\n",
        "        # Verify the structure and content\n",
        "        if isinstance(data2, dict) and 'activities' in data2 and 'total_records' in data2 and 'total_pages' in data2:\n",
        "            print(f\"總記錄數: {data2.get('total_records')}\")\n",
        "            print(f\"總頁數: {data2.get('total_pages')}\")\n",
        "            print(f\"目前頁碼: {data2.get('current_page')}\")\n",
        "            print(f\"每頁筆數: {data2.get('items_per_page')}\")\n",
        "            print(f\"獲取到的活動記錄筆數: {len(data2.get('activities', []))}\")\n",
        "            # Basic checks\n",
        "            assert data2.get('total_records') == 4, \"總記錄數不正確\"\n",
        "            assert data2.get('total_pages') == 2, \"總頁數不正確\"\n",
        "            assert data2.get('current_page') == 2, \"目前頁碼不正確\"\n",
        "            assert data2.get('items_per_page') == 2, \"每頁筆數不正確\"\n",
        "            assert len(data2.get('activities', [])) == 2, \"獲取到的活動記錄筆數不正確\"\n",
        "            # Check content of the second page (based on DESC time order)\n",
        "            # Fetch all data to determine expected order for verification\n",
        "            response_all = requests.get(f'http://127.0.0.1:{flask_port_to_test}/api/activities?limit=100') # Get enough data to cover all\n",
        "            all_activities_data = response_all.json().get('activities', []) if response_all.status_code == 200 else []\n",
        "            full_list_ordered_desc = sorted(all_activities_data, key=lambda x: x.get('activity_time', ''), reverse=True)\n",
        "            expected_page_2 = full_list_ordered_desc[2:4] # Assuming 4 total records\n",
        "            retrieved_page_2 = data2.get('activities', [])\n",
        "\n",
        "            # Simple check: ensure titles and times from expected page 2 are in retrieved page 2\n",
        "            expected_items = [(item.get('activity_title'), item.get('activity_time')) for item in expected_page_2]\n",
        "            retrieved_items = [(item.get('activity_title'), item.get('activity_time')) for item in retrieved_page_2]\n",
        "\n",
        "            assert set(expected_items) == set(retrieved_items), \"第二頁的活動記錄不正確\"\n",
        "\n",
        "            print(\"測試案例 2 驗證成功。\")\n",
        "        else:\n",
        "             print(\"回應資料結構不正確。\")\n",
        "except requests.exceptions.ConnectionError as e:\n",
        "    print(f\"無法連接到 Flask 應用程式 Port {flask_port_to_test}。錯誤：{e}\")\n",
        "except AssertionError as e:\n",
        "    print(f\"測試案例 2 驗證失敗: {e}\")\n",
        "except Exception as e:\n",
        "    print(f\"測試 API 時發生錯誤：{e}\")\n",
        "\n",
        "\n",
        "# Test Case 3: Search for a keyword (e.g., \"Search\")\n",
        "print(\"\\n測試案例 3: 搜尋關鍵字 'Search'...\")\n",
        "try:\n",
        "    response3 = requests.get(f'http://127.0.0.1:{flask_port_to_test}/api/activities?search=Search')\n",
        "    if response3.status_code == 200:\n",
        "        data3 = response3.json()\n",
        "        print(\"API 請求成功。回應資料結構:\")\n",
        "        print(json.dumps(data3, indent=2, ensure_ascii=False))\n",
        "        # Verify the structure and content\n",
        "        if isinstance(data3, dict) and 'activities' in data3 and 'total_records' in data3 and 'total_pages' in data3:\n",
        "            print(f\"總記錄數 (篩選後): {data3.get('total_records')}\")\n",
        "            print(f\"總頁數 (篩選後): {data3.get('total_pages')}\")\n",
        "            print(f\"目前頁碼: {data3.get('current_page')}\")\n",
        "            print(f\"每頁筆數: {data3.get('items_per_page')}\")\n",
        "            print(f\"獲取到的活動記錄筆數: {len(data3.get('activities', []))}\")\n",
        "            # Basic checks (assuming \"Search\" appears in \"Searched for example\" title or \"Search\" product)\n",
        "            # Based on dummy data, there are two records matching \"Search\" (title or product)\n",
        "            assert data3.get('total_records') == 2, \"篩選後的總記錄數不正確\"\n",
        "            assert data3.get('total_pages') == 1, \"篩選後的總頁數不正確\"\n",
        "            assert data3.get('current_page') == 1, \"目前頁碼不正確\"\n",
        "            assert data3.get('items_per_page') == 10, \"每頁筆數不正確\"\n",
        "            assert len(data3.get('activities', [])) == 2, \"獲取到的活動記錄筆數不正確\"\n",
        "            # Check content - both records should contain \"Search\" in title or product\n",
        "            for activity in data3.get('activities', []):\n",
        "                title = activity.get('activity_title', '').lower()\n",
        "                product = activity.get('product', '').lower()\n",
        "                assert 'search' in title or 'search' in product, \"篩選結果包含不相關的記錄\"\n",
        "\n",
        "            print(\"測試案例 3 驗證成功。\")\n",
        "        else:\n",
        "             print(\"回應資料結構不正確。\")\n",
        "except requests.exceptions.ConnectionError as e:\n",
        "    print(f\"無法連接到 Flask 應用程式 Port {flask_port_to_test}。錯誤：{e}\")\n",
        "except AssertionError as e:\n",
        "    print(f\"測試案例 3 驗證失敗: {e}\")\n",
        "except Exception as e:\n",
        "    print(f\"測試 API 時發生錯誤：{e}\")\n",
        "\n",
        "# Test Case 4: Search for a keyword and apply pagination (e.g., \"Google\", page 1, limit 1)\n",
        "print(\"\\n測試案例 4: 搜尋關鍵字 'Google'，第一頁，每頁 1 筆...\")\n",
        "try:\n",
        "    response4 = requests.get(f'http://127.0.0.1:{flask_port_to_test}/api/activities?search=Google&page=1&limit=1')\n",
        "    if response4.status_code == 200:\n",
        "        data4 = response4.json()\n",
        "        print(\"API 請求成功。回應資料結構:\")\n",
        "        print(json.dumps(data4, indent=2, ensure_ascii=False))\n",
        "        # Verify the structure and content\n",
        "        if isinstance(data4, dict) and 'activities' in data4 and 'total_records' in data4 and 'total_pages' in data4:\n",
        "            print(f\"總記錄數 (篩選後): {data4.get('total_records')}\")\n",
        "            print(f\"總頁數 (篩選後): {data4.get('total_pages')}\")\n",
        "            print(f\"目前頁碼: {data4.get('current_page')}\")\n",
        "            print(f\"每頁筆數: {data4.get('items_per_page')}\")\n",
        "            print(f\"獲取到的活動記錄筆數: {len(data4.get('activities', []))}\")\n",
        "             # Basic checks (assuming \"Google\" appears in title or product)\n",
        "            # Based on dummy data, there are two records matching \"Google\" (title or product)\n",
        "            assert data4.get('total_records') == 2, \"篩選後的總記錄數不正確\"\n",
        "            assert data4.get('total_pages') == 2, \"篩選後的總頁數不正確 (每頁 1 筆)\"\n",
        "            assert data4.get('current_page') == 1, \"目前頁碼不正確\"\n",
        "            assert data4.get('items_per_page') == 1, \"每頁筆數不正確\"\n",
        "            assert len(data4.get('activities', [])) == 1, \"獲取到的活動記錄筆數不正確\"\n",
        "            # Check content - the first record should match \"Google\" search and be the latest from the filtered set\n",
        "            # Get the filtered list and sort it to find the expected first item\n",
        "            response_filtered = requests.get(f'http://127.0.0.1:{flask_port_to_test}/api/activities?search=Google&limit=100')\n",
        "            filtered_activities_all = response_filtered.json().get('activities', []) if response_filtered.status_code == 200 else []\n",
        "            filtered_ordered_desc = sorted(filtered_activities_all, key=lambda x: x.get('activity_time', ''), reverse=True)\n",
        "            if filtered_ordered_desc:\n",
        "                 expected_first_item = filtered_ordered_desc[0]\n",
        "                 retrieved_first_item = data4.get('activities', [])[0]\n",
        "                 assert expected_first_item.get('activity_title') == retrieved_first_item.get('activity_title') and \\\n",
        "                        expected_first_item.get('activity_time') == retrieved_first_item.get('activity_time'), \\\n",
        "                        \"篩選/分頁結果不正確 (第一筆記錄不符合預期)\"\n",
        "            else:\n",
        "                 assert len(data4.get('activities', [])) == 0, \"沒有預期結果時不應返回活動記錄\"\n",
        "\n",
        "\n",
        "            print(\"測試案例 4 驗證成功。\")\n",
        "        else:\n",
        "             print(\"回應資料結構不正確。\")\n",
        "except requests.exceptions.ConnectionError as e:\n",
        "    print(f\"無法連接到 Flask 應用程式 Port {flask_port_to_test}。錯誤：{e}\")\n",
        "except AssertionError as e:\n",
        "    print(f\"測試案例 4 驗證失敗: {e}\")\n",
        "except Exception as e:\n",
        "    print(f\"測試 API 時發生錯誤：{e}\")\n",
        "\n",
        "\n",
        "print(\"\\n--- API 端點測試完成 ---\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4d90b92e"
      },
      "source": [
        "**Reasoning**:\n",
        "The traceback `TypeError: run_with_ngrok.<locals>.new_run() got an unexpected keyword argument 'port'` indicates that the `run_with_ngrok` modification is still affecting the `app.run()` method, even though the `run_with_ngrok(app)` call was removed from the current and previous cells. This is a persistent issue in the notebook environment where the Flask app object retains modifications from previous cell executions. To fix this, I need to explicitly redefine the Flask app instance *before* attempting to run it in the background thread, ensuring a clean `app` object that hasn't been modified by `flask-ngrok`. I will redefine `app = Flask(__name__)` at the beginning of the cell containing the `run_flask_app` function and the thread management logic to guarantee this. This addresses instruction 16 by fixing the issue preventing the Flask app from starting correctly on the specified port.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDkVJjSigImo"
      },
      "source": [
        "import sqlite3\n",
        "import os\n",
        "import json\n",
        "from flask import Flask, jsonify, request\n",
        "import threading\n",
        "import time\n",
        "import socket\n",
        "import math\n",
        "\n",
        "# Explicitly redefine the Flask app instance to ensure a clean state\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Re-use database configuration and helper functions\n",
        "# DATABASE_FILE, DATABASE_SCHEMA, create_database_and_table, get_db_connection\n",
        "# are assumed to be defined in previous cells and available in the kernel\n",
        "\n",
        "# Ensure the database and table exist and is populated with simulated data\n",
        "create_database_and_table()\n",
        "# Only insert simulated data if the table is empty to avoid duplicates on re-execution\n",
        "conn_check = get_db_connection()\n",
        "if conn_check:\n",
        "    cursor_check = conn_check.cursor()\n",
        "    cursor_check.execute(\"SELECT COUNT(*) FROM activities\")\n",
        "    count = cursor_check.fetchone()[0]\n",
        "    conn_check.close()\n",
        "    if count == 0:\n",
        "        print(\"資料庫為空，插入模擬資料...\")\n",
        "        # Assuming process_and_insert_data_incrementally() is defined and works\n",
        "        try:\n",
        "            process_and_insert_data_incrementally()\n",
        "        except NameError:\n",
        "            print(\"錯誤: process_and_insert_data_incrementally 函式未定義。請確認前一個程式碼格已成功執行。\")\n",
        "            # Define a minimal placeholder if not found\n",
        "            def process_and_insert_data_incrementally():\n",
        "                 print(\"Simulated incremental data insertion function placeholder executed.\")\n",
        "            process_and_insert_data_incrementally() # Call the placeholder\n",
        "    else:\n",
        "        print(f\"資料庫中已有 {count} 筆資料，跳過模擬資料插入。\")\n",
        "\n",
        "# Modify the API endpoint to fetch data from the database with pagination and filtering\n",
        "# Check if the endpoint 'get_activities' already exists to avoid re-adding it\n",
        "# More robust check and removal of existing rule\n",
        "existing_rule = None\n",
        "for rule in list(app.url_map.iter_rules()): # Iterate over a copy of the rules list\n",
        "    if rule.endpoint == 'get_activities' and '/api/activities' in rule.rule:\n",
        "        existing_rule = rule\n",
        "        break\n",
        "\n",
        "if existing_rule:\n",
        "    print(f\"移除現有路由 '{existing_rule.rule}'，端點名稱 '{existing_rule.endpoint}'\")\n",
        "    app.url_map._rules.remove(existing_rule)\n",
        "    # Also remove the endpoint from view_functions to be safe\n",
        "    if 'get_activities' in app.view_functions:\n",
        "         del app.view_functions['get_activities']\n",
        "\n",
        "\n",
        "# --- Redefine the API endpoint with the correct dictionary return structure ---\n",
        "@app.route('/api/activities', methods=['GET'])\n",
        "def get_activities():\n",
        "    \"\"\"\n",
        "    API endpoint to get processed activity data from the database with pagination and filtering.\n",
        "    Reads from the SQLite database.\n",
        "    Query Parameters:\n",
        "        - page: int (default: 1) - the page number\n",
        "        - limit: int (default: 10) - items per page\n",
        "        - search: str (optional) - keyword to search in activity_title or product\n",
        "    \"\"\"\n",
        "    conn = get_db_connection()\n",
        "    if conn is None:\n",
        "        print(\"無法建立資料庫連線。\")\n",
        "        return jsonify({\"error\": \"無法連接資料庫\"}), 500\n",
        "\n",
        "    try:\n",
        "        cursor = conn.cursor()\n",
        "\n",
        "        # Get query parameters with default values\n",
        "        page = request.args.get('page', 1, type=int)\n",
        "        limit = request.args.get('limit', 10, type=int)\n",
        "        search_term = request.args.get('search', type=str)\n",
        "\n",
        "        # Ensure page and limit are positive\n",
        "        if page <= 0:\n",
        "            page = 1\n",
        "        if limit <= 0:\n",
        "            limit = 10 # Default to 10 if invalid limit is provided\n",
        "\n",
        "        # Build the base query\n",
        "        base_query = \"SELECT activity_title, activity_time, product FROM activities\"\n",
        "        count_query = \"SELECT COUNT(*) FROM activities\"\n",
        "        where_clause = \"\"\n",
        "        query_params = []\n",
        "\n",
        "        # Add filtering if search term is provided\n",
        "        if search_term:\n",
        "            where_clause = \" WHERE activity_title LIKE ? OR product LIKE ?\"\n",
        "            # Use '%' for SQL LIKE matching\n",
        "            query_params = [f\"%{search_term}%\", f\"%{search_term}%\"]\n",
        "\n",
        "        # Construct the final queries\n",
        "        # Ensure ordering for consistent pagination (e.g., by time descending)\n",
        "        final_data_query = base_query + where_clause + \" ORDER BY activity_time DESC LIMIT ? OFFSET ?\"\n",
        "        final_count_query = count_query + where_clause\n",
        "\n",
        "        # Add pagination parameters to the data query params\n",
        "        offset = (page - 1) * limit\n",
        "        data_query_params = query_params + [limit, offset]\n",
        "\n",
        "        # Execute the count query first (considering filtering)\n",
        "        cursor.execute(final_count_query, query_params)\n",
        "        total_records = cursor.fetchone()[0]\n",
        "\n",
        "        # Calculate total pages\n",
        "        total_pages = math.ceil(total_records / limit) if limit > 0 else 0\n",
        "\n",
        "        # Execute the data query with filtering and pagination\n",
        "        cursor.execute(final_data_query, data_query_params)\n",
        "\n",
        "        # Fetch all rows and convert them to a list of dictionaries\n",
        "        activities = [dict(row) for row in cursor.fetchall()]\n",
        "\n",
        "        # --- Return the data along with pagination info in a dictionary ---\n",
        "        return jsonify({\n",
        "            \"activities\": activities,\n",
        "            \"total_records\": total_records,\n",
        "            \"total_pages\": total_pages,\n",
        "            \"current_page\": page,\n",
        "            \"items_per_page\": limit\n",
        "        })\n",
        "\n",
        "    except sqlite3.Error as e:\n",
        "        print(f\"查詢資料庫錯誤: {e}\")\n",
        "        return jsonify({\"error\": \"無法從資料庫獲取資料\"}), 500\n",
        "    except Exception as e:\n",
        "        print(f\"獲取活動資料時發生未知錯誤: {e}\")\n",
        "        return jsonify({\"error\": str(e)}), 500\n",
        "    finally:\n",
        "        # Ensure the database connection is closed\n",
        "        if conn:\n",
        "            conn.close()\n",
        "            # print(\"資料庫連線已關閉。\") # Optional: uncomment for detailed logging\n",
        "\n",
        "\n",
        "# Function to run the Flask app in a separate thread for notebook environment\n",
        "# Re-using the function definition from previous cells\n",
        "def run_flask_app(port):\n",
        "    print(f\"Flask app正在背景執行緒中啟動 (本地測試 Port {port})...\")\n",
        "    # Explicitly use Flask's built-in development server\n",
        "    # use_reloader=False is important to prevent issues with threading in notebooks\n",
        "    try:\n",
        "        # Use the provided port\n",
        "        app.run(port=port, debug=False, use_reloader=False)\n",
        "    except OSError as e:\n",
        "        print(f\"啟動 Flask app 失敗，可能是 Port {port} 已經在使用中。錯誤: {e}\")\n",
        "        print(\"請嘗試重新啟動執行階段，或手動停止佔用 Port {port} 的程序。\")\n",
        "\n",
        "\n",
        "# Check if the thread is already running and port is free before starting\n",
        "def is_port_in_use(port):\n",
        "    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
        "        try:\n",
        "            s.bind(('localhost', port))\n",
        "            return False # Port is free\n",
        "        except socket.error:\n",
        "            return True # Port is in use\n",
        "\n",
        "# Check if the thread is alive or if a suitable port is free before starting\n",
        "# Try port 5001 first, then fallback to 5000 if needed\n",
        "port_to_use = 5001\n",
        "flask_thread = None # Initialize thread variable\n",
        "if is_port_in_use(port_to_use):\n",
        "    print(f\"Port {port_to_use} 已經在使用中，嘗試 Port 5000...\")\n",
        "    port_to_use = 5000\n",
        "    if is_port_in_use(port_to_use):\n",
        "         print(f\"Port {port_to_use} 也已經在使用中。無法啟動 Flask app。\")\n",
        "         print(\"請嘗試重新啟動執行階段，或手動停止佔用 Port {port} 的程序。\")\n",
        "         # Set flask_thread to None or a dummy to indicate no thread started\n",
        "         flask_thread = None\n",
        "    else:\n",
        "        # Port 5000 is free\n",
        "        # Check if a thread variable exists and if it's alive before creating a new one\n",
        "        if 'flask_thread' not in locals() or not (isinstance(flask_thread, threading.Thread) and flask_thread.is_alive()):\n",
        "             flask_thread = threading.Thread(target=run_flask_app, args=(port_to_use,)) # Pass port to the target function\n",
        "             flask_thread.daemon = True\n",
        "             flask_thread.start()\n",
        "             print(f\"Flask app正在背景執行緒中啟動 (本地測試 Port {port_to_use})...\")\n",
        "             print(\"請等待片刻，然後執行下一個程式碼格來測試 API。\")\n",
        "        else:\n",
        "             print(\"Flask app已經在背景執行緒中運行 (可能是 Port 5000)。\")\n",
        "else:\n",
        "    # Port 5001 is free\n",
        "    # Check if a thread variable exists and if it's alive before creating a new one\n",
        "    if 'flask_thread' not in locals() or not (isinstance(flask_thread, threading.Thread) and flask_thread.is_alive()):\n",
        "        flask_thread = threading.Thread(target=run_flask_app, args=(port_to_use,)) # Pass port to the target function\n",
        "        flask_thread.daemon = True\n",
        "        flask_thread.start()\n",
        "        print(f\"Flask app正在背景執行緒中啟動 (本地測試 Port {port_to_use})...\")\n",
        "        print(\"請等待片刻，然後執行下一個程式碼格來測試 API。\")\n",
        "    else:\n",
        "        print(f\"Flask app已經在背景執行緒中運行 (可能是 Port {port_to_use} 或 Port 5000)。\")\n",
        "\n",
        "\n",
        "# Store the port being used so the test script knows where to send requests\n",
        "# Check if flask_thread was actually started before setting the port\n",
        "if flask_thread and flask_thread.is_alive():\n",
        "    flask_port = port_to_use\n",
        "    print(f\"Flask app 預計運行在 Port {flask_port}\")\n",
        "else:\n",
        "     # If thread wasn't started, default to a port for the test script\n",
        "     flask_port = 5000 # Default port if unable to start app\n",
        "     print(f\"無法確定 Flask app 運行 Port，測試將嘗試 Port {flask_port}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "732c22c8"
      },
      "source": [
        "**Reasoning**:\n",
        "The Flask app should now be running correctly in a background thread on an available port. The next step is to test the updated API endpoint to ensure it functions correctly with different query parameters and returns the data in the expected structured JSON format. I will use the `requests` library to make calls to the `/api/activities` endpoint with various combinations of `page`, `limit`, and `search` parameters and verify the structure and content of the responses. This addresses instruction 16 of the subtask by testing the API functionality.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6c1c004d"
      },
      "source": [
        "import requests\n",
        "import time\n",
        "import json\n",
        "\n",
        "# Give the Flask app a moment to ensure the new endpoint is active\n",
        "time.sleep(5) # Increased sleep time to allow the app to fully start\n",
        "\n",
        "# Use the port determined in the previous cell\n",
        "# Ensure flask_port is defined, default to 5000 if not\n",
        "flask_port_to_test = locals().get('flask_port', 5000)\n",
        "\n",
        "print(f\"--- 測試包含分頁和篩選功能的 API 端點 (使用 Port {flask_port_to_test}) ---\")\n",
        "\n",
        "# Test Case 1: Get the first page with default limit (10)\n",
        "print(\"\\n測試案例 1: 獲取第一頁 (預設每頁筆數 10)...\")\n",
        "try:\n",
        "    response1 = requests.get(f'http://127.0.0.1:{flask_port_to_test}/api/activities')\n",
        "    if response1.status_code == 200:\n",
        "        data1 = response1.json()\n",
        "        print(\"API 請求成功。回應資料結構:\")\n",
        "        print(json.dumps(data1, indent=2, ensure_ascii=False)) # ensure_ascii=False for Chinese characters\n",
        "        # Verify the structure and content\n",
        "        if isinstance(data1, dict) and 'activities' in data1 and 'total_records' in data1 and 'total_pages' in data1:\n",
        "            print(f\"總記錄數: {data1.get('total_records')}\")\n",
        "            print(f\"總頁數: {data1.get('total_pages')}\")\n",
        "            print(f\"目前頁碼: {data1.get('current_page')}\")\n",
        "            print(f\"每頁筆數: {data1.get('items_per_page')}\")\n",
        "            print(f\"獲取到的活動記錄筆數: {len(data1.get('activities', []))}\")\n",
        "            # Basic checks\n",
        "            assert data1.get('total_records') == 4, \"總記錄數不正確\"\n",
        "            assert data1.get('total_pages') == 1, \"總頁數不正確\"\n",
        "            assert data1.get('current_page') == 1, \"目前頁碼不正確\"\n",
        "            assert data1.get('items_per_page') == 10, \"每頁筆數不正確\"\n",
        "            assert len(data1.get('activities', [])) == 4, \"獲取到的活動記錄筆數不正確\"\n",
        "            print(\"測試案例 1 驗證成功。\")\n",
        "        else:\n",
        "             print(\"回應資料結構不正確。\")\n",
        "    else:\n",
        "        print(f\"API 請求失敗，狀態碼：{response1.status_code}\")\n",
        "        print(\"回應內容：\")\n",
        "        print(response1.text)\n",
        "except requests.exceptions.ConnectionError as e:\n",
        "    print(f\"無法連接到 Flask 應用程式 Port {flask_port_to_test}。請確認前一個程式碼格已執行，並且 Flask 應用程式正在運行。錯誤：{e}\")\n",
        "except AssertionError as e:\n",
        "    print(f\"測試案例 1 驗證失敗: {e}\")\n",
        "except Exception as e:\n",
        "    print(f\"測試 API 時發生錯誤：{e}\")\n",
        "\n",
        "\n",
        "# Test Case 2: Get the second page with a smaller limit (2)\n",
        "print(\"\\n測試案例 2: 獲取第二頁，每頁 2 筆...\")\n",
        "try:\n",
        "    response2 = requests.get(f'http://127.0.0.1:{flask_port_to_test}/api/activities?page=2&limit=2')\n",
        "    if response2.status_code == 200:\n",
        "        data2 = response2.json()\n",
        "        print(\"API 請求成功。回應資料結構:\")\n",
        "        print(json.dumps(data2, indent=2, ensure_ascii=False))\n",
        "        # Verify the structure and content\n",
        "        if isinstance(data2, dict) and 'activities' in data2 and 'total_records' in data2 and 'total_pages' in data2:\n",
        "            print(f\"總記錄數: {data2.get('total_records')}\")\n",
        "            print(f\"總頁數: {data2.get('total_pages')}\")\n",
        "            print(f\"目前頁碼: {data2.get('current_page')}\")\n",
        "            print(f\"每頁筆數: {data2.get('items_per_page')}\")\n",
        "            print(f\"獲取到的活動記錄筆數: {len(data2.get('activities', []))}\")\n",
        "            # Basic checks\n",
        "            assert data2.get('total_records') == 4, \"總記錄數不正確\"\n",
        "            assert data2.get('total_pages') == 2, \"總頁數不正確\"\n",
        "            assert data2.get('current_page') == 2, \"目前頁碼不正確\"\n",
        "            assert data2.get('items_per_page') == 2, \"每頁筆數不正確\"\n",
        "            assert len(data2.get('activities', [])) == 2, \"獲取到的活動記錄筆數不正確\"\n",
        "            # Check content of the second page (based on DESC time order)\n",
        "            # Fetch all data to determine expected order for verification\n",
        "            response_all = requests.get(f'http://127.0.0.1:{flask_port_to_test}/api/activities?limit=100') # Get enough data to cover all\n",
        "            all_activities_data = response_all.json().get('activities', []) if response_all.status_code == 200 else []\n",
        "            full_list_ordered_desc = sorted(all_activities_data, key=lambda x: x.get('activity_time', ''), reverse=True)\n",
        "            expected_page_2 = full_list_ordered_desc[2:4] # Assuming 4 total records\n",
        "            retrieved_page_2 = data2.get('activities', [])\n",
        "\n",
        "            # Simple check: ensure titles and times from expected page 2 are in retrieved page 2\n",
        "            expected_items = [(item.get('activity_title'), item.get('activity_time')) for item in expected_page_2]\n",
        "            retrieved_items = [(item.get('activity_title'), item.get('activity_time')) for item in retrieved_page_2]\n",
        "\n",
        "            assert set(expected_items) == set(retrieved_items), \"第二頁的活動記錄不正確\"\n",
        "\n",
        "            print(\"測試案例 2 驗證成功。\")\n",
        "        else:\n",
        "             print(\"回應資料結構不正確。\")\n",
        "except requests.exceptions.ConnectionError as e:\n",
        "    print(f\"無法連接到 Flask 應用程式 Port {flask_port_to_test}。請確認前一個程式碼格已執行，並且 Flask 應用程式正在運行。錯誤：{e}\")\n",
        "except AssertionError as e:\n",
        "    print(f\"測試案例 2 驗證失敗: {e}\")\n",
        "except Exception as e:\n",
        "    print(f\"測試 API 時發生錯誤：{e}\")\n",
        "\n",
        "\n",
        "# Test Case 3: Search for a keyword (e.g., \"Search\")\n",
        "print(\"\\n測試案例 3: 搜尋關鍵字 'Search'...\")\n",
        "try:\n",
        "    response3 = requests.get(f'http://127.0.0.1:{flask_port_to_test}/api/activities?search=Search')\n",
        "    if response3.status_code == 200:\n",
        "        data3 = response3.json()\n",
        "        print(\"API 請求成功。回應資料結構:\")\n",
        "        print(json.dumps(data3, indent=2, ensure_ascii=False))\n",
        "        # Verify the structure and content\n",
        "        if isinstance(data3, dict) and 'activities' in data3 and 'total_records' in data3 and 'total_pages' in data3:\n",
        "            print(f\"總記錄數 (篩選後): {data3.get('total_records')}\")\n",
        "            print(f\"總頁數 (篩選後): {data3.get('total_pages')}\")\n",
        "            print(f\"目前頁碼: {data3.get('current_page')}\")\n",
        "            print(f\"每頁筆數: {data3.get('items_per_page')}\")\n",
        "            print(f\"獲取到的活動記錄筆數: {len(data3.get('activities', []))}\")\n",
        "            # Basic checks (assuming \"Search\" appears in \"Searched for example\" title or \"Search\" product)\n",
        "            # Based on dummy data, there are two records matching \"Search\" (title or product)\n",
        "            assert data3.get('total_records') == 2, \"篩選後的總記錄數不正確\"\n",
        "            assert data3.get('total_pages') == 1, \"篩選後的總頁數不正確\"\n",
        "            assert data3.get('current_page') == 1, \"目前頁碼不正確\"\n",
        "            assert data3.get('items_per_page') == 10, \"每頁筆數不正確\"\n",
        "            assert len(data3.get('activities', [])) == 2, \"獲取到的活動記錄筆數不正確\"\n",
        "            # Check content - both records should contain \"Search\" in title or product\n",
        "            for activity in data3.get('activities', []):\n",
        "                title = activity.get('activity_title', '').lower()\n",
        "                product = activity.get('product', '').lower()\n",
        "                assert 'search' in title or 'search' in product, \"篩選結果包含不相關的記錄\"\n",
        "\n",
        "            print(\"測試案例 3 驗證成功。\")\n",
        "        else:\n",
        "             print(\"回應資料結構不正確。\")\n",
        "except requests.exceptions.ConnectionError as e:\n",
        "    print(f\"無法連接到 Flask 應用程式 Port {flask_port_to_test}。請確認前一個程式碼格已執行，並且 Flask 應用程式正在運行。錯誤：{e}\")\n",
        "except AssertionError as e:\n",
        "    print(f\"測試案例 3 驗證失敗: {e}\")\n",
        "except Exception as e:\n",
        "    print(f\"測試 API 時發生錯誤：{e}\")\n",
        "\n",
        "# Test Case 4: Search for a keyword and apply pagination (e.g., \"Google\", page 1, limit 1)\n",
        "print(\"\\n測試案例 4: 搜尋關鍵字 'Google'，第一頁，每頁 1 筆...\")\n",
        "try:\n",
        "    response4 = requests.get(f'http://127.0.0.1:{flask_port_to_test}/api/activities?search=Google&page=1&limit=1')\n",
        "    if response4.status_code == 200:\n",
        "        data4 = response4.json()\n",
        "        print(\"API 請求成功。回應資料結構:\")\n",
        "        print(json.dumps(data4, indent=2, ensure_ascii=False))\n",
        "        # Verify the structure and content\n",
        "        if isinstance(data4, dict) and 'activities' in data4 and 'total_records' in data4 and 'total_pages' in data4:\n",
        "            print(f\"總記錄數 (篩選後): {data4.get('total_records')}\")\n",
        "            print(f\"總頁數 (篩選後): {data4.get('total_pages')}\")\n",
        "            print(f\"目前頁碼: {data4.get('current_page')}\")\n",
        "            print(f\"每頁筆數: {data4.get('items_per_page')}\")\n",
        "            print(f\"獲取到的活動記錄筆數: {len(data4.get('activities', []))}\")\n",
        "             # Basic checks (assuming \"Google\" appears in title or product)\n",
        "            # Based on dummy data, there are two records matching \"Google\" (title or product)\n",
        "            assert data4.get('total_records') == 2, \"篩選後的總記錄數不正確\"\n",
        "            assert data4.get('total_pages') == 2, \"篩選後的總頁數不正確 (每頁 1 筆)\"\n",
        "            assert data4.get('current_page') == 1, \"目前頁碼不正確\"\n",
        "            assert data4.get('items_per_page') == 1, \"每頁筆數不正確\"\n",
        "            assert len(data4.get('activities', [])) == 1, \"獲取到的活動記錄筆數不正確\"\n",
        "            # Check content - the first record should match \"Google\" search and be the latest from the filtered set\n",
        "            # Get the filtered list and sort it to find the expected first item\n",
        "            response_filtered = requests.get(f'http://127.0.0.1:{flask_port_to_test}/api/activities?search=Google&limit=100')\n",
        "            filtered_activities_all = response_filtered.json().get('activities', []) if response_filtered.status_code == 200 else []\n",
        "            filtered_ordered_desc = sorted(filtered_activities_all, key=lambda x: x.get('activity_time', ''), reverse=True)\n",
        "            if filtered_ordered_desc:\n",
        "                 expected_first_item = filtered_ordered_desc[0]\n",
        "                 retrieved_first_item = data4.get('activities', [])[0]\n",
        "                 assert expected_first_item.get('activity_title') == retrieved_first_item.get('activity_title') and \\\n",
        "                        expected_first_item.get('activity_time') == retrieved_first_item.get('activity_time'), \\\n",
        "                        \"篩選/分頁結果不正確 (第一筆記錄不符合預期)\"\n",
        "            else:\n",
        "                 assert len(data4.get('activities', [])) == 0, \"沒有預期結果時不應返回活動記錄\"\n",
        "\n",
        "\n",
        "            print(\"測試案例 4 驗證成功。\")\n",
        "        else:\n",
        "             print(\"回應資料結構不正確。\")\n",
        "except requests.exceptions.ConnectionError as e:\n",
        "    print(f\"無法連接到 Flask 應用程式 Port {flask_port_to_test}。請確認前一個程式碼格已執行，並且 Flask 應用程式正在運行。錯誤：{e}\")\n",
        "except AssertionError as e:\n",
        "    print(f\"測試案例 4 驗證失敗: {e}\")\n",
        "except Exception as e:\n",
        "    print(f\"測試 API 時發生錯誤：{e}\")\n",
        "\n",
        "\n",
        "print(\"\\n--- API 端點測試完成 ---\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9445ed12"
      },
      "source": [
        "**Reasoning**:\n",
        "Test Case 4 failed because the expected total records for the search term 'Google' was 2 based on the dummy data, but the API returned 0. This indicates an issue with the filtering logic for the search term 'Google'. I need to examine the dummy data and the SQL query in the `get_activities` endpoint to understand why 'Google' is not matching any records. It's possible the search term is case-sensitive in the SQL `LIKE` clause or the dummy data doesn't contain 'Google' in the expected fields. I will re-examine the dummy data and the API code to identify and fix the issue. This addresses instruction 16 by debugging the API functionality based on the failed test case.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQqh9HeOgTuZ"
      },
      "source": [
        "導入 sqlite3\n",
        "導入 o\n",
        "導入 json\n",
        "從 flask 導入 Flask 、 jsonify 、 請求\n",
        "導入 線程\n",
        "導入 時間\n",
        "導入 套接字\n",
        "導入 數學\n",
        "\n",
        "# 如果存在，則重新使用 Flask 應用程式實例，否則建立一個新的\n",
        "嘗試：\n",
        "    app\n",
        "except  NameError ：\n",
        "    app = Flask ( __name__ )\n",
        "\n",
        "# 重新使用資料庫配置和輔助函數#\n",
        "DATABASE_FILE、DATABASE_SCHEMA、create_database_and_table 、get_db_connection\n",
        "# 假定在先前的單元格中定義並 在核心中可用\n",
        "\n",
        "# 確保資料庫和表格存在，並填入了模擬資料\n",
        "create_database_and_table ()\n",
        "# 僅當表格為空時插入模擬數據，以避免    重複 執行時出現重複\n",
        "conn_check = get_db_connection ( )\n",
        "if  conn_check :\n",
        "    cursor_check = conn_check.cursor ( )\n",
        "    curute_Peck .\n",
        "= cursor_check.fetchone ()[ 0 ]\n",
        "    conn_check.close () if count ==  0  : print ( \"資料庫為空，插入模擬資料... \" ) #假設            process_and_insert_data_incrementally ( ) 定義 並可工作process_and_insert_data_incrementally 函數未定義。​​​​​​​​​            ​​​​​​​​ \"資料庫中已有 { count } 筆資料，跳過模擬資料插入。\" )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 修改 API 端點，以便透過分頁和過濾從資料庫中取得資料\n",
        "# 檢查端點「get_activities」是否已存在，以避免重新新增#\n",
        "更強大的檢查和刪除現有規則 existing_rule\n",
        "=  None\n",
        "for rule in list ( app.url_map.iter_rules ()): #   直接規則 清單的副本( app.url .  rule.rule :         existing_rule = rule break\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if  existing_rule : print ( f \"移除現有路由 ' { existing_rule.rule } '，端點名稱 ' { existing_rule.endpoint } '\" )     app.url_map._rules.remove ( existing_rule ) # 為安全性起見，也從 view_function  ' : del  app.view_functions [ 'get_activities' ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# --- 使用正確的字典返回結構重新定義 API 端點---\n",
        "@app.route ( '/api/activities' ,  methods= [ 'GET' ])\n",
        "def get_activities () :  \"\"\" API 端點透過分頁和過濾從資料庫        取得    已    處理的活動    資料        。 int（預設值：10）- 每頁項目數-         search: str（可選）-在 activity_title 或 product 中搜尋的關鍵字    \"\"\" conn =     get_db_connection () if  conn  is None : print ( \"無法建立資料庫連結。\" ) return jsonify  ( { \"error\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    嘗試：\n",
        "        cursor = conn.cursor （）\n",
        "\n",
        "        # 取得預設值的查詢參數\n",
        "        page = request.args.get ( 'page' , 1 , type = int )\n",
        "        limit = request.args.get ( 'limit' , 10 , type = int )\n",
        "        search_term = request.args.get ( 'search' , type = str )\n",
        "\n",
        "        # 確保頁面和限制為正數，如果 頁面 <=  0 ：            頁 =  1 ，如果 限制 <=  0 ：            限制 =  10 # 如果提供了無效的限制，則預設為 10\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # 建立基本查詢\n",
        "        base_query =  \"SELECT activity_title, activity_time, product FRO M activities\"\n",
        "        count_query =  \"SELECT COUNT(*) FROM activities\"\n",
        "        where_clause =  \"\"\n",
        "        query_params =  []\n",
        "\n",
        "        # 如果提供了搜尋字詞，則新增篩選if  search_term : # 在SQLite中使用 COLLATE NOCASE 進行不區分大小寫的搜尋where_clause = \" WHERE activity_title LIKE ? COLLATE NOCASE OR p oduct             LIKE  ? COLLATE NOsearchE             \"  #對NOCAS_gsearch \" , f \"% { search_term } %\" ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # 建立最終查詢# 確保分頁排序一致（例如， 按時間降序）        final_data_query = base_query + where_clau se +  \" ORDER BY activity_time DESC LIMIT ? OFFSET ? \"         final_count_query = count_laury + where_c se\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # 為資料查詢新增分頁參數 para ms\n",
        "        offset =  ( page -  1 )  * limit\n",
        "        data_query_params = query_params +  [ limit ,  offset ]\n",
        "\n",
        "        # 首先執行計數查詢（考慮過濾）\n",
        "        cursor.execute ( final_count_query ,  query_params )\n",
        "        total_records = cursor.fetchone ()[ 0 ]\n",
        "\n",
        "        # 計算總頁數\n",
        "        total_pages = math.ceil ( total_records / limit ) if  limit >  0 else 0\n",
        "\n",
        "        # 執行帶有過濾和分頁的資料查詢\n",
        "        cursor.execute ( final_data_query ,  data_query_params )\n",
        "\n",
        "        # 取得所有行並將其轉換為字典列表\n",
        "        activities =  [ dict ( row ) for  row  in  cursor.fetchall ()]\n",
        "\n",
        "        # ---在字典中傳回資料以及分頁資訊--- return  jsonify ({ \"activities\" :  activities , \"total_records\" :  total_records , \"total_pages\" : total_pages , \"current_page\" : page , \"items_perli_page :  pages , \"current_page\" :  page , \"items_perli_page : :  li\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "     except sqlite3.Error  as  e : print ( f \"查詢資料庫 錯誤: { e } \" ) return  jsonify ( { \"error\" : \"無法從資料庫取得 資料 \" } ), 500 except Exception as  e  : print ( f \"取得活動資料時發生 未知錯誤{ str 0 : return ) finally : # 確保資料庫連線已關閉if  conn :             conn.close () # print(\"資料庫連線已關閉。\") # 可選：取消 詳細日誌記錄的註釋\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 在筆記本環境的單獨執行緒中執行 Flask 應用程式的函數\n",
        "# 重複使用先前儲存格中的函數定義def\n",
        "run_flask_app ( port ) : print  ( f \" Flask app正在後台執行緒中啟動 (本機測試 Port  { port } )...\" ) # 明確使用 Flask 的內建開發者 (F) 的筆記本電腦內建問題」的功能性「內建        問題」。port=port ,  debug= False ,  use_reloader= False )  except OSError  as  e : print ( f \" 啟動Flask app失敗，可能是 Port { port }已經在使用中。 錯誤 : { e } \" ) print ( \"請嘗試停止重新啟動執行程式。\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#在啟動之前檢查            執行緒是否已在運作且連接埠 是否空閒def  is_port_in_use\n",
        "( port ) : with socket.socket  (  socket.AF_INET , socket.SOCK_STREAM )  as s : try  : s.bind ( ( ' localhost' port  ports receptor ports . True # 連接埠正在使用中\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 啟動前檢查執行緒是否處於活動狀態或適當的連接埠是否空閒#先\n",
        "嘗試連接埠 5001，如果需要則回退到 5000 port_to_use\n",
        "=  5001flask_thread\n",
        "=  None # 初始化執行緒變數\n",
        "if  is_port_in_use ( port_to_use ): print ( f \"   Port port_to 」    port_to_use =  5000 if  is_port_in_use ( port_to_use ): print ( f \"Port { port_to_use }也已經在使用中。無法啟動 Flask app.\" ) print ( \"請嘗試重新 啟動執行階段，或手動停止佔用程式{ port  }         的 代碼。  None else : # 連接埠 5000 是空閒的#在建立新變數之前檢查執行緒變數是否存在以及它是否處於活動狀態if              '  flask_thread ' not in locals ( ) or not ( isinstance ( flask_thread ,  threading.Thread ) andflask_threadis_aliveask_thread . target=run_flask_app ,  args= ( port_to_use ,)) # 將連接埠傳遞給目標函數             Flask_thread.daemon =  True              Flask_thread.start () print ( f \"Flask app正在後台執行緒中啟動(本機測試 Port { port_to_) print ( f \" Flask app正在後台執行緒中啟動(本機測試 Port { port_to_ print } ) ... \" ) print  print \"Flask app已經在後台執行緒中執行 (可能是 Port 5000）。\" ) else : # 連接埠 5001 是空閒的#在建立新執行緒變數之前，檢查執行緒變數 是否存在以及是否處於活動狀態if 'flask_thread' not in locals () or not ( isinstance (  Thask )_ ) . ()):         flask_thread = threading.Thread ( target=run_flask_app\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        ",  args= ( port_to_use ,)) # 將 port 傳遞給目標函數         flask_thread.daemon\n",
        "        =  Trueflask_thread.start () print ( f \" Flask app正在後台執行緒中啟動(本機測試 Port  { port_to_use } )...\" ) print ( \"請等請執行一個碼，然後測試下一個9 print ( app已經在背景執行緒中運作 (可能是 Port  { port_to_use } 或連接埠 5000) 。\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 儲存正在使用的端口，以便測試腳本知道將請求發送到哪裡#在設定端口\n",
        "之前檢查 flask_thread 是否已經啟動\n",
        "if  flask_thread  and  flask_thread.is_alive ():\n",
        "    flask_port = port_to_use print  ( f \" Flask app 則預計     運行 在Portal { flask_port } \" flask 5000 # 如果無法啟動應用程序，則預設連接埠print ( f \"無法確定 Flask app 運行 Port，測試將測試 Port  { flask_port } \" )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3b9befc1"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   The `process_and_insert_data_incrementally` function was successfully modified to check for existing records based on `activity_title` and `activity_time`.\n",
        "*   The modified function correctly updates existing records if the `product` information is different and skips records that are identical.\n",
        "*   Execution of the incremental data processing showed that 0 new records were inserted, 2 existing records were updated, and 3 records were skipped from the simulated data, resulting in a total of 4 records in the database.\n",
        "*   The Flask API endpoint `/api/activities` was modified to read data from the SQLite database and include logic for pagination (`LIMIT`, `OFFSET`) and filtering (`WHERE LIKE`).\n",
        "*   The API endpoint is designed to return a JSON object containing the list of activities, total record count, total pages, current page, and items per page.\n",
        "*   Attempts to test the updated Flask API endpoint in the notebook environment failed due to issues with starting the Flask development server in a background thread, specifically encountering \"Port in use\" errors on both attempted ports (5000 and 5001).\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   While the data processing logic for incremental updates is functional, further testing with a wider variety of data scenarios (e.g., large datasets, data with missing fields, data with different time formats) would ensure its robustness.\n",
        "*   The primary blocker for testing the API was the inability to reliably start and access the Flask development server in the notebook environment. For future development or deployment, consider using a more stable hosting method for the Flask application (e.g., a dedicated Flask server like Gunicorn with a production-ready web server like Nginx) or utilizing testing frameworks that mock the Flask request context for unit testing the endpoint logic without needing a running server.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1051a38"
      },
      "source": [
        "import sqlite3\n",
        "import os\n",
        "import json\n",
        "from flask import Flask, jsonify, request\n",
        "import math\n",
        "\n",
        "# Define the database file path\n",
        "DATABASE_FILE = 'activities.db'\n",
        "\n",
        "# Define the database schema\n",
        "DATABASE_SCHEMA = \"\"\"\n",
        "CREATE TABLE IF NOT EXISTS activities (\n",
        "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "    activity_title TEXT NOT NULL,\n",
        "    activity_time TEXT NOT NULL,\n",
        "    product TEXT\n",
        ");\n",
        "\"\"\"\n",
        "\n",
        "def create_database_and_table():\n",
        "    \"\"\"Creates the database file and the activities table if they don't exist.\"\"\"\n",
        "    conn = None\n",
        "    try:\n",
        "        conn = sqlite3.connect(DATABASE_FILE)\n",
        "        cursor = conn.cursor()\n",
        "        cursor.execute(DATABASE_SCHEMA)\n",
        "        conn.commit()\n",
        "        print(f\"資料庫 '{DATABASE_FILE}' 已準備就緒，活動記錄表格已建立或已存在。\")\n",
        "    except sqlite3.Error as e:\n",
        "        print(f\"資料庫操作錯誤: {e}\")\n",
        "    finally:\n",
        "        if conn:\n",
        "            conn.close()\n",
        "\n",
        "def get_db_connection():\n",
        "    \"\"\"Establishes and returns a database connection.\"\"\"\n",
        "    try:\n",
        "        conn = sqlite3.connect(DATABASE_FILE)\n",
        "        conn.row_factory = sqlite3.Row # Return rows as dictionary-like objects\n",
        "        return conn\n",
        "    except sqlite3.Error as e:\n",
        "        print(f\"無法建立資料庫連線: {e}\")\n",
        "        return None\n",
        "\n",
        "# 模擬原始 Google Takeout JSON最初所在的路徑\n",
        "simulated_raw_data_path =  '/tmp/simulated_google_takeout_raw.json'\n",
        "\n",
        "# 建立或更新一個包含資料的虛擬 RAW JSON 檔案來 測試更新\n",
        "dummy_raw_data =  [ { \"header\" : \"Google Search\" , \" title \" : \" Searched for example\" , \" time \" : \" 2023-10-27T10 : 00 : 00.000 , \"title\" : \"Watched a video\" , \"time\" : \"2023-10-27T10:05:00.000Z\" , \"products\" : [ \"YouTube\" ] }, { \"header\" : \"Google Maps\" , \"tletle\" : \"YouTube\" ] }, { \"header\" : \"Google Maps\" , \"tletle\" : \"tied for title \" \"2023-10-27T10:10:00.000Z\" , \"products\" : [ \"Maps\" ] }, { \"header\" : \"Google 搜尋\" , \"title\" : \"搜尋了範例\" , \"time\" : \"2023-10-2710: \"搜尋了範例\" , \"time\" : \"2023-10-2710: \"搜尋了範例\" , \"time\" : \"2023-10-2700: \"搜尋了範例\" \"網頁與應用程式活動\" ] }, { \"header\" : \"Google 圖片\" , \"title\" : \"檢視了圖片\" , \"time\" : \"2023-10-27T10:15:00.000Z\" , \" products \" : [ \"圖片\" ] } ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 如果不存在則建立虛擬原始資料文件，或用新的虛擬資料覆寫它以進行測試\n",
        "with open ( simulated_raw_data_path , 'w' ) as  f :\n",
        "    json.dump ( dummy_raw_data ,  f ,  indent= 4 )\n",
        "print ( f \"模擬原始資料檔已建立/更新於 程式碼\n",
        "\n",
        "# 修改資料處理函數，從原始JSON中讀取並增量更新/插入資料庫\n",
        "def process_and_insert_data_incrementally () :  \"\"\"    讀取    模擬    的Google Takeout原始數據，處理後增量更新或插入SQLite 資料庫。    處理資料時，檢查 記錄 是否存在，如果更新產品資訊，否則插入新記錄。\"無法建立資料庫連線，跳過資料處理及插入。\" )返回\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    遊標 = conn.cursor ()\n",
        "    插入計數 =  0\n",
        "    更新計數 =  0\n",
        "    跳過計數 =  0\n",
        "\n",
        "    嘗試：# 從模擬的原始 JSON 檔案讀取資料with open ( simulated_raw_data_path , 'r' ) as  f :             takeout_data = json.load ( f )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        print ( \"\\n開始增量處理和插入/更新資料...\" )\n",
        "\n",
        "        # Process data and insert/update into the database\n",
        "        for item in takeout_data:\n",
        "            try:\n",
        "                processed_item = {\n",
        "                    'activity_title': item.get('title', '無標題'),\n",
        "                    'activity_time': item.get('time', '無時間資訊'),\n",
        "                    'product': ', '.join(item.get('products', [])) or '無產品資訊'\n",
        "                }\n",
        "\n",
        "                # 檢查是否已經存在相同標題和時間的記錄\n",
        "                cursor.execute ( \"SELECT id, product FROM activities WHERE activity _title = ? AND activity_time = !\" , ( processed_item [ 'activity_title '                 ] ,  processed_ittimes [ dvates ) ' ()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                if  existing_record : # 記錄存在，檢查產品是否需要更新existing_id                     , existing_product  = existing_record if  existing_product != processed_item [ 'product' ]: #產品資訊不同，更新現有記錄cur                         . processed_item [ 'product' ],  existing_id ) )                         updated_count +=  1 print ( f \"更新記錄 (ID:  { existing_id } ):  { processed_item [ 'activity_title' ]} ( { processed_item [ 'activity_item [ 'activity_title' ]}  ( { processed_item []prodity_item []-vtime's ) ' ]}s> \" processed_item [ ]prodity_item] -v > 新 產品] ) else : # 記錄存在且產品相同，跳過                        skipped_count +=  1 print ( f \"記錄已存在且內容相同，跳過插入/更新:  { processed_item [ 'activity_title' ]}  ( { processed_item [ 'activity_time' ]} )\" INS                     )不存在: # INSv電話(activity_title, activity_ time, product) VALUES (?, ?, ?)\" , ( processed_item [ 'activity_title' ],  processed_item [ 'activity_time' ],  processed_item [ 'product' ])插入1_counts_time ' ] , processed_item [ ' product ' ]  )                    插入 1月_count 'activity_title' ]}  ( { processed_item [ 'activity_time' ]} )\" )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "             except sqlite3.Error  as e : print ( f \"處理或插入/更新 單筆資料錯誤:  { e }  - 資料:  { processed_item } \" ) # 決定出錯時繼續或中斷\n",
        "\n",
        "\n",
        "\n",
        "        conn.commit () # 循環後提交交易 print ( f \"\\n完成增量處理。已插入 { inserted_count } 筆記錄新，更新 { updated_count } 筆記錄，跳過 { skipped_count } 筆記錄。\" )\n",
        "\n",
        "\n",
        "     except FileNotFoundError : print ( f \"錯誤: 模擬原始資料檔案找不到於 { simulated_raw_data_path } \" ) except  json.JSONDecodeError : print ( f \"錯誤: 無法解析 模擬 原始資料 檔{ simulated_raw_data_path } 中的 ExJSON \" ) { sim \"處理和插入/更新資料時發生未知錯誤:  { e } \" ) finally : if  conn :             conn.close () #關閉資料庫連接\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# --- Flask 應用程式定義 ---\n",
        "app = Flask ( __name__ )\n",
        "\n",
        "@app.route ( '/api/activities' ,  methods= [ 'GET' ])\n",
        "def get_activities () :  \"\"\"     API 端點，用於從資料庫取得已處理的活動數據，並進行分頁與篩選。    從 SQLite 資料庫讀取。        查詢    參數：        - page: int（        預設值：1）- 4-int . str（可選）-在 activity_title 或 product 中搜尋的關鍵字    \"\"\"     conn = get_db_connection () if  conn  is None : return  jsonify ({ \"error\" : \"非法連接資料庫\" }), 500\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    嘗試：\n",
        "        cursor = conn.cursor （）\n",
        "\n",
        "        # 取得預設值的查詢參數\n",
        "        page = request.args.get ( 'page' , 1 , type = int )\n",
        "        limit = request.args.get ( 'limit' , 10 , type = int )\n",
        "        search_term = request.args.get ( 'search' , type = str )\n",
        "\n",
        "        # 確保頁面和限制為正數，如果 頁面 <=  0 ：            頁 =  1 ，如果 限制 <=  0 ：            限制 =  10 # 如果提供了無效的限制，則預設為 10\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # 建立基本查詢\n",
        "        base_query =  \"SELECT activity_title, activity_time, product FRO M activities\"\n",
        "        count_query =  \"SELECT COUNT(*) FROM activities\"\n",
        "        where_clause =  \"\"\n",
        "        query_params =  []\n",
        "\n",
        "        # 如果提供了搜尋字詞，則新增篩選if  search_term : # 在SQLite中使用 COLLATE NOCASE 進行不區分大小寫的搜尋where_clause = \" WHERE activity_title LIKE ? COLLATE NOCASE OR p oduct             LIKE  ? COLLATE NOsearchE             \"  #對NOCAS_gsearch \" , f \"% { search_term } %\" ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # 建立最終查詢# 確保分頁排序一致（例如， 按時間降序）        final_data_query = base_query + where_clau se +  \" ORDER BY activity_time DESC LIMIT ? OFFSET ? \"         final_count_query = count_laury + where_c se\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # 為資料查詢新增分頁參數 para ms\n",
        "        offset =  ( page -  1 )  * limit\n",
        "        data_query_params = query_params +  [ limit ,  offset ]\n",
        "\n",
        "        # 首先執行計數查詢（考慮過濾）\n",
        "        cursor.execute ( final_count_query ,  query_params )\n",
        "        total_records = cursor.fetchone ()[ 0 ]\n",
        "\n",
        "        # 計算總頁數\n",
        "        total_pages = math.ceil ( total_records / limit ) if  limit >  0 else 0\n",
        "\n",
        "        # 執行帶有過濾和分頁的資料查詢\n",
        "        cursor.execute ( final_data_query ,  data_query_params )\n",
        "\n",
        "        # 取得所有行並將其轉換為字典列表\n",
        "        activities =  [ dict ( row ) for  row  in  cursor.fetchall ()]\n",
        "\n",
        "        # 在字典中傳回資料以及分頁資訊 return  jsonify ({ \"activities\" :  activities , \"total_records\" :  total_records , \"total_pages\" :  total_pages , \"current_page\" :  page , \"items_per_page\" :  limit })\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "     except sqlite3.Error  as  e : print ( f \"查詢資料庫 錯誤: { e } \" ) return  jsonify ( { \"error\" : \"無法從資料庫取得 資料 \" } ), 500 except Exception as  e  : print ( f \"取得活動資料時發生 未知錯誤{ str 0 : return ) finally : # 確保資料庫連線已關閉if  conn :             conn.close ()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# --- 執行 Flask 應用程式的入口點 ---\n",
        "if __name__  ==  '__main__' :  # 確保直接執行腳本時建立並填入資料        庫和表    create_database_and_table ()     conn_check = get_db_connection ( ) if  conn_check :         cursor_check = conn_check. FROM events\" ) count =         cursor_check.fetchone ()[ 0 ]         conn_check.close () if count  ==  0 : print ( \"資料庫為空，插入模擬資料...\" )             process_and_insert_data_incrementally () else資料庫中：已跳過f 資料庫 中，\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    print ( \"\\n--- 啟動 Flask 開發伺服器 ---\" ) # 執行 Flask 開發伺服器# 對於生產，使用 WSGI 伺服器，如 Gunicorn 或 uWSGI     app.run ( port= 5000 ,  debug= True )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ceeef5e"
      },
      "source": [
        "**如何運行 Flask 應用程式：**\n",
        "\n",
        "1.  將上面的程式碼複製並貼上到您電腦上的文字編輯器中。\n",
        "2.  將檔案儲存為 `app.py`。\n",
        "3.  開啟終端機或命令提示字元。\n",
        "4.  導航到您儲存 `app.py` 檔案的目錄。\n",
        "5.  確保您已安裝 Flask 和所需的 Python 依賴項。如果沒有，請運行："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "465d0eae"
      },
      "source": [
        "%%writefile index.html\n",
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "    <title>我的活動追蹤器</title>\n",
        "    <link rel=\"stylesheet\" href=\"style.css\">\n",
        "</head>\n",
        "<body>\n",
        "    <div>\n",
        "        <input type=\"text\" id=\"search-input\" placeholder=\"搜尋活動標題或產品...\">\n",
        "        <button id=\"search-button\">搜尋</button>\n",
        "        <button id=\"clear-button\" style=\"display: none;\">清除搜尋</button>\n",
        "    </div>\n",
        "    <div id=\"activity-container\">\n",
        "        <!-- 活動資料會在此處載入 -->\n",
        "    </div>\n",
        "    <script src=\"script.js\"></script>\n",
        "</body>\n",
        "</html>"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "defafd1b"
      },
      "source": [
        "%%writefile style.css\n",
        "body { font-family: sans-serif ;邊距：20px ；行高：1.6 ；/* 提高必性 */ }\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#activity-container {邊框：1px實心  #ccc  ;內邊距：15px ；頂部邊距：20px ；/* 在容器上方增加一些空間 */ }\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        ".activity- item { border - bottom : 1pxsolid   #eee  ; /* 活動項目分隔符號 */ padding: 10px 0 ;下邊距：10px ；}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        ".activity-item:last-child { border-bottom:無; /* 刪除最後一個陌生人 */ }\n",
        "\n",
        "\n",
        "\n",
        ".activity-item h3 {  上邊距：0 ;下邊距：5px ;顏色：#333 ;  }\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        ".activity-item p {  邊距：5px 0 ;顏色：#666 ;字體大小：0.9em ;  }\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#pagination-controls {邊距頂部：20px ;文字對齊：居中；/* 中心分頁控制 */ }\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#pagination-controls按鈕{  邊距：0 5px ;填充：8px 15px ;遊標：指標;  }\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "/* 基本響應式設計 */ @media\n",
        "(    max  -width:   600  px  )   {\n",
        "    body {  margin: 10px ; /* 在較小的螢幕上減少邊距 */ }\n",
        "\n",
        "\n",
        "\n",
        "    #activity-container {填充：10px ; /* 減少填充 */ }\n",
        "\n",
        "\n",
        "\n",
        "    #pagination-controls按鈕{ padding: 5px 10px ; /* 縮小的按鈕 */ font-size: 0.9em ; }\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    #pagination-controls span {  字體大小：0.9em ;  }\n",
        "\n",
        "\n",
        "\n",
        "    .activity-item h3 {字體大小：1em ; /* 調整字體大小 */ }\n",
        "\n",
        "\n",
        "\n",
        "    .activity-item p {字體大小：0.8em ; /* 調整字體大小 */ }  }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5ba9391"
      },
      "source": [
        "%% writefile script.js document.addEventListener\n",
        "( ' DOMContentLoaded ' , ( ) = > { const  activityContainer  =  document . getElementById   (   '   activity   - container ' ) ; const   searchInput   = document . Element  age  ;  =   document . getElementById  ( ' clear- button ' ) ; const  paginationDiv  =   document . createElement  ( ' div ' ) ; //為頁面控制項建立一個divginationDiv.id = '  divgination - controls ;          activityConiv  . activityContainer.nextSibling ) ;  }\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    讓  所有活動  = []; // 用於儲存所有取得的活動的變數 const itemsPerPage = 10 ; // 每頁顯示的項目數let currentPage = 1 ; // 當前頁碼let   FilteredActivities = []; // 用於儲存過濾活動的變數\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    // 根據所提供的資料渲染活動的函數 const renderActivities = (  eventsToRender ) => { if (!activityContainer  ) return ; //確保容器存在activityContainer . 內部 HTML = '' ; // 清除目前內容\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        如果(  activitiesToRender   &&   activitiesToRender  .  length   > 0 ) {\n",
        "             activitiesToRender  .  forEach  (  activity   => { const  activityDiv   =   document   .  createElement  ( ' div ' ) ;                  activityDiv  .  classactivity  . (div ' ) ;\n",
        "\n",
        "\n",
        "\n",
        "                const   titleElement   =  文檔 . 建立元素 （'h3' ）；// 使用 h3 作為標題\n",
        "                titleElement  。 文字內容  =  活動 。 活動標題  || '無標題' ;\n",
        "\n",
        "                const   timeElement   =  文檔 . 建立元素 ( 'p' ) ; // 時間以提高可行性（可選）try { const date = new Date ( Activity  . Activity_time ) ;                     時間元素 .文字內容 = ` ` 時間：$ { 日期 .  toLocString() 時間元素。 活動 。活動時間|| '無時間資訊' } ` ; }\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                const 產品元素 = 文檔.建立元素（'p' ）；\n",
        "                產品元素。textContent  = `產品：  ${活動.產品 || '無產品資訊' } ` ;\n",
        "\n",
        "                activityDiv.appendChild ( titleElement  ) ;                  activityDiv.appendChild (  timeElement  ) ;                  activityDiv.appendChild (  productElement  ) ;\n",
        "\n",
        "\n",
        "\n",
        "                活動容器。追加子元素（activityDiv ）；}); } else {            活動容器. textContent  = '沒有活動資料可顯示。 ' ; } };\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    // 用來渲染分頁控制項的函式 const renderPaginationControls =  (totalRecords,totalPages) => { if (!  paginationDiv) return; //確保分頁div存在        paginationDiv .內部 HTML = '' ; // 清除現有控制項\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        if ( totalPages  > 1 ) {    const  prevButton  =  document . createElement ( ' button '  )             ; prevButton 。​            ​​​ ​ ​ ​​​            ​​​​​​​​​                ​​                 ​​​取得並渲染新頁面});             paginationDiv . appendChild ( prevButton );\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            const  pageInfo  =  document.createElement ( 'span' ) ; pageInfo.textContent\n",
        "            = `基礎 $  { currentPage }  /  ${ totalPages } 字段 ( 字段  $ { totalRecords }字段 ) ` ; paginationDiv.appendChild\n",
        "            ( pageInfo ) ;\n",
        "\n",
        "            const  nextButton  =  document . createElement ( ' button' );\n",
        "            nextButton = document  .   createElement  ( ' button '                 ) ;\n",
        "            nextButton . textContent =  '下一頁' ;\n",
        "            nextButton    . disabled =\n",
        "                currentPage === totalPages ; nextButton 。              paginationDiv . appendChild ( nextButton ); } };\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "     // 從 API 取得資料並渲染的函數const  fetchAndRenderActivities  = () => { const  searchTerm  =  searchInput . value . toLowerCase (); const  apiUrl  = ` /api/activities?page = $ { currentPage } & limit = $ {待\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "         fetch ( apiUrl ) . then ( respond  => { if ( ! response . ok ) { throw new Error (  ` HTTP錯誤                ！狀態：  $ { response . status } ` ) ; } return  respond . json ( ) ;  } ) . then . if ( data  &&  data . activities ) { renderActivities ( data . activities ); //為當前頁面渲染活動                    renderPaginationControls ( data . total_records ,  data . total_pages ); //根據總記錄/頁面渲染分頁}配置為數                    頁                    }                    的活動= 0 ); // 清除分頁}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            })\n",
        "            .catch(error => {\n",
        "                console.error('Error fetching activities:', error);\n",
        "                if (activityContainer) {\n",
        "                    activityContainer.textContent = '載入活動資料失敗。請確認後端應用程式正在運行。';\n",
        "                }\n",
        "                 if (paginationDiv) {\n",
        "                     paginationDiv.innerHTML = ''; // Clear pagination on error\n",
        "                 }\n",
        "\n",
        "            }); };\n",
        "\n",
        "\n",
        "    // 頁面載入時初始取得與渲染\n",
        "    fetchAndRenderActivities ();\n",
        "\n",
        "\n",
        "    // 搜尋按鈕的事件監聽器if ( searchButton ) {         searchButton . addEventListener ( 'click' , () = > {             currentPage  = 1 ; //在新的搜尋中重置到第一頁            fetchAndRenderActivities ( )                  ; //使用搜尋字詞取得 與渲染搜尋後顯示清除按鈕} }); }\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    // 清除搜尋的事件監聽器if ( clearButton ) {         clearButton . addEventListener ( 'click' , () = > { if ( searchInput )  searchInput . value  = ' ' ; //清除搜尋輸入             currentPage  = 1 ; //重置為第一個頁面為play play                 ;隱藏清除按鈕}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            fetchAndRenderActivities (); // 取得並渲染所有資料 }); }\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    // 選擇性：允許透過在輸入欄位中按 Enter 鍵進行搜尋 if ( searchInput &&   searchButton ) { searchInput .  addEventListener ( ' keypress' , (  event ) => { if ( event . key === ' Enter ' ) {                  event . PreventDefault( ) 選取搜尋表 (key === ' Enter ' ) { event .\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "});"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a213fd4b"
      },
      "source": [
        "# Task\n",
        "繼續完善現有的 Flask Web 應用程式，並朝 PWA 方向發展，具體包括增強前端篩選功能、改善響應式設計、實作 Service Worker 和 Web App Manifest，並進行測試。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47a76eb8"
      },
      "source": [
        "## 增強前端功能\n",
        "\n",
        "### Subtask:\n",
        "根據之前的討論，為前端添加更進階的篩選選項（例如按日期範圍、產品類別）。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1c558700"
      },
      "source": [
        "**Reasoning**:\n",
        "I will modify the `index.html` file to add date range input fields and a product category dropdown, which are the new filter controls required by the subtask. This addresses instruction 1.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9b82e82e"
      },
      "source": [
        "%%writefile index.html\n",
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "    <title>我的活動追蹤器</title>\n",
        "    <link rel=\"stylesheet\" href=\"style.css\">\n",
        "</head>\n",
        "<body>\n",
        "    <div class=\"controls-container\">\n",
        "        <div>\n",
        "            <label for=\"start-date\">開始日期:</label>\n",
        "            <input type=\"date\" id=\"start-date\">\n",
        "            <label for=\"end-date\">結束日期:</label>\n",
        "            <input type=\"date\" id=\"end-date\">\n",
        "        </div>\n",
        "        <div>\n",
        "            <label for=\"product-filter\">產品類別:</label>\n",
        "            <select id=\"product-filter\">\n",
        "                <option value=\"\">所有產品</option>\n",
        "                <!-- Product options will be populated by JavaScript -->\n",
        "            </select>\n",
        "        </div>\n",
        "        <div>\n",
        "            <input type=\"text\" id=\"search-input\" placeholder=\"搜尋活動標題或產品...\">\n",
        "            <button id=\"search-button\">搜尋</button>\n",
        "            <button id=\"clear-button\" style=\"display: none;\">清除篩選</button>\n",
        "        </div>\n",
        "    </div>\n",
        "    <div id=\"activity-container\">\n",
        "        <!-- 活動資料會在此處載入 -->\n",
        "    </div>\n",
        "    <div id=\"pagination-controls\">\n",
        "        <!-- Pagination controls will be loaded here -->\n",
        "    </div>\n",
        "    <script src=\"script.js\"></script>\n",
        "</body>\n",
        "</html>"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8734d069"
      },
      "source": [
        "**Reasoning**:\n",
        "I have updated the HTML structure. Now I will modify the `script.js` file to get references to the newly added filter controls, update the `fetchAndRenderActivities` function to include the filter values in the API request URL, and add event listeners to the new filter controls to trigger data fetching and rendering. I will also modify the search button event listener to include the new filter values and update the clear button functionality to clear the new filter inputs. This addresses instructions 2, 3, 4, and 5.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2b377d49"
      },
      "source": [
        "%%writefile script.js\n",
        "document.addEventListener('DOMContentLoaded', () => {\n",
        "    const activityContainer = document.getElementById('activity-container');\n",
        "    const searchInput = document.getElementById('search-input');\n",
        "    const searchButton = document.getElementById('search-button');\n",
        "    const clearButton = document.getElementById('clear-button');\n",
        "    const paginationDiv = document.getElementById('pagination-controls'); // Get existing pagination div\n",
        "\n",
        "    // Get references to the new filter controls\n",
        "    const startDateInput = document.getElementById('start-date');\n",
        "    const endDateInput = document.getElementById('end-date');\n",
        "    const productFilterSelect = document.getElementById('product-filter');\n",
        "\n",
        "    let allActivities = []; // Variable to store all fetched activities (might not be needed anymore with backend filtering)\n",
        "    const itemsPerPage = 10; // Number of items to display per page\n",
        "    let currentPage = 1; // Current page number\n",
        "    let filteredActivities = []; // Variable to store filtered activities (might not be needed anymore)\n",
        "\n",
        "    // Function to populate the product filter dropdown\n",
        "    const populateProductFilter = (activities) => {\n",
        "        const products = new Set();\n",
        "        activities.forEach(activity => {\n",
        "            if (activity.product) {\n",
        "                // Assuming product is a comma-separated string, split and add\n",
        "                activity.product.split(', ').forEach(p => products.add(p.trim()));\n",
        "            }\n",
        "        });\n",
        "        productFilterSelect.innerHTML = '<option value=\"\">所有產品</option>'; // Reset options\n",
        "        Array.from(products).sort().forEach(product => {\n",
        "            const option = document.createElement('option');\n",
        "            option.value = product;\n",
        "            option.textContent = product;\n",
        "            productFilterSelect.appendChild(option);\n",
        "        });\n",
        "    };\n",
        "\n",
        "\n",
        "    // Function to render activities for the current page\n",
        "    const renderActivities = (activitiesToRender) => {\n",
        "        activityContainer.innerHTML = ''; // Clear current content\n",
        "\n",
        "        if (activitiesToRender && activitiesToRender.length > 0) {\n",
        "            activitiesToRender.forEach(activity => {\n",
        "                const activityDiv = document.createElement('div');\n",
        "                activityDiv.classList.add('activity-item');\n",
        "\n",
        "                const titleElement = document.createElement('h3'); // Use h3 for title\n",
        "                titleElement.textContent = activity.activity_title || '無標題';\n",
        "\n",
        "                const timeElement = document.createElement('p');\n",
        "                // Format time for better readability (optional)\n",
        "                try {\n",
        "                    const date = new Date(activity.activity_time);\n",
        "                    // Use toLocaleString with options for better control and clarity\n",
        "                    timeElement.textContent = `時間: ${date.toLocaleString('zh-TW', {\n",
        "                        year: 'numeric',\n",
        "                        month: 'long',\n",
        "                        day: 'numeric',\n",
        "                        hour: '2-digit',\n",
        "                        minute: '2-digit',\n",
        "                        second: '2-digit',\n",
        "                         hour12: false // Use 24-hour format\n",
        "                    })}`;\n",
        "                } catch (e) {\n",
        "                    timeElement.textContent = `時間: ${activity.activity_time || '無時間資訊'}`;\n",
        "                }\n",
        "\n",
        "\n",
        "                const productElement = document.createElement('p');\n",
        "                productElement.textContent = `產品: ${activity.product || '無產品資訊'}`;\n",
        "\n",
        "                activityDiv.appendChild(titleElement);\n",
        "                activityDiv.appendChild(timeElement);\n",
        "                activityDiv.appendChild(productElement);\n",
        "\n",
        "                activityContainer.appendChild(activityDiv);\n",
        "            });\n",
        "        } else {\n",
        "            activityContainer.textContent = '沒有活動資料可顯示。';\n",
        "        }\n",
        "    };\n",
        "\n",
        "    // Function to render pagination controls\n",
        "    const renderPaginationControls = (totalRecords, totalPages) => {\n",
        "        if (!paginationDiv) return; // Ensure pagination div exists\n",
        "        paginationDiv.innerHTML = ''; // Clear existing controls\n",
        "\n",
        "        if (totalPages > 1) {\n",
        "            const prevButton = document.createElement('button');\n",
        "            prevButton.textContent = '上一頁';\n",
        "            prevButton.disabled = currentPage === 1;\n",
        "            prevButton.addEventListener('click', () => {\n",
        "                currentPage--;\n",
        "                fetchAndRenderActivities(); // Fetch data for the previous page\n",
        "            });\n",
        "            paginationDiv.appendChild(prevButton);\n",
        "\n",
        "            const pageInfo = document.createElement('span');\n",
        "            pageInfo.textContent = ` 第 ${currentPage} / ${totalPages} 頁 (共 ${totalRecords} 筆記錄) `;\n",
        "            paginationDiv.appendChild(pageInfo);\n",
        "\n",
        "            const nextButton = document.createElement('button');\n",
        "            nextButton.textContent = '下一頁';\n",
        "            nextButton.disabled = currentPage === totalPages;\n",
        "            nextButton.addEventListener('click', () => {\n",
        "                currentPage++;\n",
        "                fetchAndRenderActivities(); // Fetch data for the next page\n",
        "            });\n",
        "            paginationDiv.appendChild(nextButton);\n",
        "        }\n",
        "    };\n",
        "\n",
        "\n",
        "    // Function to fetch data from the API based on current filters and render\n",
        "    const fetchAndRenderActivities = () => {\n",
        "        if (!activityContainer) return; // Ensure container exists\n",
        "\n",
        "        const searchTerm = searchInput.value.toLowerCase();\n",
        "        const startDate = startDateInput.value;\n",
        "        const endDate = endDateInput.value;\n",
        "        const selectedProduct = productFilterSelect.value;\n",
        "\n",
        "        let apiUrl = `/api/activities?page=${currentPage}&limit=${itemsPerPage}`;\n",
        "\n",
        "        if (searchTerm) {\n",
        "            apiUrl += `&search=${encodeURIComponent(searchTerm)}`;\n",
        "        }\n",
        "        if (startDate) {\n",
        "             // Append start_time filter\n",
        "            apiUrl += `&start_time=${encodeURIComponent(startDate)}`;\n",
        "        }\n",
        "         if (endDate) {\n",
        "             // Append end_time filter (add end of day to include the full day)\n",
        "            const endDateObj = new Date(endDate);\n",
        "            endDateObj.setHours(23, 59, 59, 999);\n",
        "            apiUrl += `&end_time=${encodeURIComponent(endDateObj.toISOString())}`;\n",
        "        }\n",
        "         if (selectedProduct) {\n",
        "             // Append product filter\n",
        "            apiUrl += `&product=${encodeURIComponent(selectedProduct)}`;\n",
        "        }\n",
        "\n",
        "\n",
        "        console.log('Fetching from:', apiUrl); // Log the API URL\n",
        "\n",
        "        fetch(apiUrl)\n",
        "            .then(response => {\n",
        "                // Check if the request was successful\n",
        "                if (!response.ok) {\n",
        "                    throw new Error(`HTTP error! status: ${response.status}`);\n",
        "                }\n",
        "                // Parse the JSON response\n",
        "                return response.json();\n",
        "            })\n",
        "            .then(data => {\n",
        "                console.log('Fetched data:', data); // Log the data to the console\n",
        "\n",
        "                // Populate product filter on the first fetch with all data (before filtering is applied)\n",
        "                // This assumes the first fetch without filters gets all possible product values.\n",
        "                // A more robust solution would be a dedicated endpoint for product categories.\n",
        "                 if (currentPage === 1 && !searchTerm && !startDate && !endDate && !selectedProduct) {\n",
        "                     populateProductFilter(data.activities); // Use activities from the *first* page of all data\n",
        "                 }\n",
        "\n",
        "\n",
        "                // Render the activities for the current page\n",
        "                renderActivities(data.activities);\n",
        "\n",
        "                // Render pagination controls based on the fetched data's total records and pages\n",
        "                renderPaginationControls(data.total_records, data.total_pages);\n",
        "\n",
        "                 // Show/hide clear button\n",
        "                if (searchTerm || startDate || endDate || selectedProduct) {\n",
        "                    clearButton.style.display = 'inline-block';\n",
        "                } else {\n",
        "                    clearButton.style.display = 'none';\n",
        "                }\n",
        "\n",
        "            })\n",
        "            .catch(error => {\n",
        "                console.error('Error fetching activities:', error);\n",
        "                if (activityContainer) {\n",
        "                    activityContainer.textContent = '載入活動資料失敗。請確認後端應用程式正在運行，並檢查控制台是否有錯誤。';\n",
        "                }\n",
        "                 if (paginationDiv) {\n",
        "                     paginationDiv.innerHTML = ''; // Clear pagination on error\n",
        "                 }\n",
        "\n",
        "            });\n",
        "    };\n",
        "\n",
        "\n",
        "    // 頁面載入時初始取得與渲染\n",
        "    // Fetch all data initially to populate product filter (temporary workaround)\n",
        "    fetch('/api/activities?limit=10000') // Fetch a large number to get most/all products\n",
        "         .then(response => response.json())\n",
        "         .then(data => {\n",
        "             if (data && data.activities) {\n",
        "                 populateProductFilter(data.activities);\n",
        "             }\n",
        "             // Then fetch and render the first page with default filters\n",
        "             fetchAndRenderActivities();\n",
        "         })\n",
        "        .catch(error => {\n",
        "            console.error('Error fetching all activities for product filter:', error);\n",
        "            // Still attempt to fetch and render the first page even if product fetch fails\n",
        "            fetchAndRenderActivities();\n",
        "        });\n",
        "\n",
        "\n",
        "\n",
        "    // Event listener for the search button\n",
        "    if (searchButton) {\n",
        "         searchButton.addEventListener('click', () => {\n",
        "             currentPage = 1; // Reset to first page on new search/filter\n",
        "             fetchAndRenderActivities(); // Fetch data with current search and filters\n",
        "         });\n",
        "     }\n",
        "\n",
        "    // Event listeners for filter changes (with debounce to avoid too many requests)\n",
        "    let filterTimer;\n",
        "    const debounceFilter = () => {\n",
        "        clearTimeout(filterTimer);\n",
        "        filterTimer = setTimeout(() => {\n",
        "            currentPage = 1; // Reset to first page on filter change\n",
        "            fetchAndRenderActivities(); // Fetch data with current filters\n",
        "        }, 300); // 300ms delay\n",
        "    };\n",
        "\n",
        "    if (startDateInput) startDateInput.addEventListener('change', debounceFilter);\n",
        "    if (endDateInput) endDateInput.addEventListener('change', debounceFilter);\n",
        "    if (productFilterSelect) productFilterSelect.addEventListener('change', debounceFilter);\n",
        "\n",
        "\n",
        "    // Event listener for clearing all filters and search\n",
        "    if (clearButton) {\n",
        "         clearButton.addEventListener('click', () => {\n",
        "             if (searchInput) searchInput.value = ''; // Clear search input\n",
        "             if (startDateInput) startDateInput.value = ''; // Clear start date input\n",
        "             if (endDateInput) endDateInput.value = ''; // Clear end date input\n",
        "             if (productFilterSelect) productFilterSelect.value = ''; // Reset product filter to \"所有產品\"\n",
        "\n",
        "             currentPage = 1; // Reset to first page\n",
        "             fetchAndRenderActivities(); // Fetch data without any filters\n",
        "             clearButton.style.display = 'none'; // Hide clear button\n",
        "         });\n",
        "     }\n",
        "\n",
        "\n",
        "    // Optional: Allow searching by pressing Enter key in the input field\n",
        "    if (searchInput && searchButton) {\n",
        "        searchInput.addEventListener('keypress', (event) => {\n",
        "            if (event.key === 'Enter') {\n",
        "                event.preventDefault(); // Prevent form submission\n",
        "                searchButton.click(); // Trigger the search button click\n",
        "            }\n",
        "        });\n",
        "    }\n",
        "});"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f28167d2"
      },
      "source": [
        "**Reasoning**:\n",
        "I have updated the HTML and JavaScript for the new filter controls. The next step is to modify the Flask backend API to handle the new `start_time`, `end_time`, and `product` query parameters for filtering the data from the SQLite database. This involves updating the SQL query in the `get_activities` function to include `WHERE` clauses based on these new parameters and adding the corresponding values to the query parameters list. I will also update the import statement to include `request` if it's not already imported in this block. This addresses the backend part of the filtering functionality.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1c52d0d"
      },
      "source": [
        "import sqlite3\n",
        "import os\n",
        "import json\n",
        "from flask import Flask, jsonify, request # Ensure request is imported\n",
        "import math\n",
        "from datetime import datetime, timezone # Import for time comparison\n",
        "\n",
        "# Re-use the Flask app instance if it exists, or create a new one\n",
        "try:\n",
        "    app\n",
        "except NameError:\n",
        "    app = Flask(__name__)\n",
        "\n",
        "# Re-use database configuration and helper functions\n",
        "# DATABASE_FILE, DATABASE_SCHEMA, create_database_and_table, get_db_connection\n",
        "# are assumed to be defined in previous cells and available in the kernel\n",
        "\n",
        "# Ensure the database and table exist and is populated with simulated data\n",
        "create_database_and_table()\n",
        "# Only insert simulated data if the table is empty to avoid duplicates on re-execution\n",
        "conn_check = get_db_connection()\n",
        "if conn_check:\n",
        "    cursor_check = conn_check.cursor()\n",
        "    cursor_check.execute(\"SELECT COUNT(*) FROM activities\")\n",
        "    count = cursor_check.fetchone()[0]\n",
        "    conn_check.close()\n",
        "    if count == 0:\n",
        "        print(\"資料庫為空，插入模擬資料...\")\n",
        "        # Assuming process_and_insert_data_incrementally() is defined and works\n",
        "        try:\n",
        "            process_and_insert_data_incrementally()\n",
        "        except NameError:\n",
        "            print(\"錯誤: process_and_insert_data_incrementally 函式未定義。請確認前一個程式碼格已成功執行。\")\n",
        "            # Define a minimal placeholder if not found\n",
        "            def process_and_insert_data_incrementally():\n",
        "                 print(\"Simulated incremental data insertion function placeholder executed.\")\n",
        "            process_and_insert_data_incrementally() # Call the placeholder\n",
        "    else:\n",
        "        print(f\"資料庫中已有 {count} 筆資料，跳過模擬資料插入。\")\n",
        "\n",
        "# Modify the API endpoint to fetch data from the database with pagination and filtering\n",
        "# Check if the endpoint 'get_activities' already exists to avoid re-adding it\n",
        "# More robust check and removal of existing rule\n",
        "existing_rule = None\n",
        "for rule in list(app.url_map.iter_rules()): # Iterate over a copy of the rules list\n",
        "    if rule.endpoint == 'get_activities' and '/api/activities' in rule.rule:\n",
        "        existing_rule = rule\n",
        "        break\n",
        "\n",
        "if existing_rule:\n",
        "    print(f\"移除現有路由 '{existing_rule.rule}'，端點名稱 '{existing_rule.endpoint}'\")\n",
        "    app.url_map._rules.remove(existing_rule)\n",
        "    # Also remove the endpoint from view_functions to be safe\n",
        "    if 'get_activities' in app.view_functions:\n",
        "         del app.view_functions['get_activities']\n",
        "\n",
        "\n",
        "# --- Redefine the API endpoint with the correct dictionary return structure and new filters ---\n",
        "@app.route('/api/activities', methods=['GET'])\n",
        "def get_activities():\n",
        "    \"\"\"\n",
        "    API endpoint to get processed activity data from the database with pagination and filtering.\n",
        "    Reads from the SQLite database.\n",
        "    Query Parameters:\n",
        "        - page: int (default: 1) - the page number\n",
        "        - limit: int (default: 10) - items per page\n",
        "        - search: str (optional) - keyword to search in activity_title or product\n",
        "        - start_time: str (optional) - ISO 8601 formatted start time for filtering\n",
        "        - end_time: str (optional) - ISO 8601 formatted end time for filtering\n",
        "        - product: str (optional) - product name for filtering\n",
        "    \"\"\"\n",
        "    conn = get_db_connection()\n",
        "    if conn is None:\n",
        "        print(\"無法建立資料庫連線。\")\n",
        "        return jsonify({\"error\": \"無法連接資料庫\"}), 500\n",
        "\n",
        "    try:\n",
        "        cursor = conn.cursor()\n",
        "\n",
        "        # Get query parameters with default values\n",
        "        page = request.args.get('page', 1, type=int)\n",
        "        limit = request.args.get('limit', 10, type=int)\n",
        "        search_term = request.args.get('search', type=str)\n",
        "        start_time_str = request.args.get('start_time', type=str)\n",
        "        end_time_str = request.args.get('end_time', type=str)\n",
        "        product_filter = request.args.get('product', type=str)\n",
        "\n",
        "\n",
        "        # Ensure page and limit are positive\n",
        "        if page <= 0:\n",
        "            page = 1\n",
        "        if limit <= 0:\n",
        "            limit = 10 # Default to 10 if invalid limit is provided\n",
        "\n",
        "        # Build the base query and where clause\n",
        "        base_query = \"SELECT activity_title, activity_time, product FROM activities\"\n",
        "        count_query = \"SELECT COUNT(*) FROM activities\"\n",
        "        where_clauses = []\n",
        "        query_params = []\n",
        "\n",
        "        # Add filtering for search term\n",
        "        if search_term:\n",
        "            where_clauses.append(\"(activity_title LIKE ? COLLATE NOCASE OR product LIKE ? COLLATE NOCASE)\")\n",
        "            query_params.extend([f\"%{search_term}%\", f\"%{search_term}%\"])\n",
        "\n",
        "        # Add filtering for start time\n",
        "        if start_time_str:\n",
        "            # Assuming start_time_str is a date (YYYY-MM-DD), filter from the beginning of that day\n",
        "            where_clauses.append(\"activity_time >= ?\")\n",
        "            # SQLite stores time as TEXT, compare as strings (ISO 8601 is comparable)\n",
        "            # Ensure the start time is in a comparable format (e.g., YYYY-MM-DDTHH:MM:SS.sssZ)\n",
        "            # If input is just YYYY-MM-DD, compare with that prefix\n",
        "            query_params.append(start_time_str)\n",
        "\n",
        "\n",
        "        # Add filtering for end time\n",
        "        if end_time_str:\n",
        "            # Assuming end_time_str is ISO 8601 format\n",
        "            where_clauses.append(\"activity_time <= ?\")\n",
        "             # SQLite stores time as TEXT, compare as strings (ISO 8601 is comparable)\n",
        "            query_params.append(end_time_str)\n",
        "\n",
        "        # Add filtering for product\n",
        "        if product_filter:\n",
        "            where_clauses.append(\"product LIKE ? COLLATE NOCASE\")\n",
        "             # Use '%' around the product name for partial match, or exact match if needed\n",
        "            query_params.append(f\"%{product_filter}%\") # Using LIKE for flexibility\n",
        "\n",
        "\n",
        "        # Combine where clauses\n",
        "        where_clause = \"\"\n",
        "        if where_clauses:\n",
        "            where_clause = \" WHERE \" + \" AND \".join(where_clauses)\n",
        "\n",
        "\n",
        "        # Construct the final queries\n",
        "        # Ensure ordering for consistent pagination (e.g., by time descending)\n",
        "        final_data_query = base_query + where_clause + \" ORDER BY activity_time DESC LIMIT ? OFFSET ?\"\n",
        "        final_count_query = count_query + where_clause\n",
        "\n",
        "        # Add pagination parameters to the data query params\n",
        "        offset = (page - 1) * limit\n",
        "        data_query_params = query_params + [limit, offset]\n",
        "\n",
        "        # Execute the count query first (considering filtering)\n",
        "        cursor.execute(final_count_query, query_params)\n",
        "        total_records = cursor.fetchone()[0]\n",
        "\n",
        "        # Calculate total pages\n",
        "        total_pages = math.ceil(total_records / limit) if limit > 0 else 0\n",
        "\n",
        "        # Execute the data query with filtering and pagination\n",
        "        cursor.execute(final_data_query, data_query_params)\n",
        "\n",
        "        # Fetch all rows and convert them to a list of dictionaries\n",
        "        activities = [dict(row) for row in cursor.fetchall()]\n",
        "\n",
        "        # Return the data along with pagination info in a dictionary\n",
        "        return jsonify({\n",
        "            \"activities\": activities,\n",
        "            \"total_records\": total_records,\n",
        "            \"total_pages\": total_pages,\n",
        "            \"current_page\": page,\n",
        "            \"items_per_page\": limit\n",
        "        })\n",
        "\n",
        "    except sqlite3.Error as e:\n",
        "        print(f\"查詢資料庫錯誤: {e}\")\n",
        "        return jsonify({\"error\": \"無法從資料庫獲取資料\"}), 500\n",
        "    except Exception as e:\n",
        "        print(f\"獲取活動資料時發生未知錯誤: {e}\")\n",
        "        return jsonify({\"error\": str(e)}), 500\n",
        "    finally:\n",
        "        # Ensure the database connection is closed\n",
        "        if conn:\n",
        "            conn.close()\n",
        "\n",
        "\n",
        "# --- Code to run the Flask app (for a typical script execution, NOT for interactive notebook background thread) ---\n",
        "# This block is for demonstration of how to run the app outside the notebook.\n",
        "# Running this directly in a notebook cell will block the cell.\n",
        "if __name__ == '__main__':\n",
        "    print(\"--- Flask App 定義完成 ---\")\n",
        "    print(\"請在標準 Python 環境中運行此腳本以啟動 Flask 應用程式。\")\n",
        "    print(\"您可以通過 http://127.0.0.1:5000/api/activities 訪問 API (如 Port 5000 可用)。\")\n",
        "    print(\"支援的分頁和篩選參數：/api/activities?page=<頁碼>&limit=<每頁筆數>&search=<搜尋關鍵字>&start_time=<開始時間>&end_time=<結束時間>&product=<產品類別>\")\n",
        "    # Example of how to run the app if needed outside the notebook:\n",
        "    # app.run(port=5000, debug=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c811126c"
      },
      "source": [
        "**Reasoning**:\n",
        "The traceback indicates that `create_database_and_table` and likely other helper functions like `get_db_connection` and `process_and_insert_data_incrementally` are not defined in the current execution context, although they were defined in previous cells. This is a limitation of the notebook environment where function definitions in previous cells might not be available in later cells if the kernel state is reset or inconsistent. To fix this and ensure the Flask app code has access to these necessary functions, I need to include the definitions of `create_database_and_table`, `get_db_connection`, and `process_and_insert_data_incrementally` within the same code block as the Flask app definition and the `/api/activities` endpoint. This addresses the `NameError` and ensures all required components are available for the Flask app to function correctly.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V44VU2R3yhpp"
      },
      "source": [
        "import sqlite3\n",
        "import os\n",
        "import json\n",
        "from flask import Flask, jsonify, request\n",
        "import math\n",
        "from datetime import datetime, timezone # Import for time comparison\n",
        "\n",
        "# Define the database file path\n",
        "DATABASE_FILE = 'activities.db'\n",
        "\n",
        "# Define the database schema\n",
        "DATABASE_SCHEMA = \"\"\"\n",
        "CREATE TABLE IF NOT EXISTS activities (\n",
        "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "    activity_title TEXT NOT NULL,\n",
        "    activity_time TEXT NOT NULL,\n",
        "    product TEXT\n",
        ");\n",
        "\"\"\"\n",
        "\n",
        "def create_database_and_table():\n",
        "    \"\"\"Creates the database file and the activities table if they don't exist.\"\"\"\n",
        "    conn = None\n",
        "    try:\n",
        "        conn = sqlite3.connect(DATABASE_FILE)\n",
        "        cursor = conn.cursor()\n",
        "        cursor.execute(DATABASE_SCHEMA)\n",
        "        conn.commit()\n",
        "        print(f\"資料庫 '{DATABASE_FILE}' 已準備就緒，活動記錄表格已建立或已存在。\")\n",
        "    except sqlite3.Error as e:\n",
        "        print(f\"資料庫操作錯誤: {e}\")\n",
        "    finally:\n",
        "        if conn:\n",
        "            conn.close()\n",
        "\n",
        "def get_db_connection():\n",
        "    \"\"\"Establishes and returns a database connection.\"\"\"\n",
        "    try:\n",
        "        conn = sqlite3.connect(DATABASE_FILE)\n",
        "        conn.row_factory = sqlite3.Row # Return rows as dictionary-like objects\n",
        "        return conn\n",
        "    except sqlite3.Error as e:\n",
        "        print(f\"無法建立資料庫連線: {e}\")\n",
        "        return None\n",
        "\n",
        "# Simulate the path where raw Google Takeout JSON would be located initially\n",
        "simulated_raw_data_path =  '/tmp/simulated_google_takeout_raw.json'\n",
        "\n",
        "# Create or update a dummy RAW JSON file with data to test updates\n",
        "# Added a record with the same title and time as an existing one, but different product(s)\n",
        "dummy_raw_data =  [ { \"header\" : \"Google Search\" , \" title \" : \" Searched for example\" , \" time \" : \" 2023-10-27T10 : 00 : 00.000 , \"title\" : \"Watched a video\" , \"time\" : \"2023-10-27T10:05:00.000Z\" , \"products\" : [ \"YouTube\" ] }, { \"header\" : \"Google Maps\" , \"tletle\" : \"YouTube\" ] }, { \"header\" : \"Google Maps\" , \"tletle\" : \"tied for title \" \"2023-10-27T10:10:00.000Z\" , \"products\" : [ \"Maps\" ] }, { \"header\" : \"Google 搜尋\" , \"title\" : \"搜尋了範例\" , \"time\" : \"2023-10-2710: \"搜尋了範例\" , \"time\" : \"2023-10-2710: \"搜尋了範例\" , \"time\" : \"2023-10-2700: \"搜尋了範例\" \"網頁與應用程式活動\" ] }, { \"header\" : \"Google 圖片\" , \"title\" : \"檢視了圖片\" , \"time\" : \"2023-10-27T10:15:00.000Z\" , \" products \" : [ \"圖片\" ] } ]\n",
        "\n",
        "# Create the dummy raw data file if it doesn't exist or overwrite it with new dummy data for testing\n",
        "with open ( simulated_raw_data_path , 'w' ) as  f :\n",
        "    json.dump ( dummy_raw_data ,  f ,  indent= 4 )\n",
        "print ( f \"模擬原始資料檔案已建立/更新於 程式碼\n",
        "\n",
        "# 修改資料處理函數，從原始JSON中讀取並增量更新/插入資料庫\n",
        "def process_and_insert_data_incrementally () :  \"\"\"    讀取    模擬    的Google Takeout原始數據，處理後增量更新或插入SQLite 資料庫。    處理資料時，檢查 記錄 是否存在，如果更新產品資訊，否則插入新記錄。\"無法建立資料庫連線，跳過資料處理及插入。\" )返回\n",
        "\n",
        "    遊標 = conn.cursor ()\n",
        "    插入計數 =  0\n",
        "    更新計數 =  0\n",
        "    跳過計數 =  0\n",
        "\n",
        "    嘗試：# 從模擬的原始 JSON 檔案讀取資料with open ( simulated_raw_data_path , 'r' ) as  f :             takeout_data = json.load ( f )\n",
        "\n",
        "        print ( \"\\n開始增量處理和插入/更新資料...\" )\n",
        "\n",
        "        # Process data and insert/update into the database\n",
        "        for item in takeout_data:\n",
        "            try:\n",
        "                processed_item = {\n",
        "                    'activity_title': item.get('title', '無標題'),\n",
        "                    'activity_time': item.get('time', '無時間資訊'),\n",
        "                    'product': ', '.join(item.get('products', [])) or '無產品資訊'\n",
        "                }\n",
        "\n",
        "                # 檢查是否已經存在相同標題和時間的記錄\n",
        "                cursor.execute ( \"SELECT id, product FROM activities WHERE activity _title = ? AND activity_time = ?\" , ( processed_item [ 'activity_title '                 ] ,  processed_ittimes [ dvates ) ' ()\n",
        "\n",
        "                if  existing_record : # 記錄存在，檢查產品是否需要更新existing_id                     , existing_product  = existing_record if  existing_product != processed_item [ 'product' ]: #產品資訊不同，更新現有記錄cur                         . processed_item [ 'product' ],  existing_id ) )                         updated_count +=  1 print ( f \"更新記錄 (ID:  { existing_id } ):  { processed_item [ 'activity_title' ]} ( { processed_item [ 'activity_item [ 'activity_title' ]}  ( { processed_item []prodity_item] -vtime's ) ' ]}s> \" processed_item [ ]prodity_item] -v > 新 產品] ) else : # 記錄存在且產品相同，跳過                        skipped_count +=  1 print ( f \"記錄已存在且內容相同，跳過插入/更新:  { processed_item [ 'activity_title' ]}  ( { processed_item [ 'activity_time' ]} )\" INS                     )不存在: # INSv電話(activity_title, activity_ time, product) VALUES (?, ?, ?)\" , ( processed_item [ 'activity_title' ],  processed_item [ 'activity_time' ],  processed_item [ 'product' ])插入1_counts_time ' ] , processed_item [ ' product ' ]  )                    插入 1月_count 'activity_title' ]}  ( { processed_item [ 'activity_time' ]} )\" )\n",
        "\n",
        "             except sqlite3.Error  as e : print ( f \"處理或插入/更新 單筆資料錯誤:  { e }  - 資料:  { processed_item } \" ) # 決定出錯時繼續或中斷\n",
        "\n",
        "        conn.commit () # 循環後提交交易 print ( f \"\\n完成增量處理。已插入 { inserted_count } 筆記錄新，更新 { updated_count } 筆記錄，跳過 { skipped_count } 筆記錄。\" )\n",
        "\n",
        "     except FileNotFoundError : print ( f \"錯誤: 模擬原始資料檔案找不到於 { simulated_raw_data_path } \" ) except  json.JSONDecodeError : print ( f \"錯誤: 無法解析 模擬 原始資料 檔{ simulated_raw_data_path } 中的 ExJSON \" ) { sim \"處理和插入/更新資料時發生未知錯誤:  { e } \" ) finally : if  conn :             conn.close () #關閉資料庫連接\n",
        "\n",
        "# --- Flask 應用程式定義 ---\n",
        "app = Flask ( __name__ )\n",
        "\n",
        "@app.route ( '/api/activities' ,  methods= [ 'GET' ])\n",
        "def get_activities () :  \"\"\"     API 端點，用於從資料庫取得已處理的活動數據，並進行分頁與篩選。    從 SQLite 資料庫讀取。        查詢    參數：        - page: int（        預設值：1）- 4-int . str（可選）-在 activity_title 或 product 中搜尋的關鍵字    \"\"\"     conn = get_db_connection () if  conn  is None : return  jsonify ({ \"error\" : \"非法連接資料庫\" }), 500\n",
        "\n",
        "    嘗試：\n",
        "        cursor = conn.cursor （）\n",
        "\n",
        "        # 取得預設值的查詢參數\n",
        "        page = request.args.get ( 'page' , 1 , type = int )\n",
        "        limit = request.args.get ( 'limit' , 10 , type = int )\n",
        "        search_term = request.args.get ( 'search' , type = str )\n",
        "        start_time_str = request.args.get ( 'start_time' , type = str )\n",
        "        end_time_str = request.args.get ( 'end_time' , type = str )\n",
        "        product_filter = request.args.get ( 'product' , type = str )\n",
        "\n",
        "        # 確保頁面和限制為正數，如果 頁面 <=  0 ：            頁 =  1 ，如果 限制 <=  0 ：            限制 =  10 # 如果提供了無效的限制，則預設為 10\n",
        "\n",
        "        # 建立基本查詢\n",
        "        base_query =  \"SELECT activity_title, activity_time, product FRO M activities\"\n",
        "        count_query =  \"SELECT COUNT(*) FROM activities\"\n",
        "        where_clauses = []\n",
        "        query_params =  []\n",
        "\n",
        "        # Add filtering for search term\n",
        "        if search_term:\n",
        "            # Use COLLATE NOCASE for case-insensitive search in SQLite\n",
        "            where_clauses.append(\"(activity_title LIKE ? COLLATE NOCASE OR product LIKE ? COLLATE NOCASE)\")\n",
        "            query_params.extend([f\"%{search_term}%\", f\"%{search_term}%\"])\n",
        "\n",
        "        # Add filtering for start time\n",
        "        if start_time_str:\n",
        "            # Assuming start_time_str is a date (YYYY-MM-DD), filter from the beginning of that day\n",
        "            where_clauses.append(\"activity_time >= ?\")\n",
        "            # SQLite stores time as TEXT, compare as strings (ISO 8601 is comparable)\n",
        "            # Ensure the start time is in a comparable format (e.g., YYYY-MM-DDTHH:MM:SS.sssZ)\n",
        "            # If input is just YYYY-MM-DD, compare with that prefix\n",
        "            query_params.append(start_time_str)\n",
        "\n",
        "        # Add filtering for end time\n",
        "        if end_time_str:\n",
        "            # Assuming end_time_str is ISO 8601 format\n",
        "            where_clauses.append(\"activity_time <= ?\")\n",
        "             # SQLite stores time as TEXT, compare as strings (ISO 8601 is comparable)\n",
        "            query_params.append(end_time_str)\n",
        "\n",
        "        # Add filtering for product\n",
        "        if product_filter:\n",
        "            where_clauses.append(\"product LIKE ? COLLATE NOCASE\")\n",
        "             # Use '%' around the product name for partial match, or exact match if needed\n",
        "            query_params.append(f\"%{product_filter}%\") # Using LIKE for flexibility\n",
        "\n",
        "        # Combine where clauses\n",
        "        where_clause = \"\"\n",
        "        if where_clauses:\n",
        "            where_clause = \" WHERE \" + \" AND \".join(where_clauses)\n",
        "\n",
        "        # Construct the final queries\n",
        "        # Ensure ordering for consistent pagination (e.g., by time descending)\n",
        "        final_data_query = base_query + where_clause + \" ORDER BY activity_time DESC LIMIT ? OFFSET ?\"\n",
        "        final_count_query = count_query + where_clause\n",
        "\n",
        "        # Add pagination parameters to the data query params\n",
        "        offset = (page - 1) * limit\n",
        "        data_query_params = query_params + [limit, offset]\n",
        "\n",
        "        # Execute the count query first (considering filtering)\n",
        "        cursor.execute(final_count_query, query_params)\n",
        "        total_records = cursor.fetchone()[0]\n",
        "\n",
        "        # Calculate total pages\n",
        "        total_pages = math.ceil(total_records / limit) if limit > 0 else 0\n",
        "\n",
        "        # Execute the data query with filtering and pagination\n",
        "        cursor.execute(final_data_query, data_query_params)\n",
        "\n",
        "        # Fetch all rows and convert them to a list of dictionaries\n",
        "        activities = [dict(row) for row in cursor.fetchall()]\n",
        "\n",
        "        # Return the data along with pagination info in a dictionary\n",
        "        return jsonify({\n",
        "            \"activities\": activities,\n",
        "            \"total_records\": total_records,\n",
        "            \"total_pages\": total_pages,\n",
        "            \"current_page\": page,\n",
        "            \"items_per_page\": limit\n",
        "        })\n",
        "\n",
        "    except sqlite3.Error as e:\n",
        "        print(f\"查詢資料庫錯誤: {e}\")\n",
        "        return jsonify({\"error\": \"無法從資料庫獲取資料\"}), 500\n",
        "    except Exception as e:\n",
        "        print(f\"獲取活動資料時發生未知錯誤: {e}\")\n",
        "        return jsonify({\"error\": str(e)}), 500\n",
        "    finally:\n",
        "        # Ensure the database connection is closed\n",
        "        if conn:\n",
        "            conn.close()\n",
        "\n",
        "\n",
        "# --- 執行 Flask 應用程式的入口點 ---\n",
        "if __name__  ==  '__main__' :  # 確保直接執行腳本時建立並填入資料        庫和表    create_database_and_table ()     conn_check = get_db_connection ( ) if  conn_check :         cursor_check = conn_check. FROM events\" ) count =         cursor_check.fetchone ()[ 0 ]         conn_check.close () if count  ==  0 : print ( \"資料庫為空，插入模擬資料...\" )             process_and_insert_data_incrementally () else資料庫中：已跳過f 資料庫 中，\n",
        "\n",
        "    print ( \"\\n--- 啟動 Flask 開發伺服器 ---\" ) # 執行 Flask 開發伺服器# 對於生產，使用 WSGI 伺服器，如 Gunicorn 或 uWSGI     app.run ( port= 5000 ,  debug= True )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6d89438"
      },
      "source": [
        "**Reasoning**:\n",
        "The traceback shows a `SyntaxError: invalid decimal literal` on line 51, specifically within the `dummy_raw_data` definition. Looking at the line, there seems to be an incomplete or corrupted time string: `\" 2023-10-27T10 : 00 : 00.000 , \"`. It looks like a comma is present within the time string itself, breaking the JSON structure. I need to fix this syntax error in the `dummy_raw_data` list to ensure the JSON is valid and can be parsed correctly. I will correct the invalid time string to a valid ISO 8601 format. This directly addresses the syntax error and allows the code execution to proceed.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKAjbbVgyniF",
        "outputId": "6dad0eb1-3c82-4027-f8b8-7e391d23f524"
      },
      "source": [
        "import sqlite3\n",
        "import os\n",
        "import json\n",
        "from flask import Flask, jsonify, request\n",
        "import math\n",
        "from datetime import datetime, timezone\n",
        "\n",
        "# Define the database file path\n",
        "DATABASE_FILE = 'activities.db'\n",
        "\n",
        "# Define the database schema\n",
        "DATABASE_SCHEMA = \"\"\"\n",
        "CREATE TABLE IF NOT EXISTS activities (\n",
        "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "    activity_title TEXT NOT NULL,\n",
        "    activity_time TEXT NOT NULL,\n",
        "    product TEXT\n",
        ");\n",
        "\"\"\"\n",
        "\n",
        "def create_database_and_table():\n",
        "    \"\"\"Creates the database file and the activities table if they don't exist.\"\"\"\n",
        "    conn = None\n",
        "    try:\n",
        "        conn = sqlite3.connect(DATABASE_FILE)\n",
        "        cursor = conn.cursor()\n",
        "        cursor.execute(DATABASE_SCHEMA)\n",
        "        conn.commit()\n",
        "        print(f\"資料庫 '{DATABASE_FILE}' 已準備就緒，活動記錄表格已建立或已存在。\")\n",
        "    except sqlite3.Error as e:\n",
        "        print(f\"資料庫操作錯誤: {e}\")\n",
        "    finally:\n",
        "        if conn:\n",
        "            conn.close()\n",
        "\n",
        "def get_db_connection():\n",
        "    \"\"\"Establishes and returns a database connection.\"\"\"\n",
        "    try:\n",
        "        conn = sqlite3.connect(DATABASE_FILE)\n",
        "        conn.row_factory = sqlite3.Row # Return rows as dictionary-like objects\n",
        "        return conn\n",
        "    except sqlite3.Error as e:\n",
        "        print(f\"無法建立資料庫連線: {e}\")\n",
        "        return None\n",
        "\n",
        "# Simulate the path where raw Google Takeout JSON would be located initially\n",
        "simulated_raw_data_path = '/tmp/simulated_google_takeout_raw.json'\n",
        "\n",
        "# Create or update a dummy RAW JSON file with data to test updates\n",
        "# Corrected the invalid time string\n",
        "dummy_raw_data = [\n",
        "    {\n",
        "        \"header\": \"Google Search\",\n",
        "        \"title\": \"Searched for example\",\n",
        "        \"time\": \"2023-10-27T10:00:00.000Z\", # Corrected time string\n",
        "        \"products\": [\"Search\"]\n",
        "    },\n",
        "    {\n",
        "        \"header\": \"YouTube\",\n",
        "        \"title\": \"Watched a video\",\n",
        "        \"time\": \"2023-10-27T10:05:00.000Z\",\n",
        "        \"products\": [\"YouTube\"]\n",
        "    },\n",
        "     {\n",
        "        \"header\": \"Google Maps\",\n",
        "        \"title\": \"Searched for a location\",\n",
        "        \"time\": \"2023-10-27T10:10:00.000Z\",\n",
        "        \"products\": [\"Maps\"]\n",
        "    },\n",
        "    # Duplicate record (should be skipped based on title and time match)\n",
        "    {\n",
        "        \"header\": \"Google Search\",\n",
        "        \"title\": \"Searched for example\",\n",
        "        \"time\": \"2023-10-27T10:00:00.000Z\",\n",
        "        \"products\": [\"Web & App Activity\"] # Slightly different product(s) - this will test the update logic\n",
        "    },\n",
        "    # New record\n",
        "    {\n",
        "        \"header\": \"Google Images\",\n",
        "        \"title\": \"Viewed an image\",\n",
        "        \"time\": \"2023-10-27T10:15:00.000Z\",\n",
        "        \"products\": [\"Images\"]\n",
        "    },\n",
        "     {\n",
        "        \"header\": \"Google Search\",\n",
        "        \"title\": \"Another search\",\n",
        "        \"time\": \"2023-10-28T11:00:00.000Z\", # New record for date filtering test\n",
        "        \"products\": [\"Search\"]\n",
        "    }\n",
        "]\n",
        "\n",
        "# Create the dummy raw data file if it doesn't exist or overwrite it with new dummy data for testing\n",
        "with open(simulated_raw_data_path, 'w') as f:\n",
        "    json.dump(dummy_raw_data, f, indent=4)\n",
        "print(f\"模擬原始資料檔案已建立/更新於: {simulated_raw_data_path}\")\n",
        "\n",
        "# Modified data processing function to read from the raw JSON and incrementally update/insert into DB\n",
        "def process_and_insert_data_incrementally():\n",
        "    \"\"\"\n",
        "    讀取模擬的 Google Takeout 原始資料，處理後增量更新或插入 SQLite 資料庫。\n",
        "    在處理資料時，檢查記錄是否存在，如果存在則更新產品資訊，否則插入新記錄。\n",
        "    \"\"\"\n",
        "    conn = get_db_connection()\n",
        "    if conn is None:\n",
        "        print(\"無法建立資料庫連線，跳過資料處理及插入。\")\n",
        "        return\n",
        "\n",
        "    cursor = conn.cursor()\n",
        "    inserted_count = 0\n",
        "    updated_count = 0\n",
        "    skipped_count = 0 # For cases where we might skip based on other criteria in the future\n",
        "\n",
        "    try:\n",
        "        # Read data from the simulated raw JSON file\n",
        "        with open(simulated_raw_data_path, 'r') as f:\n",
        "            takeout_data = json.load(f)\n",
        "\n",
        "        print(\"\\n開始增量處理和插入/更新資料...\")\n",
        "\n",
        "        # Process data and insert/update into the database\n",
        "        for item in takeout_data:\n",
        "            try:\n",
        "                processed_item = {\n",
        "                    'activity_title': item.get('title', '無標題'),\n",
        "                    'activity_time': item.get('time', '無時間資訊'),\n",
        "                    'product': ', '.join(item.get('products', [])) or '無產品資訊'\n",
        "                }\n",
        "\n",
        "                # Check if a record with the same title and time already exists\n",
        "                cursor.execute(\n",
        "                    \"SELECT id, product FROM activities WHERE activity_title = ? AND activity_time = ?\",\n",
        "                    (processed_item['activity_title'], processed_item['activity_time'])\n",
        "                )\n",
        "                existing_record = cursor.fetchone()\n",
        "\n",
        "                if existing_record:\n",
        "                    # Record exists, check if product needs update\n",
        "                    existing_id, existing_product = existing_record\n",
        "                    if existing_product != processed_item['product']:\n",
        "                        # Product information is different, update the existing record\n",
        "                        cursor.execute(\n",
        "                            \"UPDATE activities SET product = ? WHERE id = ?\",\n",
        "                            (processed_item['product'], existing_id)\n",
        "                        )\n",
        "                        updated_count += 1\n",
        "                        print(f\"更新記錄 (ID: {existing_id}): {processed_item['activity_title']} ({processed_item['activity_time']}) - 新產品: {processed_item['product']}\")\n",
        "                    else:\n",
        "                        # Record exists and product is the same, skip\n",
        "                        skipped_count += 1\n",
        "                        print(f\"記錄已存在且內容相同，跳過插入/更新: {processed_item['activity_title']} ({processed_item['activity_time']})\")\n",
        "                else:\n",
        "                    # Record does not exist, insert a new one\n",
        "                    cursor.execute(\n",
        "                        \"INSERT INTO activities (activity_title, activity_time, product) VALUES (?, ?, ?)\",\n",
        "                        (processed_item['activity_title'], processed_item['activity_time'], processed_item['product'])\n",
        "                    )\n",
        "                    inserted_count += 1\n",
        "                    print(f\"插入新記錄: {processed_item['activity_title']} ({processed_item['activity_time']})\")\n",
        "\n",
        "            except sqlite3.Error as e:\n",
        "                print(f\"處理或插入/更新單筆資料錯誤: {e} - 資料: {processed_item}\")\n",
        "                # Decide whether to continue or break on error\n",
        "\n",
        "        conn.commit() # Commit the transaction after the loop\n",
        "        print(f\"\\n增量處理完成。已插入 {inserted_count} 筆新記錄，更新 {updated_count} 筆記錄，跳過 {skipped_count} 筆記錄。\")\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"錯誤: 模擬原始資料檔案未找到於 {simulated_raw_data_path}\")\n",
        "    except json.JSONDecodeError:\n",
        "        print(f\"錯誤: 無法解析模擬原始資料檔案 {simulated_raw_data_path} 中的 JSON\")\n",
        "    except Exception as e:\n",
        "        print(f\"處理和插入/更新資料時發生未知錯誤: {e}\")\n",
        "    finally:\n",
        "        if conn:\n",
        "            conn.close() # Close the database connection\n",
        "\n",
        "\n",
        "# --- Flask 應用程式定義 ---\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route('/api/activities', methods=['GET'])\n",
        "def get_activities():\n",
        "    \"\"\"\n",
        "    API endpoint to get processed activity data from the database with pagination and filtering.\n",
        "    Reads from the SQLite database.\n",
        "    Query Parameters:\n",
        "        - page: int (default: 1) - the page number\n",
        "        - limit: int (default: 10) - items per page\n",
        "        - search: str (optional) - keyword to search in activity_title or product\n",
        "        - start_time: str (optional) - YYYY-MM-DD format start date for filtering\n",
        "        - end_time: str (optional) - YYYY-MM-DD format end date for filtering\n",
        "        - product: str (optional) - product name for filtering\n",
        "    \"\"\"\n",
        "    conn = get_db_connection()\n",
        "    if conn is None:\n",
        "        print(\"無法建立資料庫連線。\")\n",
        "        return jsonify({\"error\": \"無法連接資料庫\"}), 500\n",
        "\n",
        "    try:\n",
        "        cursor = conn.cursor()\n",
        "\n",
        "        # Get query parameters with default values\n",
        "        page = request.args.get('page', 1, type=int)\n",
        "        limit = request.args.get('limit', 10, type=int)\n",
        "        search_term = request.args.get('search', type=str)\n",
        "        start_date_str = request.args.get('start_time', type=str) # Use start_date_str for clarity\n",
        "        end_date_str = request.args.get('end_time', type=str) # Use end_date_str for clarity\n",
        "        product_filter = request.args.get('product', type=str)\n",
        "\n",
        "\n",
        "        # Ensure page and limit are positive\n",
        "        if page <= 0:\n",
        "            page = 1\n",
        "        if limit <= 0:\n",
        "            limit = 10 # Default to 10 if invalid limit is provided\n",
        "\n",
        "        # Build the base query and where clause\n",
        "        base_query = \"SELECT activity_title, activity_time, product FROM activities\"\n",
        "        count_query = \"SELECT COUNT(*) FROM activities\"\n",
        "        where_clauses = []\n",
        "        query_params = []\n",
        "\n",
        "        # Add filtering for search term\n",
        "        if search_term:\n",
        "            # Use COLLATE NOCASE for case-insensitive search in SQLite\n",
        "            where_clauses.append(\"(activity_title LIKE ? COLLATE NOCASE OR product LIKE ? COLLATE NOCASE)\")\n",
        "            query_params.extend([f\"%{search_term}%\", f\"%{search_term}%\"])\n",
        "\n",
        "        # Add filtering for start date\n",
        "        if start_date_str:\n",
        "            # Filter from the beginning of the start day (YYYY-MM-DD)\n",
        "            where_clauses.append(\"activity_time >= ?\")\n",
        "            query_params.append(f\"{start_date_str}T00:00:00.000Z\") # Append time part for comparison\n",
        "\n",
        "\n",
        "        # Add filtering for end date\n",
        "        if end_date_str:\n",
        "             # Filter up to the end of the end day (YYYY-MM-DD)\n",
        "            where_clauses.append(\"activity_time <= ?\")\n",
        "            query_params.append(f\"{end_date_str}T23:59:59.999Z\") # Append time part for comparison\n",
        "\n",
        "\n",
        "        # Add filtering for product\n",
        "        if product_filter:\n",
        "            where_clauses.append(\"product LIKE ? COLLATE NOCASE\")\n",
        "             # Use '%' around the product name for partial match, or exact match if needed\n",
        "            query_params.append(f\"%{product_filter}%\") # Using LIKE for flexibility\n",
        "\n",
        "\n",
        "        # Combine where clauses\n",
        "        where_clause = \"\"\n",
        "        if where_clauses:\n",
        "            where_clause = \" WHERE \" + \" AND \".join(where_clauses)\n",
        "\n",
        "\n",
        "        # Construct the final queries\n",
        "        # Ensure ordering for consistent pagination (e.g., by time descending)\n",
        "        final_data_query = base_query + where_clause + \" ORDER BY activity_time DESC LIMIT ? OFFSET ?\"\n",
        "        final_count_query = count_query + where_clause\n",
        "\n",
        "        # Add pagination parameters to the data query params\n",
        "        offset = (page - 1) * limit\n",
        "        data_query_params = query_params + [limit, offset]\n",
        "\n",
        "        # Execute the count query first (considering filtering)\n",
        "        cursor.execute(final_count_query, query_params)\n",
        "        total_records = cursor.fetchone()[0]\n",
        "\n",
        "        # Calculate total pages\n",
        "        total_pages = math.ceil(total_records / limit) if limit > 0 else 0\n",
        "\n",
        "        # Execute the data query with filtering and pagination\n",
        "        cursor.execute(final_data_query, data_query_params)\n",
        "\n",
        "        # Fetch all rows and convert them to a list of dictionaries\n",
        "        activities = [dict(row) for row in cursor.fetchall()]\n",
        "\n",
        "        # Return the data along with pagination info in a dictionary\n",
        "        return jsonify({\n",
        "            \"activities\": activities,\n",
        "            \"total_records\": total_records,\n",
        "            \"total_pages\": total_pages,\n",
        "            \"current_page\": page,\n",
        "            \"items_per_page\": limit\n",
        "        })\n",
        "\n",
        "    except sqlite3.Error as e:\n",
        "        print(f\"查詢資料庫錯誤: {e}\")\n",
        "        return jsonify({\"error\": \"無法從資料庫獲取資料\"}), 500\n",
        "    except Exception as e:\n",
        "        print(f\"獲取活動資料時發生未知錯誤: {e}\")\n",
        "        return jsonify({\"error\": str(e)}), 500\n",
        "    finally:\n",
        "        # Ensure the database connection is closed\n",
        "        if conn:\n",
        "            conn.close()\n",
        "\n",
        "\n",
        "# --- 執行 Flask 應用程式的入口點 ---\n",
        "if __name__ == '__main__':\n",
        "    # Ensure database and table are created and populated when the script is run directly\n",
        "    create_database_and_table()\n",
        "    conn_check = get_db_connection()\n",
        "    if conn_check:\n",
        "        cursor_check = conn_check.cursor()\n",
        "        cursor_check.execute(\"SELECT COUNT(*) FROM activities\")\n",
        "        count = cursor_check.fetchone()[0]\n",
        "        conn_check.close()\n",
        "        if count == 0:\n",
        "            print(\"資料庫為空，插入模擬資料...\")\n",
        "            process_and_insert_data_incrementally()\n",
        "        else:\n",
        "            print(f\"資料庫中已有 {count} 筆資料，跳過模擬資料插入。\")\n",
        "\n",
        "    print(\"\\n--- 啟動 Flask 開發伺服器 ---\")\n",
        "    # Run the Flask development server\n",
        "    # For production, use a WSGI server like Gunicorn or uWSGI\n",
        "    app.run(port=5000, debug=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "模擬原始資料檔案已建立/更新於: /tmp/simulated_google_takeout_raw.json\n",
            "資料庫 'activities.db' 已準備就緒，活動記錄表格已建立或已存在。\n",
            "資料庫為空，插入模擬資料...\n",
            "\n",
            "開始增量處理和插入/更新資料...\n",
            "插入新記錄: Searched for example (2023-10-27T10:00:00.000Z)\n",
            "插入新記錄: Watched a video (2023-10-27T10:05:00.000Z)\n",
            "插入新記錄: Searched for a location (2023-10-27T10:10:00.000Z)\n",
            "更新記錄 (ID: 1): Searched for example (2023-10-27T10:00:00.000Z) - 新產品: Web & App Activity\n",
            "插入新記錄: Viewed an image (2023-10-27T10:15:00.000Z)\n",
            "插入新記錄: Another search (2023-10-28T11:00:00.000Z)\n",
            "\n",
            "增量處理完成。已插入 5 筆新記錄，更新 1 筆記錄，跳過 0 筆記錄。\n",
            "\n",
            "--- 啟動 Flask 開發伺服器 ---\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: on\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug: * Restarting with watchdog (inotify)\n"
          ]
        }
      ]
    }
  ]
}